																																																																		
Logged in as: zhouzw Logout																																																																		
Application																																																																		
Tools																																																																		
Configuration																																																																		
Local logs																																																																		
Server stacks																																																																		
Server metrics																																																																		
Log Type: stdout																																																																		
																																																																		
Log Upload Time: Mon Aug 03 20:19:12 +0800 2020																																																																		
																																																																		
Log Length: 1298787																																																																		
																																																																		
2020-08-03 17:41:44,120 | INFO  | [main] | Registered signal handler for TERM | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,124 | INFO  | [main] | Registered signal handler for HUP | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,127 | INFO  | [main] | Registered signal handler for INT | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,314 | WARN  | [main] | The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:44,315 | WARN  | [main] | The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:44,360 | INFO  | [main] | Changing view acls to: admin,su_graph_pro | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,361 | INFO  | [main] | Changing modify acls to: admin,su_graph_pro | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,362 | INFO  | [main] | Changing view acls groups to:  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,363 | INFO  | [main] | Changing modify acls groups to:  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,364 | INFO  | [main] | SecurityManager: authentication enabled; ui acls enabled; users  with view permissions: Set(admin, su_graph_pro); groups with view permissions: Set(); users  with modify permissions: Set(admin, su_graph_pro); groups with modify permissions: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:44,980 | WARN  | [main] | spark.yarn.security.credentials.hbase.enabled is deprecated.  Please use spark.security.credentials.hbase.enabled instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:44,989 | WARN  | [main] | spark.yarn.security.credentials.hbase.enabled is deprecated.  Please use spark.security.credentials.hbase.enabled instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:45,018 | INFO  | [main] | Attempting to login to KDC using principal: su_graph_pro@HADOOP.COM | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:45,186 | INFO  | [main] | Successfully logged into KDC. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:46,238 | INFO  | [main] | getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1703672210_1, ugi=su_graph_pro@HADOOP.COM (auth:KERBEROS)]] | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:46,383 | INFO  | [main] | Created token for su_graph_pro: HDFS_DELEGATION_TOKEN owner=su_graph_pro@HADOOP.COM, renewer=, realUser=, issueDate=1596447706343, maxDate=1597052506343, sequenceNumber=2387940, masterKeyId=214 on ha-hdfs:hacluster | org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:714)																																																																		
2020-08-03 17:41:46,400 | INFO  | [main] | getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1703672210_1, ugi=su_graph_pro@HADOOP.COM (auth:KERBEROS)]] | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:46,412 | INFO  | [main] | Created token for su_graph_pro: HDFS_DELEGATION_TOKEN owner=su_graph_pro@HADOOP.COM, renewer=, realUser=, issueDate=1596447706405, maxDate=1597052506405, sequenceNumber=2387941, masterKeyId=214 on ha-hdfs:hacluster | org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:714)																																																																		
2020-08-03 17:41:48,400 | INFO  | [main] | Process identifier=hconnection-0x34b87182 connecting to ZooKeeper ensemble=10.27.132.3:24002,10.27.132.5:24002,10.27.132.4:24002 | org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:146)																																																																		
2020-08-03 17:41:48,410 | INFO  | [main] | Client environment:zookeeper.version=3.5.1, built on 07/10/2019 17:53 GMT | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,411 | INFO  | [main] | Client environment:host.name=dn37 | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,411 | INFO  | [main] | Client environment:java.version=1.8.0_201 | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,411 | INFO  | [main] | Client environment:java.vendor=Oracle Corporation | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,411 | INFO  | [main] | Client environment:java.home=/opt/huawei/Bigdata/common/runtime0/jdk-8u201/jre | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,412 | INFO  | [main] | Client environment:java.class.path=/opt/huawei/Bigdata/common/runtime/security:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_conf__:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/accessors-smart-1.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/activation-1.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/aircompressor-0.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/antlr-2.7.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/antlr4-runtime-4.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/antlr-runtime-3.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/aopalliance-1.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/aopalliance-repackaged-2.4.0-b34.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/apache-log4j-extras-1.2.17.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/arpack_combined_all-0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/arrow-format-0.8.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/arrow-memory-0.8.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/arrow-vector-0.8.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/avro-1.7.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/avro-ipc-1.7.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/avro-mapred-1.7.7-hadoop2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/aws-java-sdk-bundle-1.11.271.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/bonecp-0.8.0.RELEASE.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/breeze_2.11-0.13.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/breeze-macros_2.11-0.13.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/calcite-avatica-1.2.0-incubating.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/calcite-core-1.2.0-incubating.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/calcite-linq4j-1.2.0-incubating.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-bloom-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-cli-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-common-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-common-plugin-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-core-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-datamap-examples-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-format-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-geo-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-hadoop-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-hive-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-mv-core-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-mv-plan-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-processing-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-secondary_index-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-spark2-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-spark-common-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-spark-datasource-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-store-sdk-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/carbondata-streaming-2.0.0.0200.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/cas-client-core-hw-3.3.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/cglib-nodep-3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/chill_2.11-0.8.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/chill-java-0.8.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-beanutils-1.9.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-cli-1.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-codec-1.10.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-collections-3.2.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-compiler-3.0.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-compress-1.4.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-configuration2-2.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-crypto-1.0.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-daemon-1.0.13.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-dbcp-1.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-httpclient-3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-io-2.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-lang-2.6.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-lang3-3.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-logging-1.1.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-math3-3.4.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-net-2.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/commons-pool-1.5.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/compress-lzf-1.0.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/core-1.1.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/crypter-0.0.6.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/curator-client-2.7.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/curator-framework-2.7.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/curator-recipes-2.7.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/datanucleus-api-jdo-3.2.6.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/datanucleus-core-3.2.10.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/datanucleus-rdbms-3.2.9.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/derby-10.12.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/dnsjava-2.1.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/ehcache-3.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/eigenbase-properties-1.1.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/fastutil-8.2.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/flatbuffers-1.2.0-3f79e055.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/gson-2.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/guava-14.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/guice-4.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/guice-servlet-4.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-annotations-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-auth-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-aws-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-client-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-common-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-hdfs-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-hdfs-client-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-huaweicloud-3.1.1-hw-37.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-mapreduce-client-common-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-mapreduce-client-core-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-mapreduce-client-jobclient-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jpam-1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-plugins-1.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-yarn-api-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-yarn-client-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-yarn-common-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-yarn-registry-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-yarn-server-common-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hadoop-yarn-server-web-proxy-3.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hbase-client-1.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hbase-common-1.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hbase-hadoop2-compat-1.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hbase-hadoop-compat-1.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hbase-protocol-1.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hbase-server-1.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/HikariCP-java7-2.4.12.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-beeline-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-cli-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-common-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-contrib-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-exec-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-hbase-handler-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-jdbc-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hive-metastore-1.2.1.spark_2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hk2-api-2.4.0-b34.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hk2-locator-2.4.0-b34.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hk2-utils-2.4.0-b34.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/hppc-0.7.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/htrace-core-3.1.0-incubating.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/htrace-core4-4.1.0-incubating.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/httpclient-4.5.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/httpcore-4.4.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/ivy-2.4.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-annotations-2.10.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-core-2.10.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-core-asl-1.9.13.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-databind-2.10.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-jaxrs-1.9.13.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-jaxrs-base-2.9.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-jaxrs-json-provider-2.9.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-mapper-asl-1.9.13.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-module-jaxb-annotations-2.10.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-module-paranamer-2.10.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-module-scala_2.11-2.10.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jackson-xc-1.9.13.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/janino-3.0.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jansi-1.11.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/JavaEWAH-0.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/javassist-3.18.1-GA.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/javax.annotation-api-1.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/javax.inject-2.4.0-b34.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/javax.servlet-api-3.1.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/javax.ws.rs-api-2.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/javolution-5.5.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jaxb-api-2.2.11.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jaxb-impl-2.2.3-1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jcip-annotations-1.0-1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jcl-over-slf4j-1.7.16.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/JDBCPushDown-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jdo-api-3.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-client-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-common-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-container-servlet-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-container-servlet-core-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-guava-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-media-jaxb-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jersey-server-2.22.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jettison-1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jetty-util-ajax-9.3.24.v20180605.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jetty-webapp-9.3.24.v20180605.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jetty-xml-9.3.24.v20180605.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/joda-time-2.9.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jodd-core-3.5.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/json-20090211.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/json4s-ast_2.11-3.2.11.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/json4s-core_2.11-																																																																		
3.2.11.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/json4s-jackson_2.11-3.2.11.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/json-smart-2.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jsp-api-2.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jsr305-1.3.9.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jta-1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jtransforms-2.4.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jts-core-1.16.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/jul-to-slf4j-1.7.16.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-admin-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-client-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-common-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-core-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-crypto-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-identity-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-server-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-simplekdc-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerb-util-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerby-asn1-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerby-config-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerby-pkix-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerby-util-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kerby-xdr-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/kryo-shaded-3.0.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/leveldbjni-all-1.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/libfb303-0.9.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/libthrift-0.12.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/log4j-1.2.17.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/luna-0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/lz4-java-1.4.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/machinist_2.11-0.6.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/macro-compat_2.11-1.1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/metrics-core-2.2.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/metrics-core-3.1.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/metrics-graphite-3.1.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/metrics-json-3.1.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/metrics-jvm-3.1.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/minlog-1.3.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/mrs-obs-provider-2.8.3.35.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/mssql-jdbc-6.2.1.jre7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/netty-3.9.9.Final.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/netty-all-4.1.17.Final.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/nimbus-jose-jwt-4.41.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/objenesis-2.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/okhttp-2.7.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/okio-1.6.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/om-controller-api-0.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/opencsv-2.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/opensaml-2.6.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/orc-core-1.4.4-nohive.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/orc-mapreduce-1.4.4-nohive.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/original-spark-examples_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/oro-2.0.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/osgi-resource-locator-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parallelalgorithm_2.10-0.1.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/paranamer-2.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-column-1.8.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-common-1.8.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-encoding-1.8.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-format-2.3.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-hadoop-1.8.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-hadoop-bundle-1.6.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-hadoop-bundle-1.8.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/parquet-jackson-1.8.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/protobuf-java-2.5.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/py4j-0.10.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/pyrolite-4.13.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/re2j-1.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/RoaringBitmap-0.5.11.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/scala-library-2.11.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/scalap-2.11.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/scala-parser-combinators_2.11-1.0.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/scala-reflect-2.11.8.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/scala-xml_2.11-1.0.5.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/scopt_2.11-3.7.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/shapeless_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/slf4j-api-1.7.16.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/slf4j-log4j12-1.7.16.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/snappy-0.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/snappy-java-1.1.2.6.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/solr-solrj-6.2.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-catalyst_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-core_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-fi-jobHistoryEnhance-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/sparkfilter-1.1.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-fi-plugin_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-fi-plugin_2.11-2.3.2-tests.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-graphx_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-hbase_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-hbaseV2_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-hive_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-hive-thriftserver_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-hw-plugin_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-kvstore_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-launcher_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-mllib_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-mllib-local_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-network-common_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-network-shuffle_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-om_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-repl_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-sketch_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-sql_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-streaming_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-tags_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-unsafe_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spark-yarn_2.11-2.3.2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spire_2.11-0.13.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/spire-macros_2.11-0.13.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/SSO-1.0.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/ST4-4.0.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/stax2-api-3.1.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/stax-api-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/stream-2.7.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/stringtemplate-3.2.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/super-csv-2.2.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/token-provider-1.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/univocity-parsers-2.5.9.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/validation-api-1.1.0.Final.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/wc2frm-v1r2c60-20160429.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/woodstox-core-5.0.3.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/xbean-asm5-shaded-4.4.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/xercesImpl-2.9.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/xmlsec-1.5.7.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/xz-1.0.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/zkclient-0.10.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/zookeeper-3.5.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_libs__/zstd-jni-1.3.2-2.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/x86/fmi-v1r2c60-20160429.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/x86/jline-2.12.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/x86/om-alarm-common-V100R002C60B050.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/x86/scala-compiler-2.11.8.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/1_8_NodeManager/etc:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/hadoop-kms-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/hadoop-nfs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/hadoop-common-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/apache-log4j-extras-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/cas-client-core-hw-3.3.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/crypter-0.0.6.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/gsjdbc4-V100R003C10SPC117.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jna-4.4.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/																																																																		
opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/opensaml-2.6.5.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/snappy-java-1.1.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/SSO-1.0.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/wc2frm-v1r2c60-20160429.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/xmlsec-1.5.7.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/zookeeper-3.5.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-databind-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-core-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/jackson-annotations-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/common/lib/hadoop-plugins-1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-datamovement-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/apache-log4j-extras-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/zookeeper-3.5.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-core-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/lib/jobhistory-ha-0.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-globalpolicygenerator-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/spark-1.5.1-yarn-shuffle.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/superior-client-3.1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/superior-yarn-scheduler-3.1.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/yarn/lib/spark-2.3.2-yarn-shuffle.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/aliyun-sdk-oss-2.8.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/aws-java-sdk-bundle-1.11.271.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/azure-data-lake-store-sdk-2.2.7.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/azure-keyvault-core-1.0.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/azure-storage-7.0.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-aliyun-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-archive-logs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-archives-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-aws-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-azure-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-azure-datalake-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-client-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-datajoin-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-extras-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-fs2img-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-gridmix-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-kafka-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-openstack-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-resourceestimator-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-rumen-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-sls-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-trace-ping-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/jdom-1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/lz4-1.2.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-buffer-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-codec-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-codec-http-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-common-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-handler-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-resolver-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/netty-transport-4.1.17.Final.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/ojalgo-43.0.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/tools/lib/hadoop-backup-util-0.0.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.1.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/share/hadoop/mapreduce/lib/jobhistory-ha-0.0.1.jar:/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/__spark_conf__/__hadoop_conf__ | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,413 | INFO  | [main] | Client environment:java.library.path=/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/lib/native:/ETL/client/faods_client/Spark2x/spark/native::/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,414 | INFO  | [main] | Client environment:java.io.tmpdir=/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/tmp | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,414 | INFO  | [main] | Client environment:java.compiler=<NA> | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,414 | INFO  | [main] | Client environment:os.name=Linux | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,414 | INFO  | [main] | Client environment:os.arch=amd64 | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,414 | INFO  | [main] | Client environment:os.version=3.10.0-862.el7.x86_64 | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,415 | INFO  | [main] | Client environment:user.name=su_graph_pro | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,415 | INFO  | [main] | Client environment:user.home=/home/su_graph_pro | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,415 | INFO  | [main] | Client environment:user.dir=/srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001 | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,415 | INFO  | [main] | Client environment:os.memory.free=1770MB | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,415 | INFO  | [main] | Client environment:os.memory.max=4551MB | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,416 | INFO  | [main] | Client environment:os.memory.total=2060MB | org.apache.zookeeper.Environment.logEnv(Environment.java:109)																																																																		
2020-08-03 17:41:48,418 | INFO  | [main] | Initiating client connection, connectString=10.27.132.3:24002,10.27.132.5:24002,10.27.132.4:24002 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@14fded9d | org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:865)																																																																		
2020-08-03 17:41:48,438 | INFO  | [main] | zookeeper.request.timeout is not configured. Using default value 120000. | org.apache.zookeeper.ClientCnxn.initRequestTimeout(ClientCnxn.java:150)																																																																		
2020-08-03 17:41:48,439 | INFO  | [main] | zookeeper.client.bind.port.range is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindingPort(ClientCnxn.java:177)																																																																		
2020-08-03 17:41:48,439 | INFO  | [main] | zookeeper.client.bind.address is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindAddress(ClientCnxn.java:194)																																																																		
2020-08-03 17:41:48,451 | INFO  | [main-SendThread(10.27.132.5:24002)] | connecting to 10.27.132.5 24002 | org.apache.zookeeper.client.FourLetterWordMain.send4LetterWord(FourLetterWordMain.java:126)																																																																		
2020-08-03 17:41:48,461 | INFO  | [main-SendThread(10.27.132.5:24002)] | Got server principal from the server and it is zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1184)																																																																		
2020-08-03 17:41:48,462 | INFO  | [main-SendThread(10.27.132.5:24002)] | Using server principal zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1226)																																																																		
2020-08-03 17:41:48,498 | INFO  | [main-SendThread(10.27.132.5:24002)] | successfully logged in. | org.apache.zookeeper.Login.login(Login.java:310)																																																																		
2020-08-03 17:41:48,501 | INFO  | [Thread-8] | TGT refresh thread started. | org.apache.zookeeper.Login$1.run(Login.java:139)																																																																		
2020-08-03 17:41:48,510 | INFO  | [main-SendThread(10.27.132.5:24002)] | Client will use GSSAPI as SASL mechanism. | org.apache.zookeeper.client.ZooKeeperSaslClient$1.run(ZooKeeperSaslClient.java:327)																																																																		
2020-08-03 17:41:48,513 | INFO  | [main-SendThread(10.27.132.5:24002)] | Opening socket connection to server 10.27.132.5/10.27.132.5:24002. Will attempt to SASL-authenticate using Login Context section 'Client' | org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1331)																																																																		
2020-08-03 17:41:48,513 | INFO  | [Thread-8] | TGT valid starting at:        Mon Aug 03 17:41:48 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:328)																																																																		
2020-08-03 17:41:48,513 | INFO  | [Thread-8] | TGT expires:                  Tue Aug 04 17:41:48 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:329)																																																																		
2020-08-03 17:41:48,514 | INFO  | [main-SendThread(10.27.132.5:24002)] | Socket connection established, initiating session, client: /10.27.132.45:33480, server: 10.27.132.5/10.27.132.5:24002 | org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:1053)																																																																		
2020-08-03 17:41:48,514 | INFO  | [Thread-8] | TGT refresh sleeping until: Tue Aug 04 13:38:07 CST 2020 | org.apache.zookeeper.Login$1.run(Login.java:193)																																																																		
2020-08-03 17:41:48,546 | INFO  | [main-SendThread(10.27.132.5:24002)] | Session establishment complete on server 10.27.132.5/10.27.132.5:24002, sessionid = 0x80043dbc98628ab5, negotiated timeout = 90000 | org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1609)																																																																		
2020-08-03 17:41:48,886 | INFO  | [main] | RPC Server Kerberos principal name for service=ClientService is hbase/hadoop.hadoop.com@HADOOP.COM | org.apache.hadoop.hbase.ipc.RpcClientImpl$Connection.processPreambleResponse(RpcClientImpl.java:824)																																																																		
2020-08-03 17:41:48,920 | INFO  | [main] | Closing zookeeper sessionid=0x80043dbc98628ab5 | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeZooKeeperWatcher(ConnectionManager.java:1765)																																																																		
2020-08-03 17:41:48,933 | INFO  | [main-EventThread] | EventThread shut down for session: 0x80043dbc98628ab5 | org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:614)																																																																		
2020-08-03 17:41:48,933 | INFO  | [main] | Session: 0x80043dbc98628ab5 closed | org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:1365)																																																																		
2020-08-03 17:41:48,955 | INFO  | [main] | Get token from HBase: Kind: HBASE_AUTH_TOKEN, Service: 7b4d2a5b-1d4f-44a1-8308-5da9caf70e38, Ident: (org.apache.hadoop.hbase.security.token.AuthenticationTokenIdentifier@344) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:48,987 | INFO  | [main] | Going to obtain Solr token | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,019 | INFO  | [main] | Scheduling login from keytab in 1921535508418.1 h. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,032 | INFO  | [main] | Preparing Local resources | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,146 | INFO  | [main] | ApplicationAttemptId: appattempt_1595920838912_178438_000001 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,176 | INFO  | [main] | Starting the user application in a separate Thread | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,188 | INFO  | [main] | Waiting for spark context initialization... | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,203 | WARN  | [Driver] | 																																																																		
																																																																		
--------------------------->:																																																																		
	su_graph_pro@HADOOP.COM | /ETL/Graphbase/export_data/tpprty/20200730/ACCOUNT_TO_PERSON | /ETL/Graphbase/export_data/mapper/ACCOUNT_TO_PERSON.mapper | /ETL/Graphbase/export_data/desc/ACCOUNT_TO_PERSON.desc | 																																																																	
																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:49,204 | WARN  | [Driver] | 																																																																		
																																																																		
--------------------------->:																																																																		
	username: su_graph_pro@HADOOP.COM																																																																	
data file: /ETL/Graphbase/export_data/tpprty/20200730/ACCOUNT_TO_PERSON																																																																		
mapping file path: /ETL/Graphbase/export_data/mapper/ACCOUNT_TO_PERSON.mapper																																																																		
meta file: /ETL/Graphbase/export_data/desc/ACCOUNT_TO_PERSON.desc																																																																		
																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:49,210 | WARN  | [Driver] | The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:49,210 | WARN  | [Driver] | The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:49,232 | INFO  | [Driver] | Running Spark version 2.3.2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,275 | WARN  | [Driver] | In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN). | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:49,282 | WARN  | [Driver] | Detected deprecated memory fraction settings: [spark.shuffle.memoryFraction, spark.storage.memoryFraction, spark.storage.unrollFraction]. As of Spark 1.6, execution and storage memory management are unified. All memory fractions used in the old model are now deprecated and no longer read. If you wish to use the old memory management, you may explicitly enable `spark.memory.useLegacyMode` (not recommended). | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:49,285 | INFO  | [Driver] | Submitted application:InsertData | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,342 | INFO  | [Driver] | Changing view acls to: admin,su_graph_pro | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,342 | INFO  | [Driver] | Changing modify acls to: admin,su_graph_pro | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,342 | INFO  | [Driver] | Changing view acls groups to:  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,342 | INFO  | [Driver] | Changing modify acls groups to:  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,342 | INFO  | [Driver] | SecurityManager: authentication enabled; ui acls enabled; users  with view permissions: Set(admin, su_graph_pro); groups with view permissions: Set(); users  with modify permissions: Set(admin, su_graph_pro); groups with modify permissions: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,661 | INFO  | [Driver] | Successfully started service 'sparkDriver' on port 22735. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,691 | INFO  | [Driver] | Registering MapOutputTracker | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,714 | INFO  | [Driver] | Registering BlockManagerMaster | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,718 | INFO  | [Driver] | Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,719 | INFO  | [Driver] | BlockManagerMasterEndpoint up | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,734 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data1/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-ec884f74-251c-4d52-932e-2cbea00c29ab | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,735 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data2/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-cdd4d11b-b223-4293-8400-df60f96f0b92 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,735 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-5ab94245-b1a8-4319-bc84-13478d6a875e | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,735 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data4/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-c3c71714-220b-4afc-9607-2b76699ab606 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,736 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data5/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-e7cd435a-0ab1-40b4-8ac8-a7c974b5a05b | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,736 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data6/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-f320f1ad-86fc-4b26-aefc-401d44b48590 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,736 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data7/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-67266905-bb63-4cd6-857f-1391c4b1f5ec | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,737 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data8/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-a9190d55-b95f-4a3b-b318-c890f318e661 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,737 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data9/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-c1a9cbf9-897c-4ea0-92e2-b4a0fe8068e1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,737 | INFO  | [Driver] | Created local directory at /srv/BigData/hadoop/data10/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/blockmgr-e2d23213-d343-46d1-af32-3fea3e1b27c5 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,757 | INFO  | [Driver] | MemoryStore started with capacity 2.5 GB | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:49,874 | INFO  | [Driver] | Registering OutputCommitCoordinator | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,059 | INFO  | [Driver] | Logging initialized @6992ms | org.spark_project.jetty.util.log.Log.initialized(Log.java:192)																																																																		
2020-08-03 17:41:50,134 | WARN  | [Driver] | The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:50,135 | WARN  | [Driver] | The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:50,141 | WARN  | [Driver] | The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:50,141 | WARN  | [Driver] | The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:50,144 | WARN  | [Driver] | The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:50,144 | WARN  | [Driver] | The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:50,157 | INFO  | [Driver] | jetty-x.y.z, build timestamp: 2018-06-06T01:11:56+08:00, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827 | org.spark_project.jetty.server.Server.doStart(Server.java:351)																																																																		
2020-08-03 17:41:50,184 | INFO  | [Driver] | Started @7117ms | org.spark_project.jetty.server.Server.doStart(Server.java:419)																																																																		
2020-08-03 17:41:50,221 | INFO  | [Driver] | Started ServerConnector@51511ed{HTTP/1.1,[http/1.1]}{10.27.132.45:22809} | org.spark_project.jetty.server.AbstractConnector.doStart(AbstractConnector.java:278)																																																																		
2020-08-03 17:41:50,221 | INFO  | [Driver] | Successfully started service 'SparkUI' on port 22809. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,292 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@174511c4{/jobs,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,296 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@21f2c61c{/jobs/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,297 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@a806366{/jobs/job,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,298 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@1cd949d5{/jobs/job/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,299 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@33902255{/stages,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,300 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@3878742b{/stages/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,302 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@7cb257e4{/stages/stage,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,304 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@706bcdeb{/stages/stage/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,305 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@3f8f1a0c{/stages/pool,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,306 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@e28ec73{/stages/pool/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,307 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@bea0422{/storage,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,308 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@19aeeada{/storage/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,309 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@4037b3e5{/storage/rdd,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,310 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@6312f161{/storage/rdd/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,312 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@720f855c{/environment,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,313 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@4732a5f6{/environment/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,314 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@4d1dd5a1{/executors,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,316 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@75b41416{/executors/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,317 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@665245e3{/executors/threadDump,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,318 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@5f9c7c27{/executors/threadDump/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,330 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@6269a79d{/static,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,331 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@8ad5991{/,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,333 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@5c7f1fc3{/api,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,334 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@c0d7832{/jobs/job/kill,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,335 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@c104f34{/stages/stage/kill,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:50,341 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,359 | INFO  | [Driver] | Bound SparkUI to *.*.132.45,and started at http://dn37:22809 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,434 | INFO  | [Driver] | Created YarnClusterScheduler | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,665 | INFO  | [Driver] | Starting Yarn extension services with app application_1595920838912_178438 and attemptId Some(appattempt_1595920838912_178438_000001) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,718 | INFO  | [Driver] | Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 22779. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,719 | INFO  | [Driver] | Server created on dn37:22779 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,722 | INFO  | [Driver] | Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,769 | INFO  | [Driver] | Registering BlockManager driver, dn37:22779, None | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,779 | INFO  | [dispatcher-event-loop-11] | Registering block manager dn37:22779 with 2.5 GB RAM, driver | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,790 | INFO  | [Driver] | Registered BlockManager driver, dn37:22779,None | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,792 | INFO  | [Driver] | Initialized BlockManager: driver, dn37:22779, None | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,823 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:50,825 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@cd37edb{/metrics/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:41:51,083 | INFO  | [Driver] | Logging events to hdfs://hacluster/spark2xJobHistory2x/application_1595920838912_178438_1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,098 | INFO  | [Driver] | Registered listener org.apache.spark.fi.listeners.SparkAMRegistedListener | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,260 | INFO  | [spark-listener-group-shared] | FI SparkAMRegistedListener->onApplicationStart | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,279 | WARN  | [main] | The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:51,280 | WARN  | [main] | The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:41:51,343 | INFO  | [main] | 																																																																		
===============================================================================																																																																		
YARN executor launch context:																																																																		
  env:																																																																		
    CLASSPATH -> <CPS>{{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$PWD/$CPU_TYPE/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_YARN_HOME/share/hadoop/mapreduce/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/tools/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__																																																																		
    SPARK_YARN_STAGING_DIR -> hdfs://hacluster/user/su_graph_pro/.sparkStaging/application_1595920838912_178438																																																																		
    SPARK_USER -> su_graph_pro																																																																		
																																																																		
  command:																																																																		
    LD_LIBRARY_PATH="/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/install/FusionInsight-Hadoop-3.1.1/hadoop/lib/native:$LD_LIBRARY_PATH" \ 																																																																		
      {{JAVA_HOME}}/bin/java \ 																																																																		
      -server \ 																																																																		
      -Xmx10240m \ 																																																																		
      '-Xloggc:<LOG_DIR>/gc.log' \ 																																																																		
      '-XX:+PrintGCDetails' \ 																																																																		
      '-XX:-OmitStackTraceInFastThrow' \ 																																																																		
      '-XX:+PrintGCTimeStamps' \ 																																																																		
      '-XX:+PrintGCDateStamps' \ 																																																																		
      '-XX:+UseGCLogFileRotation' \ 																																																																		
      '-XX:NumberOfGCLogFiles=20' \ 																																																																		
      '-XX:GCLogFileSize=10M' \ 																																																																		
      '-Dlog4j.configuration=./__spark_conf__/__hadoop_conf__/log4j-executor.properties' \ 																																																																		
      '-Djava.security.auth.login.config=./__spark_conf__/__hadoop_conf__/jaas-zk.conf' \ 																																																																		
      '-Dzookeeper.server.principal=zookeeper/hadoop.hadoop.com' \ 																																																																		
      '-Djava.security.krb5.conf=./__spark_conf__/__hadoop_conf__/kdc.conf' \ 																																																																		
      '-Dcarbon.properties.filepath=./__spark_conf__/__hadoop_conf__/carbon.properties' \ 																																																																		
      '-Djdk.tls.ephemeralDHKeySize=2048' \ 																																																																		
      -Djava.io.tmpdir={{PWD}}/tmp \ 																																																																		
      -DSPARK_APP_NAME=tp_graph_GraphWriter \ 																																																																		
      -DSPARK_APP_ID=application_1595920838912_178438 \ 																																																																		
      '-Dspark.rpc.askTimeout=120s' \ 																																																																		
      '-Dspark.rpc.retry.wait=3s' \ 																																																																		
      '-Dspark.random.port.min=22600' \ 																																																																		
      '-Dspark.rpc.io.numConnectionsPerPeer=1' \ 																																																																		
      '-Dspark.ui.port=0' \ 																																																																		
      '-Dspark.rpc.connect.threads=64' \ 																																																																		
      '-Dspark.shuffle.servicev2.port=27338' \ 																																																																		
      '-Dspark.network.timeoutInterval=60' \ 																																																																		
      '-Dspark.port.maxRetries=16' \ 																																																																		
      '-Dspark.network.timeout=360s' \ 																																																																		
      '-Dspark.rpc.io.threads=0' \ 																																																																		
      '-Dspark.rpc.message.maxSize=128' \ 																																																																		
      '-Dspark.random.port.max=22899' \ 																																																																		
      '-Dspark.authenticate=true' \ 																																																																		
      '-Dspark.rpc.lookupTimeout=120s' \ 																																																																		
      '-Dspark.rpc.numRetries=3' \ 																																																																		
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 																																																																		
      -XX:OnOutOfMemoryError='kill %p' \ 																																																																		
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 																																																																		
      --driver-url \ 																																																																		
      spark://CoarseGrainedScheduler@dn37:22735 \ 																																																																		
      --executor-id \ 																																																																		
      <executorId> \ 																																																																		
      --hostname \ 																																																																		
      <hostname> \ 																																																																		
      --cores \ 																																																																		
      2 \ 																																																																		
      --app-id \ 																																																																		
      application_1595920838912_178438 \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/__app__.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/commons-configuration-1.10.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/elasticsearch-rest-client-6.7.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/gremlin-core-3.4.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/gremlin-groovy-3.4.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/gremlin-server-3.4.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/gremlin-shaded-3.4.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/guava-12.0.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/high-scale-lib-1.1.4.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/hppc-0.7.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/httpasyncclient-4.1.2.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/httpcore-nio-4.4.5.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/httpmime-4.4.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/janusgraph-core-0.2.0.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/janusgraph-es-0.2.0.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/janusgraph-hadoop-0.2.0.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/janusgraph-hbase-0.2.0.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/javassist-3.18.0-GA.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/miner-operator-1.0.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/miner-operator-spark-common-1.0.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/reflections-0.9.9-RC1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/spatial4j-0.6.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/tinkergraph-gremlin-3.4.1.jar \ 																																																																		
      --user-class-path \ 																																																																		
      file:$PWD/vertexium-extend-1.1.jar \ 																																																																		
      1><LOG_DIR>/stdout.ext \ 																																																																		
      2><LOG_DIR>/stderr																																																																		
																																																																		
  resources:																																																																		
    vertexium-extend-1.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/vertexium-extend-1.1.jar" } size: 16113 timestamp: 1596447695722 type: FILE visibility: PRIVATE																																																																		
    commons-configuration-1.10.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/commons-configuration-1.10.jar" } size: 362679 timestamp: 1596447694258 type: FILE visibility: PRIVATE																																																																		
    janusgraph-core-0.2.0.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/janusgraph-core-0.2.0.jar" } size: 1740542 timestamp: 1596447695077 type: FILE visibility: PRIVATE																																																																		
    tinkergraph-gremlin-3.4.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/tinkergraph-gremlin-3.4.1.jar" } size: 257793 timestamp: 1596447695654 type: FILE visibility: PRIVATE																																																																		
    httpcore-nio-4.4.5.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/httpcore-nio-4.4.5.jar" } size: 356201 timestamp: 1596447694953 type: FILE visibility: PRIVATE																																																																		
    janusgraph-loading.properties -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/janusgraph-loading.properties" } size: 2419 timestamp: 1596447695776 type: FILE visibility: PRIVATE																																																																		
    gremlin-core-3.4.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/gremlin-core-3.4.1.jar" } size: 1815108 timestamp: 1596447694398 type: FILE visibility: PRIVATE																																																																		
    __app__.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/graphbase-graphwriter-tool-1.1.jar" } size: 653116 timestamp: 1596447694149 type: FILE visibility: PRIVATE																																																																		
    guava-12.0.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/guava-12.0.1.jar" } size: 1795932 timestamp: 1596447694665 type: FILE visibility: PRIVATE																																																																		
    __spark_conf__ -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/__spark_conf__.zip" } size: 297740 timestamp: 1596447696355 type: ARCHIVE visibility: PRIVATE																																																																		
    high-scale-lib-1.1.4.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/high-scale-lib-1.1.4.jar" } size: 98218 timestamp: 1596447694729 type: FILE visibility: PRIVATE																																																																		
    miner-operator-1.0.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/miner-operator-1.0.jar" } size: 163258 timestamp: 1596447695391 type: FILE visibility: PRIVATE																																																																		
    httpasyncclient-4.1.2.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/httpasyncclient-4.1.2.jar" } size: 177112 timestamp: 1596447694881 type: FILE visibility: PRIVATE																																																																		
    arm -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/spark2x/jars/6.5.1.6/spark-archive-2x-arm.zip" } size: 14955466 timestamp: 1588848338308 type: ARCHIVE visibility: PUBLIC																																																																		
    gremlin-server-3.4.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/gremlin-server-3.4.1.jar" } size: 194709 timestamp: 1596447694527 type: FILE visibility: PRIVATE																																																																		
    reflections-0.9.9-RC1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/reflections-0.9.9-RC1.jar" } size: 121013 timestamp: 1596447695526 type: FILE visibility: PRIVATE																																																																		
    x86 -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/spark2x/jars/6.5.1.6/spark-archive-2x-x86.zip" } size: 13934523 timestamp: 1588848335097 type: ARCHIVE visibility: PUBLIC																																																																		
    gremlin-groovy-3.4.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/gremlin-groovy-3.4.1.jar" } size: 216256 timestamp: 1596447694468 type: FILE visibility: PRIVATE																																																																		
    janusgraph-hbase-0.2.0.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/janusgraph-hbase-0.2.0.jar" } size: 5209254 timestamp: 1596447695272 type: FILE visibility: PRIVATE																																																																		
    locals3.jceks -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/locals3.jceks" } size: 0 timestamp: 1596447695945 type: FILE visibility: PRIVATE																																																																		
    spatial4j-0.6.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/spatial4j-0.6.jar" } size: 187537 timestamp: 1596447695598 type: FILE visibility: PRIVATE																																																																		
    janusgraph-hadoop-0.2.0.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/janusgraph-hadoop-0.2.0.jar" } size: 106048 timestamp: 1596447695190 type: FILE visibility: PRIVATE																																																																		
    krb5.conf -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/krb5.conf" } size: 1314 timestamp: 1596447695843 type: FILE visibility: PRIVATE																																																																		
    javassist-3.18.0-GA.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/javassist-3.18.0-GA.jar" } size: 713930 timestamp: 1596447695336 type: FILE visibility: PRIVATE																																																																		
    user.keytab -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/user.keytab" } size: 140 timestamp: 1596447695894 type: FILE visibility: PRIVATE																																																																		
    janusgraph-es-0.2.0.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/janusgraph-es-0.2.0.jar" } size: 72814 timestamp: 1596447695135 type: FILE visibility: PRIVATE																																																																		
    s3p.file -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/s3p.file" } size: 0 timestamp: 1596447695916 type: FILE visibility: PRIVATE																																																																		
    __spark_libs__ -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/spark2x/jars/6.5.1.6/spark-archive-2x.zip" } size: 326871132 timestamp: 1588848331897 type: ARCHIVE visibility: PUBLIC																																																																		
    elasticsearch-rest-client-6.7.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/elasticsearch-rest-client-6.7.1.jar" } size: 110308 timestamp: 1596447694323 type: FILE visibility: PRIVATE																																																																		
    gremlin-shaded-3.4.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/gremlin-shaded-3.4.1.jar" } size: 2189259 timestamp: 1596447694595 type: FILE visibility: PRIVATE																																																																		
    miner-operator-spark-common-1.0.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/miner-operator-spark-common-1.0.jar" } size: 384573 timestamp: 1596447695469 type: FILE visibility: PRIVATE																																																																		
    httpmime-4.4.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/httpmime-4.4.1.jar" } size: 40631 timestamp: 1596447695007 type: FILE visibility: PRIVATE																																																																		
    hppc-0.7.1.jar -> resource { scheme: "hdfs" host: "hacluster" port: -1 file: "/user/su_graph_pro/.sparkStaging/application_1595920838912_178438/hppc-0.7.1.jar" } size: 1140290 timestamp: 1596447694801 type: FILE visibility: PRIVATE																																																																		
																																																																		
=============================================================================== | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,386 | INFO  | [main] | Registering the ApplicationMaster | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,398 | INFO  | [main] | Failing over to 123 | org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider.performFailover(ConfiguredRMFailoverProxyProvider.java:100)																																																																		
2020-08-03 17:41:51,489 | INFO  | [main] | found resource resource-types.xml at file:/opt/huawei/Bigdata/FusionInsight_HD_6.5.1.6/1_8_NodeManager/etc/resource-types.xml | org.apache.hadoop.conf.Configuration.getConfResourceAsInputStream(Configuration.java:2795)																																																																		
2020-08-03 17:41:51,501 | INFO  | [main] | Adding resource type - name = yarn.io/gpu, units = , type = COUNTABLE | org.apache.hadoop.yarn.util.resource.ResourceUtils.getResourceInformationMapFromConfig(ResourceUtils.java:252)																																																																		
2020-08-03 17:41:51,512 | INFO  | [main] | Will request 20 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,517 | INFO  | [dispatcher-event-loop-14] | ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@dn37:22735) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,536 | INFO  | [main] | Submitted 20 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,575 | INFO  | [main] | Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:51,624 | INFO  | [dispatcher-event-loop-16] | Updating delegation tokens for current user. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,299 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000002 on host dn29 for executor with ID 1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,302 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000004 on host dn30 for executor with ID 2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,303 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000003 on host dn28 for executor with ID 3 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,304 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000006 on host dn32 for executor with ID 4 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,304 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000005 on host dn22 for executor with ID 5 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,305 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000008 on host dn34 for executor with ID 6 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,305 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000007 on host dn27 for executor with ID 7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,306 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000010 on host dn37 for executor with ID 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,306 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000009 on host dn24 for executor with ID 9 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,307 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000012 on host dn18 for executor with ID 10 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,308 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000011 on host dn19 for executor with ID 11 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,311 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000014 on host dn15 for executor with ID 12 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,312 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000013 on host dn20 for executor with ID 13 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,312 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000016 on host dn07 for executor with ID 14 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,313 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000015 on host dn16 for executor with ID 15 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,314 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000018 on host dn08 for executor with ID 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,315 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000017 on host dn14 for executor with ID 17 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,316 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000020 on host dn17 for executor with ID 18 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,316 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000019 on host dn10 for executor with ID 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,317 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000021 on host dn36 for executor with ID 20 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:52,319 | INFO  | [Reporter] | Received 20 containers from YARN, launching executors on 20 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:56,279 | INFO  | [dispatcher-event-loop-56] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.45:47294 with ID 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:56,402 | INFO  | [dispatcher-event-loop-58] | Registering block manager dn37:22861 with 5.2 GB RAM, 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:41:59,916 | INFO  | [dispatcher-event-loop-36] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.12:51724 with ID 14 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,039 | INFO  | [dispatcher-event-loop-51] | Registering block manager dn07:22897 with 5.2 GB RAM, 14 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,071 | INFO  | [dispatcher-event-loop-59] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.13:58454 with ID 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,107 | INFO  | [dispatcher-event-loop-5] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.26:51202 with ID 10 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,112 | INFO  | [dispatcher-event-loop-7] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.38:54888 with ID 2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,118 | INFO  | [dispatcher-event-loop-4] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.15:57922 with ID 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,120 | INFO  | [dispatcher-event-loop-4] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.27:46054 with ID 11 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,121 | INFO  | [dispatcher-event-loop-4] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.37:52522 with ID 1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,129 | INFO  | [dispatcher-event-loop-25] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.32:57566 with ID 9 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,144 | INFO  | [dispatcher-event-loop-6] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.35:40302 with ID 7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,153 | INFO  | [dispatcher-event-loop-20] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.30:59294 with ID 5 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,157 | INFO  | [dispatcher-event-loop-20] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.28:55400 with ID 13 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,169 | INFO  | [dispatcher-event-loop-30] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.36:38392 with ID 3 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,205 | INFO  | [dispatcher-event-loop-42] | Registering block manager dn08:22604 with 5.2 GB RAM, 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,227 | INFO  | [dispatcher-event-loop-33] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.21:46253 with ID 15 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,234 | INFO  | [dispatcher-event-loop-37] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.40:54846 with ID 4 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,244 | INFO  | [dispatcher-event-loop-38] | Registering block manager dn30:22608 with 5.2 GB RAM, 2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,245 | INFO  | [dispatcher-event-loop-38] | Registering block manager dn29:22705 with 5.2 GB RAM, 1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,255 | INFO  | [dispatcher-event-loop-47] | Registering block manager dn18:22756 with 5.2 GB RAM, 10 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,264 | INFO  | [dispatcher-event-loop-34] | Registering block manager dn27:22790 with 5.2 GB RAM, 7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,267 | INFO  | [dispatcher-event-loop-34] | Registering block manager dn10:22719 with 5.2 GB RAM, 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,270 | INFO  | [dispatcher-event-loop-46] | Registering block manager dn24:22839 with 5.2 GB RAM, 9 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,276 | INFO  | [dispatcher-event-loop-53] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.42:36736 with ID 6 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,279 | INFO  | [dispatcher-event-loop-51] | Registering block manager dn22:22834 with 5.2 GB RAM, 5 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,280 | INFO  | [dispatcher-event-loop-53] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.22:42584 with ID 18 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,282 | INFO  | [dispatcher-event-loop-49] | Registering block manager dn19:22830 with 5.2 GB RAM, 11 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,286 | INFO  | [dispatcher-event-loop-45] | Registering block manager dn20:22825 with 5.2 GB RAM, 13 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,297 | INFO  | [dispatcher-event-loop-57] | Registering block manager dn28:22784 with 5.2 GB RAM, 3 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,297 | INFO  | [Driver] | SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,298 | INFO  | [Driver] | YarnClusterScheduler.postStartHook done | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,302 | INFO  | [dispatcher-event-loop-0] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.44:60542 with ID 20 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,366 | INFO  | [dispatcher-event-loop-3] | Registering block manager dn16:22668 with 5.2 GB RAM, 15 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,378 | INFO  | [dispatcher-event-loop-7] | Registering block manager dn32:22787 with 5.2 GB RAM, 4 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,407 | INFO  | [dispatcher-event-loop-12] | Registering block manager dn17:22761 with 5.2 GB RAM, 18 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,411 | INFO  | [dispatcher-event-loop-9] | Registering block manager dn34:22620 with 5.2 GB RAM, 6 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,431 | INFO  | [dispatcher-event-loop-15] | Registering block manager dn36:22756 with 5.2 GB RAM, 20 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,453 | INFO  | [dispatcher-event-loop-19] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.19:48900 with ID 17 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,592 | INFO  | [dispatcher-event-loop-6] | Registering block manager dn14:22891 with 5.2 GB RAM, 17 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,652 | INFO  | [Driver] | Block broadcast_0 stored as values in memory (estimated size 457.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,737 | INFO  | [Driver] | Block broadcast_0_piece0 stored as bytes in memory (estimated size 55.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,741 | INFO  | [dispatcher-event-loop-39] | Added broadcast_0_piece0 in memory on dn37:22779 (size: 55.6 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,745 | INFO  | [Driver] | Created broadcast 0 from newAPIHadoopFile at HdfsReader.scala:221 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,843 | INFO  | [Driver] | Total input files to process : 1 | org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:292)																																																																		
2020-08-03 17:42:00,881 | INFO  | [Driver] | Starting job: count at HdfsReader.scala:222 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,916 | INFO  | [dag-scheduler-event-loop] | Got job 0 (count at HdfsReader.scala:222) with 1 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,917 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 0 (count at HdfsReader.scala:222) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,918 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,920 | INFO  | [dag-scheduler-event-loop] | Missing parents: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,928 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 0 (MapPartitionsRDD[1] at map at HdfsReader.scala:221), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,986 | INFO  | [dag-scheduler-event-loop] | Block broadcast_1 stored as values in memory (estimated size 2.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,994 | INFO  | [dag-scheduler-event-loop] | Block broadcast_1_piece0 stored as bytes in memory (estimated size 1826.0 B, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,995 | INFO  | [dispatcher-event-loop-41] | Added broadcast_1_piece0 in memory on dn37:22779 (size: 1826.0 B, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:00,997 | INFO  | [dag-scheduler-event-loop] | Created broadcast 1 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,016 | INFO  | [dag-scheduler-event-loop] | Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at HdfsReader.scala:221) (first 15 tasks are for partitions Vector(0)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,017 | INFO  | [dag-scheduler-event-loop] | Adding task set 0.0 with 1 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,125 | INFO  | [dispatcher-event-loop-56] | Starting task 0.0 in stage 0.0 (TID 0, dn22, executor 5, partition 0, NODE_LOCAL, 7950 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,263 | INFO  | [spark-listener-group-shared] | sparkContext has been init,so getActive from SparkContext | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,343 | INFO  | [dispatcher-event-loop-52] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.20:51756 with ID 12 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,473 | INFO  | [dispatcher-event-loop-51] | Registering block manager dn15:22640 with 5.2 GB RAM, 12 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,615 | INFO  | [dispatcher-event-loop-49] | Added broadcast_1_piece0 in memory on dn22:22834 (size: 1826.0 B, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:01,777 | INFO  | [dispatcher-event-loop-45] | Added broadcast_0_piece0 in memory on dn22:22834 (size: 55.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:02,917 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 0.0 (TID 0) in 1810 ms on dn22 (executor 5) (1/1) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:02,925 | INFO  | [task-result-getter-0] | Removed TaskSet 0.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:02,940 | INFO  | [dag-scheduler-event-loop] | ResultStage 0 (count at HdfsReader.scala:222) finished in 1.982 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:02,952 | INFO  | [Driver] | Job 0 finished: count at HdfsReader.scala:222, took 2.070166 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,009 | INFO  | [Driver] | Starting job: take at HdfsReader.scala:223 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,011 | INFO  | [dag-scheduler-event-loop] | Got job 1 (take at HdfsReader.scala:223) with 1 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,012 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 1 (take at HdfsReader.scala:223) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,012 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,012 | INFO  | [dag-scheduler-event-loop] | Missing parents: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,013 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 1 (MapPartitionsRDD[1] at map at HdfsReader.scala:221), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,018 | INFO  | [dag-scheduler-event-loop] | Block broadcast_2 stored as values in memory (estimated size 3.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,026 | INFO  | [dag-scheduler-event-loop] | Block broadcast_2_piece0 stored as bytes in memory (estimated size 1909.0 B, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,028 | INFO  | [dispatcher-event-loop-63] | Added broadcast_2_piece0 in memory on dn37:22779 (size: 1909.0 B, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,029 | INFO  | [dag-scheduler-event-loop] | Created broadcast 2 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,030 | INFO  | [dag-scheduler-event-loop] | Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[1] at map at HdfsReader.scala:221) (first 15 tasks are for partitions Vector(0)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,031 | INFO  | [dag-scheduler-event-loop] | Adding task set 1.0 with 1 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,035 | INFO  | [dispatcher-event-loop-62] | Starting task 0.0 in stage 1.0 (TID 1, dn22, executor 5, partition 0, NODE_LOCAL, 7950 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,107 | INFO  | [dispatcher-event-loop-55] | Added broadcast_2_piece0 in memory on dn22:22834 (size: 1909.0 B, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,150 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 1.0 (TID 1) in 116 ms on dn22 (executor 5) (1/1) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,151 | INFO  | [task-result-getter-1] | Removed TaskSet 1.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,153 | INFO  | [dag-scheduler-event-loop] | ResultStage 1 (take at HdfsReader.scala:223) finished in 0.137 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,154 | INFO  | [Driver] | Job 1 finished: take at HdfsReader.scala:223, took 0.144452 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,162 | INFO  | [Driver] | includeRowHead is : "includeRowHead":false, | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,163 | WARN  | [Driver] | 																																																																		
																																																																		
--------------------------->:																																																																		
	gethead is : "includeRowHead":false,																																																																	
																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:42:03,167 | WARN  | [Driver] | 																																																																		
																																																																		
--------------------------->:																																																																		
	includeRowHead is : false																																																																	
																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:42:03,297 | INFO  | [dispatcher-event-loop-61] | Removed broadcast_2_piece0 on dn37:22779 in memory (size: 1909.0 B, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,310 | INFO  | [dispatcher-event-loop-69] | Removed broadcast_2_piece0 on dn22:22834 in memory (size: 1909.0 B, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,334 | INFO  | [dispatcher-event-loop-57] | Removed broadcast_1_piece0 on dn37:22779 in memory (size: 1826.0 B, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,338 | INFO  | [dispatcher-event-loop-0] | Removed broadcast_1_piece0 on dn22:22834 in memory (size: 1826.0 B, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,353 | INFO  | [dispatcher-event-loop-8] | Removed broadcast_0_piece0 on dn37:22779 in memory (size: 55.6 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,355 | INFO  | [dispatcher-event-loop-7] | Removed broadcast_0_piece0 on dn22:22834 in memory (size: 55.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,393 | INFO  | [Driver] | loading hive config file: file:/srv/BigData/hadoop/data8/nm/localdir/usercache/su_graph_pro/filecache/577/__spark_conf__.zip/__hadoop_conf__/hive-site.xml | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,411 | INFO  | [Driver] | spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse'). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,411 | INFO  | [Driver] | Warehouse path is '/user/hive/warehouse'. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,421 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,425 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@3aa84dfa{/SQL,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:42:03,426 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,427 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@16a09c53{/SQL/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:42:03,427 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,429 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@16fa6f01{/SQL/execution,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:42:03,429 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,430 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@35438f5{/SQL/execution/json,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:42:03,431 | INFO  | [Driver] | Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,433 | INFO  | [Driver] | Started o.s.j.s.ServletContextHandler@530076af{/static/sql,null,AVAILABLE,@Spark} | org.spark_project.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:781)																																																																		
2020-08-03 17:42:03,515 | INFO  | [Driver] | Initializing HiveMetastoreConnection version 1.2.1 using Spark classes. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:03,604 | WARN  | [Driver] | load mapred-default.xml, HIVE_CONF_DIR env not found! | org.apache.hadoop.hive.ql.session.SessionState.loadMapredDefaultXml(SessionState.java:1101)																																																																		
2020-08-03 17:42:03,691 | INFO  | [Driver] | Trying to connect to metastore with URI thrift://*.*.132.3:21088 | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:471)																																																																		
2020-08-03 17:42:03,696 | INFO  | [Driver] | Whether to use hadoop rpc protection: true | org.apache.hadoop.hive.metastore.MetaStoreUtils.getMetaStoreSaslProperties(MetaStoreUtils.java:1603)																																																																		
2020-08-03 17:42:03,730 | INFO  | [Driver] | Opened a connection to metastore, current connections: 1 | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:517)																																																																		
2020-08-03 17:42:03,731 | INFO  | [Driver] | Connected to metastore. | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:596)																																																																		
2020-08-03 17:42:03,898 | INFO  | [Driver] | Registering function max_date_udf com.djt.djt_hive_udf.DJT_Max_Date | org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:181)																																																																		
2020-08-03 17:42:04,238 | INFO  | [Driver] | Registering function formula_parser cn.taiping.udf.Formula_Parser | org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:181)																																																																		
2020-08-03 17:42:04,238 | INFO  | [Driver] | Registering function checkvehicle cn.bmsoft.CheckVehicle | org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:181)																																																																		
2020-08-03 17:42:04,238 | INFO  | [Driver] | Registering function checkidnumber cn.bmsoft.CheckIDNumber | org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:181)																																																																		
2020-08-03 17:42:04,239 | INFO  | [Driver] | Registering function checkphone cn.bmsoft.CheckPhone | org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:181)																																																																		
2020-08-03 17:42:04,275 | INFO  | [Driver] | Created local directory: /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/tmp/su_graph_pro | org.apache.hadoop.hive.ql.session.SessionState.createPath(SessionState.java:675)																																																																		
2020-08-03 17:42:04,276 | INFO  | [Driver] | Created local directory: /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/tmp/4300ab00-7861-435e-b135-67adbc82762c_resources | org.apache.hadoop.hive.ql.session.SessionState.createPath(SessionState.java:675)																																																																		
2020-08-03 17:42:04,320 | INFO  | [Driver] | Created HDFS directory: /tmp/sparkhive-scratch/su_graph_pro/4300ab00-7861-435e-b135-67adbc82762c | org.apache.hadoop.hive.ql.session.SessionState.createPath(SessionState.java:675)																																																																		
2020-08-03 17:42:04,321 | INFO  | [Driver] | Created local directory: /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/tmp/su_graph_pro/4300ab00-7861-435e-b135-67adbc82762c | org.apache.hadoop.hive.ql.session.SessionState.createPath(SessionState.java:675)																																																																		
2020-08-03 17:42:04,345 | INFO  | [Driver] | Created HDFS directory: /tmp/sparkhive-scratch/su_graph_pro/4300ab00-7861-435e-b135-67adbc82762c/_tmp_space.db | org.apache.hadoop.hive.ql.session.SessionState.createPath(SessionState.java:675)																																																																		
2020-08-03 17:42:04,371 | INFO  | [Driver] | Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=4300ab00-7861-435e-b135-67adbc82762c, clientType=HIVECLI] | org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController.<init>(SQLStdHiveAccessController.java:95)																																																																		
2020-08-03 17:42:04,373 | WARN  | [Driver] | METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory. | org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:795)																																																																		
2020-08-03 17:42:04,373 | INFO  | [Driver] | Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.isCompatibleWith(HiveMetaStoreClient.java:310)																																																																		
2020-08-03 17:42:04,377 | INFO  | [Driver] | Closed a connection to metastore, current connections: 0 | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.close(HiveMetaStoreClient.java:625)																																																																		
2020-08-03 17:42:04,378 | INFO  | [Driver] | Trying to connect to metastore with URI thrift://*.*.132.3:21088 | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:471)																																																																		
2020-08-03 17:42:04,378 | INFO  | [Driver] | Whether to use hadoop rpc protection: true | org.apache.hadoop.hive.metastore.MetaStoreUtils.getMetaStoreSaslProperties(MetaStoreUtils.java:1603)																																																																		
2020-08-03 17:42:04,382 | INFO  | [Driver] | Opened a connection to metastore, current connections: 1 | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:517)																																																																		
2020-08-03 17:42:04,382 | INFO  | [Driver] | Connected to metastore. | org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:596)																																																																		
2020-08-03 17:42:04,388 | INFO  | [Driver] | Warehouse location for Hive client (version 1.2.2) is /user/hive/warehouse | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,036 | INFO  | [Driver] | Warehouse location for Hive client (version 1.2.2) is /user/hive/warehouse | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,220 | INFO  | [Driver] | Property file path: /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/container_e06_1595920838912_178438_01_000001/./__spark_conf__/__hadoop_conf__/carbon.properties | org.apache.carbondata.core.util.CarbonProperties.loadProperties(CarbonProperties.java:802)																																																																		
2020-08-03 17:42:05,221 | INFO  | [Driver] | ------Using Carbon.properties -------- | org.apache.carbondata.core.util.CarbonProperties.print(CarbonProperties.java:1012)																																																																		
2020-08-03 17:42:05,221 | INFO  | [Driver] | {max.query.execution.time=60, carbon.dataload.group.name=ficommon, carbon.indexserver.zookeeper.dir=/indexserver2x, carbon.number.of.cores=4, carbon.private.fi=true, carbon.sort.file.buffer.size=20, carbon.timestamp.format=yyyy-MM-dd HH:mm:ss, carbon.number.of.cores.while.loading=6, carbon.sort.size=500000, carbon.inmemory.record.size=480000, carbon.enable.index.server=false, carbon.disable.index.server.fallback=false, carbon.indexserver.HA.enabled=true, carbon.index.server.port=22900, carbon.storelocation=hdfs://hacluster/user/hive/warehouse/carbon.store} | org.apache.carbondata.core.util.CarbonProperties.print(CarbonProperties.java:1013)																																																																		
2020-08-03 17:42:05,229 | INFO  | [Driver] | Considered file format is: V3 | org.apache.carbondata.core.util.CarbonProperties.validateCarbonDataFileVersion(CarbonProperties.java:788)																																																																		
2020-08-03 17:42:05,230 | INFO  | [Driver] | Blocklet Size Configured value is "64" | org.apache.carbondata.core.util.CarbonProperties.validateBlockletGroupSizeInMB(CarbonProperties.java:646)																																																																		
2020-08-03 17:42:05,253 | INFO  | [Driver] | Considered value for min max byte limit for string is: 200 | org.apache.carbondata.core.util.CarbonProperties.validateStringCharacterLimit(CarbonProperties.java:1685)																																																																		
2020-08-03 17:42:05,253 | INFO  | [Driver] | Using default value for carbon.detail.batch.size 100 | org.apache.carbondata.core.util.CarbonProperties.validateDetailQueryBatchSize(CarbonProperties.java:1710)																																																																		
2020-08-03 17:42:05,294 | INFO  | [Driver] | Registered StateStoreCoordinator endpoint | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,516 | INFO  | [Driver] | read meta success! | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,543 | INFO  | [Driver] | Block broadcast_3 stored as values in memory (estimated size 467.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,572 | INFO  | [Driver] | Block broadcast_3_piece0 stored as bytes in memory (estimated size 58.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,573 | INFO  | [dispatcher-event-loop-2] | Added broadcast_3_piece0 in memory on dn37:22779 (size: 58.5 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,576 | INFO  | [Driver] | Created broadcast 3 from newAPIHadoopFile at HdfsReader.scala:172 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,742 | INFO  | [Driver] | Total input files to process : 45 | org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:292)																																																																		
2020-08-03 17:42:05,759 | INFO  | [Driver] | Starting job: isEmpty at HdfsReader.scala:192 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,761 | INFO  | [dag-scheduler-event-loop] | Got job 2 (isEmpty at HdfsReader.scala:192) with 1 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,762 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 2 (isEmpty at HdfsReader.scala:192) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,762 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,763 | INFO  | [dag-scheduler-event-loop] | Missing parents: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,764 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 2 (MapPartitionsRDD[6] at filter at HdfsReader.scala:192), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,771 | INFO  | [dag-scheduler-event-loop] | Block broadcast_4 stored as values in memory (estimated size 5.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,774 | INFO  | [dag-scheduler-event-loop] | Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,774 | INFO  | [dispatcher-event-loop-15] | Added broadcast_4_piece0 in memory on dn37:22779 (size: 2.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,775 | INFO  | [dag-scheduler-event-loop] | Created broadcast 4 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,776 | INFO  | [dag-scheduler-event-loop] | Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at filter at HdfsReader.scala:192) (first 15 tasks are for partitions Vector(0)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,777 | INFO  | [dag-scheduler-event-loop] | Adding task set 2.0 with 1 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:05,812 | INFO  | [dispatcher-event-loop-16] | Starting task 0.0 in stage 2.0 (TID 2, dn27, executor 7, partition 0, NODE_LOCAL, 7965 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:06,123 | INFO  | [dispatcher-event-loop-25] | Added broadcast_4_piece0 in memory on dn27:22790 (size: 2.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:06,329 | INFO  | [dispatcher-event-loop-19] | Added broadcast_3_piece0 in memory on dn27:22790 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:07,493 | INFO  | [task-result-getter-2] | Finished task 0.0 in stage 2.0 (TID 2) in 1682 ms on dn27 (executor 7) (1/1) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:07,494 | INFO  | [task-result-getter-2] | Removed TaskSet 2.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:07,496 | INFO  | [dag-scheduler-event-loop] | ResultStage 2 (isEmpty at HdfsReader.scala:192) finished in 1.726 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:07,497 | INFO  | [Driver] | Job 2 finished: isEmpty at HdfsReader.scala:192, took 1.737148 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:07,501 | INFO  | [Driver] | Delim for split data is: \u007c | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,112 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 11 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,113 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 54 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,113 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 66 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,113 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 67 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,113 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 73 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,113 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 51 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 71 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 74 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 64 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 69 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 72 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 65 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,114 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 55 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,115 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 52 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,122 | INFO  | [dispatcher-event-loop-32] | Removed broadcast_4_piece0 on dn37:22779 in memory (size: 2.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,138 | INFO  | [dispatcher-event-loop-22] | Removed broadcast_4_piece0 on dn27:22790 in memory (size: 2.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,147 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 63 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,147 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 56 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,147 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 61 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,147 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 70 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,147 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 50 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 60 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 62 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 68 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 59 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 53 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 58 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 57 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,148 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 32 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 49 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 10 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 26 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 31 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 12 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 29 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,149 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 15 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 33 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 42 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 35 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 4 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 48 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,150 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 44 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 34 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 45 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 14 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 43 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,151 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 28 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 27 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 6 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 36 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 20 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 40 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 0 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,152 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 9 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 5 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 13 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 39 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 46 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 3 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 18 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 47 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,153 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 41 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,154 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 17 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,154 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 37 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,154 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,154 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 38 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,154 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 30 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,154 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:08,527 | INFO  | [Driver] | skip CarbonOptimizer | org.apache.spark.sql.optimizer.CarbonLateDecodeRule.checkIfRuleNeedToBeApplied(CarbonLateDecodeRule.scala:95)																																																																		
2020-08-03 17:42:08,527 | INFO  | [Driver] | skip CarbonOptimizer | org.apache.spark.sql.optimizer.CarbonLateDecodeRule.checkIfRuleNeedToBeApplied(CarbonLateDecodeRule.scala:95)																																																																		
2020-08-03 17:42:08,527 | INFO  | [Driver] | Skip CarbonOptimizer | org.apache.spark.sql.optimizer.CarbonLateDecodeRule.apply(CarbonLateDecodeRule.scala:72)																																																																		
2020-08-03 17:42:08,638 | WARN  | [Driver] | Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf. | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 17:42:09,199 | INFO  | [Driver] | Code generated in 368.153226 ms | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,227 | INFO  | [Driver] | Starting job: runJob at SparkPlan.scala:380 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,231 | INFO  | [dag-scheduler-event-loop] | Got job 3 (runJob at SparkPlan.scala:380) with 1 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,231 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 3 (runJob at SparkPlan.scala:380) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,231 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,232 | INFO  | [dag-scheduler-event-loop] | Missing parents: List() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,233 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 3 (MapPartitionsRDD[12] at map at SparkPlan.scala:354), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,296 | INFO  | [dag-scheduler-event-loop] | Block broadcast_5 stored as values in memory (estimated size 26.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,309 | INFO  | [dag-scheduler-event-loop] | Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,310 | INFO  | [dispatcher-event-loop-21] | Added broadcast_5_piece0 in memory on dn37:22779 (size: 8.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,311 | INFO  | [dag-scheduler-event-loop] | Created broadcast 5 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,312 | INFO  | [dag-scheduler-event-loop] | Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at map at SparkPlan.scala:354) (first 15 tasks are for partitions Vector(0)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,313 | INFO  | [dag-scheduler-event-loop] | Adding task set 3.0 with 1 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,317 | INFO  | [dispatcher-event-loop-42] | Starting task 0.0 in stage 3.0 (TID 3, dn27, executor 7, partition 0, NODE_LOCAL, 7965 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:09,386 | INFO  | [dispatcher-event-loop-39] | Added broadcast_5_piece0 in memory on dn27:22790 (size: 8.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:11,624 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 3.0 (TID 3) in 2308 ms on dn27 (executor 7) (1/1) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:11,625 | INFO  | [task-result-getter-3] | Removed TaskSet 3.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:11,626 | INFO  | [dag-scheduler-event-loop] | ResultStage 3 (runJob at SparkPlan.scala:380) finished in 2.389 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:11,627 | INFO  | [Driver] | Job 3 finished: runJob at SparkPlan.scala:380, took 2.399529 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:11,803 | INFO  | [Driver] | userInfo: su_graph_pro | com.huawei.graph.security.LDAPUserInfoUtils.hasPrivilege(LDAPUserInfoUtils.java:76)																																																																		
2020-08-03 17:42:11,805 | INFO  | [Driver] | groupRole: ADMIN | com.huawei.graph.security.LDAPUserInfoUtils.hasPrivilege(LDAPUserInfoUtils.java:78)																																																																		
2020-08-03 17:42:12,079 | INFO  | [Driver] | Instantiated HBase compatibility layer supporting runtime HBase version 1.3.1: org.janusgraph.diskstorage.hbase.HBaseCompat1_0 | org.janusgraph.diskstorage.hbase.HBaseCompatLoader.getCompat(HBaseCompatLoader.java:79)																																																																		
2020-08-03 17:42:12,095 | INFO  | [Driver] | HBase configuration: setting hbase.zookeeper.property.clientPort=24002 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:325)																																																																		
2020-08-03 17:42:12,095 | INFO  | [Driver] | Copied host list from root.storage.hostname to hbase.zookeeper.quorum: cn01,cn03,cn02 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:336)																																																																		
2020-08-03 17:42:12,097 | INFO  | [Driver] | Process identifier=hconnection-0x67314c8a connecting to ZooKeeper ensemble=cn01:24002,cn03:24002,cn02:24002 | org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:146)																																																																		
2020-08-03 17:42:12,099 | INFO  | [Driver] | Initiating client connection, connectString=cn01:24002,cn03:24002,cn02:24002 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@48e74d3f | org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:865)																																																																		
2020-08-03 17:42:12,102 | INFO  | [Driver] | zookeeper.request.timeout is not configured. Using default value 120000. | org.apache.zookeeper.ClientCnxn.initRequestTimeout(ClientCnxn.java:150)																																																																		
2020-08-03 17:42:12,102 | INFO  | [Driver] | zookeeper.client.bind.port.range is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindingPort(ClientCnxn.java:177)																																																																		
2020-08-03 17:42:12,102 | INFO  | [Driver] | zookeeper.client.bind.address is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindAddress(ClientCnxn.java:194)																																																																		
2020-08-03 17:42:12,105 | INFO  | [Driver-SendThread(cn01:24002)] | connecting to cn01 24002 | org.apache.zookeeper.client.FourLetterWordMain.send4LetterWord(FourLetterWordMain.java:126)																																																																		
2020-08-03 17:42:12,109 | INFO  | [Driver-SendThread(cn01:24002)] | Got server principal from the server and it is zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1184)																																																																		
2020-08-03 17:42:12,109 | INFO  | [Driver-SendThread(cn01:24002)] | Using server principal zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1226)																																																																		
2020-08-03 17:42:12,124 | INFO  | [Driver-SendThread(cn01:24002)] | successfully logged in. | org.apache.zookeeper.Login.login(Login.java:310)																																																																		
2020-08-03 17:42:12,125 | INFO  | [Thread-74] | TGT refresh thread started. | org.apache.zookeeper.Login$1.run(Login.java:139)																																																																		
2020-08-03 17:42:12,125 | INFO  | [Driver-SendThread(cn01:24002)] | Client will use GSSAPI as SASL mechanism. | org.apache.zookeeper.client.ZooKeeperSaslClient$1.run(ZooKeeperSaslClient.java:327)																																																																		
2020-08-03 17:42:12,130 | INFO  | [Thread-74] | TGT valid starting at:        Mon Aug 03 17:42:12 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:328)																																																																		
2020-08-03 17:42:12,130 | INFO  | [Thread-74] | TGT expires:                  Tue Aug 04 17:42:12 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:329)																																																																		
2020-08-03 17:42:12,130 | INFO  | [Thread-74] | TGT refresh sleeping until: Tue Aug 04 13:05:50 CST 2020 | org.apache.zookeeper.Login$1.run(Login.java:193)																																																																		
2020-08-03 17:42:12,131 | INFO  | [Driver-SendThread(cn01:24002)] | Opening socket connection to server cn01/10.27.132.3:24002. Will attempt to SASL-authenticate using Login Context section 'Client' | org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1331)																																																																		
2020-08-03 17:42:12,133 | INFO  | [Driver-SendThread(cn01:24002)] | Socket connection established, initiating session, client: /10.27.132.45:41708, server: cn01/10.27.132.3:24002 | org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:1053)																																																																		
2020-08-03 17:42:12,148 | INFO  | [Driver-SendThread(cn01:24002)] | Session establishment complete on server cn01/10.27.132.3:24002, sessionid = 0x7e03be14a6a3c80f, negotiated timeout = 90000 | org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1609)																																																																		
2020-08-03 17:42:13,054 | INFO  | [Driver] | Loaded and initialized config classes: 7 OK out of 9 attempts in PT0.347S | org.janusgraph.core.util.ReflectiveConfigOptionLoader.loadStandard(ReflectiveConfigOptionLoader.java:174)																																																																		
2020-08-03 17:42:13,117 | INFO  | [Driver] | Reflections took 17 ms to scan 4 urls, producing 0 keys and 0 values  | org.reflections.Reflections.scan(Reflections.java:224)																																																																		
2020-08-03 17:42:13,249 | INFO  | [Driver] | Closing master protocol: MasterService | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeMasterService(ConnectionManager.java:2301)																																																																		
2020-08-03 17:42:13,254 | INFO  | [Driver] | Closing zookeeper sessionid=0x7e03be14a6a3c80f | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeZooKeeperWatcher(ConnectionManager.java:1765)																																																																		
2020-08-03 17:42:13,265 | INFO  | [Driver-EventThread] | EventThread shut down for session: 0x7e03be14a6a3c80f | org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:614)																																																																		
2020-08-03 17:42:13,265 | INFO  | [Driver] | Session: 0x7e03be14a6a3c80f closed | org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:1365)																																																																		
2020-08-03 17:42:13,278 | INFO  | [Driver] | clear hbaseStoreManger connection | org.janusgraph.diskstorage.hbase.HBaseStoreManager.close(HBaseStoreManager.java:424)																																																																		
2020-08-03 17:42:13,281 | INFO  | [Driver] | Generated unique-instance-id=0a1b842d221889-dn371 | org.janusgraph.graphdb.configuration.GraphDatabaseConfiguration.getOrGenerateUniqueInstanceId(GraphDatabaseConfiguration.java:1728)																																																																		
2020-08-03 17:42:13,329 | INFO  | [Driver] | HBase configuration: setting hbase.zookeeper.property.clientPort=24002 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:325)																																																																		
2020-08-03 17:42:13,329 | INFO  | [Driver] | Copied host list from root.storage.hostname to hbase.zookeeper.quorum: cn01,cn03,cn02 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:336)																																																																		
2020-08-03 17:42:13,330 | INFO  | [Driver] | Process identifier=hconnection-0x5e373dbf connecting to ZooKeeper ensemble=cn01:24002,cn03:24002,cn02:24002 | org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:146)																																																																		
2020-08-03 17:42:13,330 | INFO  | [Driver] | Initiating client connection, connectString=cn01:24002,cn03:24002,cn02:24002 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@528d57b7 | org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:865)																																																																		
2020-08-03 17:42:13,331 | INFO  | [Driver] | zookeeper.request.timeout is not configured. Using default value 120000. | org.apache.zookeeper.ClientCnxn.initRequestTimeout(ClientCnxn.java:150)																																																																		
2020-08-03 17:42:13,331 | INFO  | [Driver] | zookeeper.client.bind.port.range is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindingPort(ClientCnxn.java:177)																																																																		
2020-08-03 17:42:13,331 | INFO  | [Driver] | zookeeper.client.bind.address is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindAddress(ClientCnxn.java:194)																																																																		
2020-08-03 17:42:13,333 | INFO  | [Driver-SendThread(cn02:24002)] | connecting to cn02 24002 | org.apache.zookeeper.client.FourLetterWordMain.send4LetterWord(FourLetterWordMain.java:126)																																																																		
2020-08-03 17:42:13,335 | INFO  | [Driver-SendThread(cn02:24002)] | Got server principal from the server and it is zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1184)																																																																		
2020-08-03 17:42:13,335 | INFO  | [Driver-SendThread(cn02:24002)] | Using server principal zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1226)																																																																		
2020-08-03 17:42:13,349 | INFO  | [Driver-SendThread(cn02:24002)] | successfully logged in. | org.apache.zookeeper.Login.login(Login.java:310)																																																																		
2020-08-03 17:42:13,350 | INFO  | [Driver-SendThread(cn02:24002)] | Client will use GSSAPI as SASL mechanism. | org.apache.zookeeper.client.ZooKeeperSaslClient$1.run(ZooKeeperSaslClient.java:327)																																																																		
2020-08-03 17:42:13,350 | INFO  | [Thread-78] | TGT refresh thread started. | org.apache.zookeeper.Login$1.run(Login.java:139)																																																																		
2020-08-03 17:42:13,354 | INFO  | [Thread-78] | TGT valid starting at:        Mon Aug 03 17:42:13 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:328)																																																																		
2020-08-03 17:42:13,354 | INFO  | [Thread-78] | TGT expires:                  Tue Aug 04 17:42:13 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:329)																																																																		
2020-08-03 17:42:13,354 | INFO  | [Thread-78] | TGT refresh sleeping until: Tue Aug 04 13:19:27 CST 2020 | org.apache.zookeeper.Login$1.run(Login.java:193)																																																																		
2020-08-03 17:42:13,354 | INFO  | [Driver-SendThread(cn02:24002)] | Opening socket connection to server cn02/10.27.132.4:24002. Will attempt to SASL-authenticate using Login Context section 'Client' | org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1331)																																																																		
2020-08-03 17:42:13,356 | INFO  | [Driver-SendThread(cn02:24002)] | Socket connection established, initiating session, client: /10.27.132.45:57090, server: cn02/10.27.132.4:24002 | org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:1053)																																																																		
2020-08-03 17:42:13,358 | INFO  | [Driver-SendThread(cn02:24002)] | Session establishment complete on server cn02/10.27.132.4:24002, sessionid = 0x7f043dfb32fddba5, negotiated timeout = 90000 | org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1609)																																																																		
2020-08-03 17:42:13,770 | INFO  | [Driver] | Hashing index keys | org.janusgraph.graphdb.database.IndexSerializer.<init>(IndexSerializer.java:84)																																																																		
2020-08-03 17:42:14,083 | INFO  | [Driver] | Loaded unidentified ReadMarker start time 2020-08-03T09:42:14.065Z into org.janusgraph.diskstorage.log.kcvs.KCVSLog$MessagePuller@53c2150d | org.janusgraph.diskstorage.log.kcvs.KCVSLog$MessagePuller.initializeTimepoint(KCVSLog.java:744)																																																																		
2020-08-03 17:42:14,372 | WARN  | [Driver] | Query requires iterating over all vertices [(~label = meta_graphgraph)]. For better performance, use indexes | org.janusgraph.graphdb.transaction.StandardJanusGraphTx$7.execute(StandardJanusGraphTx.java:1438)																																																																		
2020-08-03 17:42:16,258 | INFO  | [Driver] | Closing master protocol: MasterService | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeMasterService(ConnectionManager.java:2301)																																																																		
2020-08-03 17:42:16,295 | INFO  | [Driver] | Closing zookeeper sessionid=0x7f043dfb32fddba5 | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeZooKeeperWatcher(ConnectionManager.java:1765)																																																																		
2020-08-03 17:42:16,298 | INFO  | [Driver-EventThread] | EventThread shut down for session: 0x7f043dfb32fddba5 | org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:614)																																																																		
2020-08-03 17:42:16,298 | INFO  | [Driver] | Session: 0x7f043dfb32fddba5 closed | org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:1365)																																																																		
2020-08-03 17:42:16,311 | INFO  | [Driver] | clear hbaseStoreManger connection | org.janusgraph.diskstorage.hbase.HBaseStoreManager.close(HBaseStoreManager.java:424)																																																																		
2020-08-03 17:42:16,318 | INFO  | [Driver] | standardjanusgraph[hbase:[cn01, cn03, cn02]] with id: 0a1b842d221889-dn371 closed | org.janusgraph.graphdb.database.StandardJanusGraph.closeInternal(StandardJanusGraph.java:261)																																																																		
2020-08-03 17:42:16,447 | INFO  | [Driver] | Start to check mapping rule with graph schema. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:16,480 | INFO  | [Driver] | userInfo: su_graph_pro | com.huawei.graph.security.LDAPUserInfoUtils.hasPrivilege(LDAPUserInfoUtils.java:76)																																																																		
2020-08-03 17:42:16,480 | INFO  | [Driver] | groupRole: ADMIN | com.huawei.graph.security.LDAPUserInfoUtils.hasPrivilege(LDAPUserInfoUtils.java:78)																																																																		
2020-08-03 17:42:16,503 | INFO  | [Driver] | HBase configuration: setting hbase.zookeeper.property.clientPort=24002 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:325)																																																																		
2020-08-03 17:42:16,503 | INFO  | [Driver] | Copied host list from root.storage.hostname to hbase.zookeeper.quorum: cn01,cn03,cn02 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:336)																																																																		
2020-08-03 17:42:16,504 | INFO  | [Driver] | Process identifier=hconnection-0x17221234 connecting to ZooKeeper ensemble=cn01:24002,cn03:24002,cn02:24002 | org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:146)																																																																		
2020-08-03 17:42:16,504 | INFO  | [Driver] | Initiating client connection, connectString=cn01:24002,cn03:24002,cn02:24002 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@1fb366da | org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:865)																																																																		
2020-08-03 17:42:16,505 | INFO  | [Driver] | zookeeper.request.timeout is not configured. Using default value 120000. | org.apache.zookeeper.ClientCnxn.initRequestTimeout(ClientCnxn.java:150)																																																																		
2020-08-03 17:42:16,506 | INFO  | [Driver] | zookeeper.client.bind.port.range is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindingPort(ClientCnxn.java:177)																																																																		
2020-08-03 17:42:16,506 | INFO  | [Driver] | zookeeper.client.bind.address is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindAddress(ClientCnxn.java:194)																																																																		
2020-08-03 17:42:16,513 | INFO  | [Driver-SendThread(cn01:24002)] | connecting to cn01 24002 | org.apache.zookeeper.client.FourLetterWordMain.send4LetterWord(FourLetterWordMain.java:126)																																																																		
2020-08-03 17:42:16,515 | INFO  | [Driver-SendThread(cn01:24002)] | Got server principal from the server and it is zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1184)																																																																		
2020-08-03 17:42:16,515 | INFO  | [Driver-SendThread(cn01:24002)] | Using server principal zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1226)																																																																		
2020-08-03 17:42:16,529 | INFO  | [Driver-SendThread(cn01:24002)] | successfully logged in. | org.apache.zookeeper.Login.login(Login.java:310)																																																																		
2020-08-03 17:42:16,530 | INFO  | [Driver-SendThread(cn01:24002)] | Client will use GSSAPI as SASL mechanism. | org.apache.zookeeper.client.ZooKeeperSaslClient$1.run(ZooKeeperSaslClient.java:327)																																																																		
2020-08-03 17:42:16,530 | INFO  | [Thread-97] | TGT refresh thread started. | org.apache.zookeeper.Login$1.run(Login.java:139)																																																																		
2020-08-03 17:42:16,533 | INFO  | [Thread-97] | TGT valid starting at:        Mon Aug 03 17:42:16 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:328)																																																																		
2020-08-03 17:42:16,533 | INFO  | [Thread-97] | TGT expires:                  Tue Aug 04 17:42:16 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:329)																																																																		
2020-08-03 17:42:16,533 | INFO  | [Thread-97] | TGT refresh sleeping until: Tue Aug 04 13:59:52 CST 2020 | org.apache.zookeeper.Login$1.run(Login.java:193)																																																																		
2020-08-03 17:42:16,534 | INFO  | [Driver-SendThread(cn01:24002)] | Opening socket connection to server cn01/10.27.132.3:24002. Will attempt to SASL-authenticate using Login Context section 'Client' | org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1331)																																																																		
2020-08-03 17:42:16,536 | INFO  | [Driver-SendThread(cn01:24002)] | Socket connection established, initiating session, client: /10.27.132.45:41826, server: cn01/10.27.132.3:24002 | org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:1053)																																																																		
2020-08-03 17:42:16,555 | INFO  | [Driver-SendThread(cn01:24002)] | Session establishment complete on server cn01/10.27.132.3:24002, sessionid = 0x7e03be14a6a3c812, negotiated timeout = 90000 | org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1609)																																																																		
2020-08-03 17:42:16,747 | INFO  | [Driver] | Closing master protocol: MasterService | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeMasterService(ConnectionManager.java:2301)																																																																		
2020-08-03 17:42:16,747 | INFO  | [Driver] | Closing zookeeper sessionid=0x7e03be14a6a3c812 | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeZooKeeperWatcher(ConnectionManager.java:1765)																																																																		
2020-08-03 17:42:16,756 | INFO  | [Driver-EventThread] | EventThread shut down for session: 0x7e03be14a6a3c812 | org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:614)																																																																		
2020-08-03 17:42:16,756 | INFO  | [Driver] | Session: 0x7e03be14a6a3c812 closed | org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:1365)																																																																		
2020-08-03 17:42:16,768 | INFO  | [Driver] | clear hbaseStoreManger connection | org.janusgraph.diskstorage.hbase.HBaseStoreManager.close(HBaseStoreManager.java:424)																																																																		
2020-08-03 17:42:16,769 | INFO  | [Driver] | Generated unique-instance-id=0a1b842d221889-dn372 | org.janusgraph.graphdb.configuration.GraphDatabaseConfiguration.getOrGenerateUniqueInstanceId(GraphDatabaseConfiguration.java:1728)																																																																		
2020-08-03 17:42:16,798 | INFO  | [Driver] | HBase configuration: setting hbase.zookeeper.property.clientPort=24002 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:325)																																																																		
2020-08-03 17:42:16,798 | INFO  | [Driver] | Copied host list from root.storage.hostname to hbase.zookeeper.quorum: cn01,cn03,cn02 | org.janusgraph.diskstorage.hbase.HBaseStoreManager.<init>(HBaseStoreManager.java:336)																																																																		
2020-08-03 17:42:16,798 | INFO  | [Driver] | Process identifier=hconnection-0x7d80ed1e connecting to ZooKeeper ensemble=cn01:24002,cn03:24002,cn02:24002 | org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.<init>(RecoverableZooKeeper.java:146)																																																																		
2020-08-03 17:42:16,799 | INFO  | [Driver] | Initiating client connection, connectString=cn01:24002,cn03:24002,cn02:24002 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.PendingWatcher@79cb102d | org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:865)																																																																		
2020-08-03 17:42:16,799 | INFO  | [Driver] | zookeeper.request.timeout is not configured. Using default value 120000. | org.apache.zookeeper.ClientCnxn.initRequestTimeout(ClientCnxn.java:150)																																																																		
2020-08-03 17:42:16,800 | INFO  | [Driver] | zookeeper.client.bind.port.range is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindingPort(ClientCnxn.java:177)																																																																		
2020-08-03 17:42:16,800 | INFO  | [Driver] | zookeeper.client.bind.address is not configured. | org.apache.zookeeper.ClientCnxn.initClientBindAddress(ClientCnxn.java:194)																																																																		
2020-08-03 17:42:16,802 | INFO  | [Driver-SendThread(cn02:24002)] | connecting to cn02 24002 | org.apache.zookeeper.client.FourLetterWordMain.send4LetterWord(FourLetterWordMain.java:126)																																																																		
2020-08-03 17:42:16,805 | INFO  | [Driver-SendThread(cn02:24002)] | Got server principal from the server and it is zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1184)																																																																		
2020-08-03 17:42:16,805 | INFO  | [Driver-SendThread(cn02:24002)] | Using server principal zookeeper/hadoop.hadoop.com | org.apache.zookeeper.ClientCnxn$SendThread.getServerPrincipalName(ClientCnxn.java:1226)																																																																		
2020-08-03 17:42:16,818 | INFO  | [Driver-SendThread(cn02:24002)] | successfully logged in. | org.apache.zookeeper.Login.login(Login.java:310)																																																																		
2020-08-03 17:42:16,819 | INFO  | [Driver-SendThread(cn02:24002)] | Client will use GSSAPI as SASL mechanism. | org.apache.zookeeper.client.ZooKeeperSaslClient$1.run(ZooKeeperSaslClient.java:327)																																																																		
2020-08-03 17:42:16,819 | INFO  | [Thread-101] | TGT refresh thread started. | org.apache.zookeeper.Login$1.run(Login.java:139)																																																																		
2020-08-03 17:42:16,823 | INFO  | [Thread-101] | TGT valid starting at:        Mon Aug 03 17:42:16 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:328)																																																																		
2020-08-03 17:42:16,823 | INFO  | [Thread-101] | TGT expires:                  Tue Aug 04 17:42:16 CST 2020 | org.apache.zookeeper.Login.getRefreshTime(Login.java:329)																																																																		
2020-08-03 17:42:16,823 | INFO  | [Thread-101] | TGT refresh sleeping until: Tue Aug 04 13:03:31 CST 2020 | org.apache.zookeeper.Login$1.run(Login.java:193)																																																																		
2020-08-03 17:42:16,824 | INFO  | [Driver-SendThread(cn02:24002)] | Opening socket connection to server cn02/10.27.132.4:24002. Will attempt to SASL-authenticate using Login Context section 'Client' | org.apache.zookeeper.ClientCnxn$SendThread.logStartConnect(ClientCnxn.java:1331)																																																																		
2020-08-03 17:42:16,826 | INFO  | [Driver-SendThread(cn02:24002)] | Socket connection established, initiating session, client: /10.27.132.45:57194, server: cn02/10.27.132.4:24002 | org.apache.zookeeper.ClientCnxn$SendThread.primeConnection(ClientCnxn.java:1053)																																																																		
2020-08-03 17:42:16,828 | INFO  | [Driver-SendThread(cn02:24002)] | Session establishment complete on server cn02/10.27.132.4:24002, sessionid = 0x7f043dfb32fddba6, negotiated timeout = 90000 | org.apache.zookeeper.ClientCnxn$SendThread.onConnected(ClientCnxn.java:1609)																																																																		
2020-08-03 17:42:16,892 | INFO  | [Driver] | Configuring index [search] | org.janusgraph.diskstorage.Backend.getIndexes(Backend.java:474)																																																																		
2020-08-03 17:42:16,927 | INFO  | [Driver] | esSecConfig is true | org.elasticsearch.client.RestClientBuilder.refreshSecureMode(RestClientBuilder.java:165)																																																																		
2020-08-03 17:42:16,927 | INFO  | [Driver] | systemSecConfig is true | org.elasticsearch.client.RestClientBuilder.refreshSecureMode(RestClientBuilder.java:166)																																																																		
2020-08-03 17:42:16,930 | INFO  | [Driver] | esSecConfig is true | org.elasticsearch.client.RestClientBuilder.refreshSecureMode(RestClientBuilder.java:165)																																																																		
2020-08-03 17:42:16,930 | INFO  | [Driver] | systemSecConfig is true | org.elasticsearch.client.RestClientBuilder.refreshSecureMode(RestClientBuilder.java:166)																																																																		
2020-08-03 17:42:16,930 | INFO  | [Driver] | isSecureMode is true | org.elasticsearch.client.RestClientBuilder.<init>(RestClientBuilder.java:190)																																																																		
2020-08-03 17:42:16,931 | INFO  | [Driver] | esSecConfig is true | org.elasticsearch.client.RestClientBuilder.refreshSecureMode(RestClientBuilder.java:165)																																																																		
2020-08-03 17:42:16,932 | INFO  | [Driver] | systemSecConfig is true | org.elasticsearch.client.RestClientBuilder.refreshSecureMode(RestClientBuilder.java:166)																																																																		
2020-08-03 17:42:17,060 | INFO  | [Driver] | JDK version is SUN | org.elasticsearch.client.RestClientBuilder.getTGT(RestClientBuilder.java:470)																																																																		
2020-08-03 17:42:17,074 | INFO  | [Driver] | Get kerberos TGT successfully. | org.elasticsearch.client.RestClientBuilder.getTGT(RestClientBuilder.java:481)																																																																		
2020-08-03 17:42:17,077 | INFO  | [pool-30-thread-1] | TGT refresh thread statrted | org.elasticsearch.client.RestClientBuilder$RefreshTgtThread.run(RestClientBuilder.java:611)																																																																		
2020-08-03 17:42:17,081 | INFO  | [pool-30-thread-1] | TGT valid starting at:        Mon Aug 03 17:42:17 CST 2020 | org.elasticsearch.client.RestClientBuilder.getRefreshTime(RestClientBuilder.java:545)																																																																		
2020-08-03 17:42:17,081 | INFO  | [pool-30-thread-1] | TGT expires:                  Tue Aug 04 17:42:17 CST 2020 | org.elasticsearch.client.RestClientBuilder.getRefreshTime(RestClientBuilder.java:546)																																																																		
2020-08-03 17:42:17,081 | INFO  | [pool-30-thread-1] | TGT refresh sleeping until: Tue Aug 04 13:18:38 CST 2020 | org.elasticsearch.client.RestClientBuilder$RefreshTgtThread.run(RestClientBuilder.java:618)																																																																		
2020-08-03 17:42:17,240 | INFO  | [Driver] | Success to get the service realm elasticsearch/hadoop.hadoop.com@HADOOP.COM | org.elasticsearch.client.RestClientBuilder.getServerRealm(RestClientBuilder.java:785)																																																																		
2020-08-03 17:42:17,240 | INFO  | [Driver] | Initialize the client successfully. | org.elasticsearch.client.RestClientBuilder.authenticate(RestClientBuilder.java:604)																																																																		
2020-08-03 17:42:18,307 | INFO  | [Driver] | Hashing index keys | org.janusgraph.graphdb.database.IndexSerializer.<init>(IndexSerializer.java:84)																																																																		
2020-08-03 17:42:18,392 | INFO  | [Driver] | Loaded unidentified ReadMarker start time 2020-08-03T09:42:18.392Z into org.janusgraph.diskstorage.log.kcvs.KCVSLog$MessagePuller@6d34d423 | org.janusgraph.diskstorage.log.kcvs.KCVSLog$MessagePuller.initializeTimepoint(KCVSLog.java:744)																																																																		
2020-08-03 17:42:18,730 | INFO  | [Driver] | skip CarbonOptimizer | org.apache.spark.sql.optimizer.CarbonLateDecodeRule.checkIfRuleNeedToBeApplied(CarbonLateDecodeRule.scala:95)																																																																		
2020-08-03 17:42:18,730 | INFO  | [Driver] | skip CarbonOptimizer | org.apache.spark.sql.optimizer.CarbonLateDecodeRule.checkIfRuleNeedToBeApplied(CarbonLateDecodeRule.scala:95)																																																																		
2020-08-03 17:42:18,731 | INFO  | [Driver] | Skip CarbonOptimizer | org.apache.spark.sql.optimizer.CarbonLateDecodeRule.apply(CarbonLateDecodeRule.scala:72)																																																																		
2020-08-03 17:42:18,810 | INFO  | [Driver] | Starting job: collect at GraphWriter.scala:537 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,013 | INFO  | [dag-scheduler-event-loop] | Registering RDD 17 (distinct at GraphWriter.scala:537) as input to shuffle 0 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,015 | INFO  | [dag-scheduler-event-loop] | Got job 4 (collect at GraphWriter.scala:537) with 90 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,015 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 5 (collect at GraphWriter.scala:537) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,015 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List(ShuffleMapStage 4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,017 | INFO  | [dag-scheduler-event-loop] | Missing parents: List(ShuffleMapStage 4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,021 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at distinct at GraphWriter.scala:537), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,114 | INFO  | [dag-scheduler-event-loop] | Block broadcast_6 stored as values in memory (estimated size 31.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,119 | INFO  | [dag-scheduler-event-loop] | Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,120 | INFO  | [dispatcher-event-loop-16] | Added broadcast_6_piece0 in memory on dn37:22779 (size: 10.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,121 | INFO  | [dag-scheduler-event-loop] | Created broadcast 6 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,125 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at distinct at GraphWriter.scala:537) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,126 | INFO  | [dag-scheduler-event-loop] | Adding task set 4.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,645 | INFO  | [dispatcher-event-loop-4] | Starting task 6.0 in stage 4.0 (TID 4, dn29, executor 1, partition 6, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,646 | INFO  | [dispatcher-event-loop-4] | Starting task 21.0 in stage 4.0 (TID 5, dn19, executor 11, partition 21, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,648 | INFO  | [dispatcher-event-loop-4] | Starting task 1.0 in stage 4.0 (TID 6, dn22, executor 5, partition 1, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,649 | INFO  | [dispatcher-event-loop-4] | Starting task 0.0 in stage 4.0 (TID 7, dn36, executor 20, partition 0, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,650 | INFO  | [dispatcher-event-loop-4] | Starting task 2.0 in stage 4.0 (TID 8, dn17, executor 18, partition 2, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,651 | INFO  | [dispatcher-event-loop-4] | Starting task 16.0 in stage 4.0 (TID 9, dn30, executor 2, partition 16, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,652 | INFO  | [dispatcher-event-loop-4] | Starting task 20.0 in stage 4.0 (TID 10, dn16, executor 15, partition 20, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,653 | INFO  | [dispatcher-event-loop-4] | Starting task 11.0 in stage 4.0 (TID 11, dn07, executor 14, partition 11, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,653 | INFO  | [dispatcher-event-loop-4] | Starting task 15.0 in stage 4.0 (TID 12, dn28, executor 3, partition 15, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,654 | INFO  | [dispatcher-event-loop-4] | Starting task 8.0 in stage 4.0 (TID 13, dn34, executor 6, partition 8, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,655 | INFO  | [dispatcher-event-loop-4] | Starting task 22.0 in stage 4.0 (TID 14, dn14, executor 17, partition 22, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,656 | INFO  | [dispatcher-event-loop-4] | Starting task 4.0 in stage 4.0 (TID 15, dn24, executor 9, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,657 | INFO  | [dispatcher-event-loop-4] | Starting task 3.0 in stage 4.0 (TID 16, dn18, executor 10, partition 3, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,658 | INFO  | [dispatcher-event-loop-4] | Starting task 10.0 in stage 4.0 (TID 17, dn15, executor 12, partition 10, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,658 | INFO  | [dispatcher-event-loop-4] | Starting task 7.0 in stage 4.0 (TID 18, dn32, executor 4, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,659 | INFO  | [dispatcher-event-loop-4] | Starting task 9.0 in stage 4.0 (TID 19, dn08, executor 16, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,659 | INFO  | [dispatcher-event-loop-4] | Starting task 30.0 in stage 4.0 (TID 20, dn10, executor 19, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,660 | INFO  | [dispatcher-event-loop-4] | Starting task 36.0 in stage 4.0 (TID 21, dn20, executor 13, partition 36, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,660 | INFO  | [dispatcher-event-loop-4] | Starting task 14.0 in stage 4.0 (TID 22, dn27, executor 7, partition 14, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,661 | INFO  | [dispatcher-event-loop-4] | Starting task 43.0 in stage 4.0 (TID 23, dn37, executor 8, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,661 | INFO  | [dispatcher-event-loop-4] | Starting task 23.0 in stage 4.0 (TID 24, dn29, executor 1, partition 23, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,662 | INFO  | [dispatcher-event-loop-4] | Starting task 26.0 in stage 4.0 (TID 25, dn19, executor 11, partition 26, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,662 | INFO  | [dispatcher-event-loop-4] | Starting task 5.0 in stage 4.0 (TID 26, dn22, executor 5, partition 5, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,663 | INFO  | [dispatcher-event-loop-4] | Starting task 12.0 in stage 4.0 (TID 27, dn36, executor 20, partition 12, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,663 | INFO  | [dispatcher-event-loop-4] | Starting task 17.0 in stage 4.0 (TID 28, dn17, executor 18, partition 17, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,664 | INFO  | [dispatcher-event-loop-4] | Starting task 28.0 in stage 4.0 (TID 29, dn30, executor 2, partition 28, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,664 | INFO  | [dispatcher-event-loop-4] | Starting task 13.0 in stage 4.0 (TID 30, dn07, executor 14, partition 13, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,665 | INFO  | [dispatcher-event-loop-4] | Starting task 38.0 in stage 4.0 (TID 31, dn28, executor 3, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,665 | INFO  | [dispatcher-event-loop-4] | Starting task 27.0 in stage 4.0 (TID 32, dn34, executor 6, partition 27, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,666 | INFO  | [dispatcher-event-loop-4] | Starting task 24.0 in stage 4.0 (TID 33, dn14, executor 17, partition 24, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,666 | INFO  | [dispatcher-event-loop-4] | Starting task 48.0 in stage 4.0 (TID 34, dn24, executor 9, partition 48, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,667 | INFO  | [dispatcher-event-loop-4] | Starting task 33.0 in stage 4.0 (TID 35, dn18, executor 10, partition 33, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,667 | INFO  | [dispatcher-event-loop-4] | Starting task 46.0 in stage 4.0 (TID 36, dn15, executor 12, partition 46, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,667 | INFO  | [dispatcher-event-loop-4] | Starting task 40.0 in stage 4.0 (TID 37, dn32, executor 4, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,668 | INFO  | [dispatcher-event-loop-4] | Starting task 80.0 in stage 4.0 (TID 38, dn08, executor 16, partition 80, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,668 | INFO  | [dispatcher-event-loop-4] | Starting task 31.0 in stage 4.0 (TID 39, dn10, executor 19, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,668 | INFO  | [dispatcher-event-loop-4] | Starting task 37.0 in stage 4.0 (TID 40, dn20, executor 13, partition 37, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,669 | INFO  | [dispatcher-event-loop-4] | Starting task 19.0 in stage 4.0 (TID 41, dn27, executor 7, partition 19, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,669 | INFO  | [dispatcher-event-loop-4] | Starting task 55.0 in stage 4.0 (TID 42, dn37, executor 8, partition 55, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,766 | INFO  | [dispatcher-event-loop-41] | Added broadcast_6_piece0 in memory on dn22:22834 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,768 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 84 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,769 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 95 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,770 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 86 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,771 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 90 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,771 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 98 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,771 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 91 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,772 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 83 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,772 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 100 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,772 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 85 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,776 | INFO  | [dispatcher-event-loop-50] | Added broadcast_6_piece0 in memory on dn27:22790 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,777 | INFO  | [dispatcher-event-loop-50] | Removed broadcast_5_piece0 on dn37:22779 in memory (size: 8.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,778 | INFO  | [dispatcher-event-loop-50] | Removed broadcast_5_piece0 on dn27:22790 in memory (size: 8.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,783 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 80 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,784 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 99 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,784 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 82 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,784 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 93 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,784 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 78 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,784 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 87 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 89 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 97 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 96 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 94 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 75 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 76 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,785 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 81 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,786 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 77 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,786 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 88 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,786 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 92 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,786 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 79 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,994 | INFO  | [dispatcher-event-loop-12] | Added broadcast_6_piece0 in memory on dn24:22839 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:19,995 | INFO  | [dispatcher-event-loop-12] | Added broadcast_6_piece0 in memory on dn16:22668 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,001 | INFO  | [dispatcher-event-loop-9] | Added broadcast_6_piece0 in memory on dn15:22640 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,020 | INFO  | [dispatcher-event-loop-15] | Added broadcast_6_piece0 in memory on dn37:22861 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,035 | INFO  | [dispatcher-event-loop-10] | Added broadcast_6_piece0 in memory on dn19:22830 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,053 | INFO  | [dispatcher-event-loop-4] | Added broadcast_6_piece0 in memory on dn32:22787 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,054 | INFO  | [dispatcher-event-loop-4] | Added broadcast_6_piece0 in memory on dn34:22620 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,055 | INFO  | [dispatcher-event-loop-4] | Added broadcast_6_piece0 in memory on dn14:22891 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,056 | INFO  | [dispatcher-event-loop-4] | Added broadcast_6_piece0 in memory on dn20:22825 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,057 | INFO  | [dispatcher-event-loop-4] | Added broadcast_6_piece0 in memory on dn08:22604 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,058 | INFO  | [dispatcher-event-loop-14] | Added broadcast_6_piece0 in memory on dn07:22897 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,070 | INFO  | [dispatcher-event-loop-18] | Added broadcast_6_piece0 in memory on dn36:22756 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,081 | INFO  | [dispatcher-event-loop-31] | Added broadcast_3_piece0 in memory on dn22:22834 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,110 | INFO  | [dispatcher-event-loop-20] | Added broadcast_6_piece0 in memory on dn10:22719 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,111 | INFO  | [dispatcher-event-loop-30] | Added broadcast_6_piece0 in memory on dn28:22784 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,115 | INFO  | [dispatcher-event-loop-24] | Added broadcast_6_piece0 in memory on dn17:22761 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,116 | INFO  | [dispatcher-event-loop-24] | Added broadcast_6_piece0 in memory on dn30:22608 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,121 | INFO  | [dispatcher-event-loop-32] | Added broadcast_6_piece0 in memory on dn18:22756 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,130 | INFO  | [dispatcher-event-loop-21] | Added broadcast_6_piece0 in memory on dn29:22705 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,365 | INFO  | [dispatcher-event-loop-26] | Added broadcast_3_piece0 in memory on dn15:22640 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,371 | INFO  | [dispatcher-event-loop-39] | Added broadcast_3_piece0 in memory on dn16:22668 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,432 | INFO  | [dispatcher-event-loop-56] | Added broadcast_3_piece0 in memory on dn37:22861 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,434 | INFO  | [dispatcher-event-loop-34] | Added broadcast_3_piece0 in memory on dn32:22787 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,435 | INFO  | [dispatcher-event-loop-41] | Added broadcast_3_piece0 in memory on dn34:22620 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,450 | INFO  | [dispatcher-event-loop-35] | Added broadcast_3_piece0 in memory on dn36:22756 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,464 | INFO  | [dispatcher-event-loop-52] | Added broadcast_3_piece0 in memory on dn08:22604 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,522 | INFO  | [dispatcher-event-loop-64] | Added broadcast_3_piece0 in memory on dn18:22756 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,524 | INFO  | [dispatcher-event-loop-59] | Added broadcast_3_piece0 in memory on dn24:22839 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,527 | INFO  | [dispatcher-event-loop-63] | Added broadcast_3_piece0 in memory on dn07:22897 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,528 | INFO  | [dispatcher-event-loop-63] | Added broadcast_3_piece0 in memory on dn19:22830 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,530 | INFO  | [dispatcher-event-loop-62] | Added broadcast_3_piece0 in memory on dn20:22825 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,532 | INFO  | [dispatcher-event-loop-67] | Added broadcast_3_piece0 in memory on dn14:22891 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,534 | INFO  | [dispatcher-event-loop-70] | Added broadcast_3_piece0 in memory on dn17:22761 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,583 | INFO  | [dispatcher-event-loop-55] | Added broadcast_3_piece0 in memory on dn29:22705 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,601 | INFO  | [dispatcher-event-loop-54] | Added broadcast_3_piece0 in memory on dn28:22784 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,605 | INFO  | [dispatcher-event-loop-65] | Added broadcast_3_piece0 in memory on dn10:22719 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:20,718 | INFO  | [dispatcher-event-loop-61] | Added broadcast_3_piece0 in memory on dn30:22608 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:22,679 | INFO  | [dispatcher-event-loop-2] | Starting task 18.0 in stage 4.0 (TID 43, dn16, executor 15, partition 18, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:30,924 | INFO  | [dispatcher-event-loop-51] | Starting task 47.0 in stage 4.0 (TID 44, dn27, executor 7, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:30,931 | INFO  | [task-result-getter-0] | Finished task 14.0 in stage 4.0 (TID 22) in 11271 ms on dn27 (executor 7) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:31,007 | INFO  | [dispatcher-event-loop-52] | Starting task 52.0 in stage 4.0 (TID 45, dn27, executor 7, partition 52, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:31,008 | INFO  | [task-result-getter-1] | Finished task 19.0 in stage 4.0 (TID 41) in 11339 ms on dn27 (executor 7) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,347 | INFO  | [dispatcher-event-loop-62] | Starting task 44.0 in stage 4.0 (TID 46, dn22, executor 5, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,348 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 4.0 (TID 26) in 12685 ms on dn22 (executor 5) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,461 | INFO  | [dispatcher-event-loop-54] | Starting task 45.0 in stage 4.0 (TID 47, dn22, executor 5, partition 45, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,462 | INFO  | [task-result-getter-3] | Finished task 1.0 in stage 4.0 (TID 6) in 12815 ms on dn22 (executor 5) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,749 | INFO  | [dispatcher-event-loop-61] | Starting task 25.0 in stage 4.0 (TID 48, dn14, executor 17, partition 25, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,750 | INFO  | [task-result-getter-0] | Finished task 22.0 in stage 4.0 (TID 14) in 13095 ms on dn14 (executor 17) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,751 | INFO  | [dispatcher-event-loop-61] | Starting task 54.0 in stage 4.0 (TID 49, dn14, executor 17, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,752 | INFO  | [task-result-getter-1] | Finished task 24.0 in stage 4.0 (TID 33) in 13086 ms on dn14 (executor 17) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,797 | INFO  | [task-result-getter-2] | Finished task 20.0 in stage 4.0 (TID 10) in 13146 ms on dn16 (executor 15) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,963 | INFO  | [dispatcher-event-loop-0] | Starting task 58.0 in stage 4.0 (TID 50, dn32, executor 4, partition 58, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,964 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 4.0 (TID 18) in 13306 ms on dn32 (executor 4) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,971 | INFO  | [task-result-getter-0] | Finished task 18.0 in stage 4.0 (TID 43) in 10294 ms on dn16 (executor 15) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,994 | INFO  | [dispatcher-event-loop-8] | Starting task 29.0 in stage 4.0 (TID 51, dn17, executor 18, partition 29, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:32,996 | INFO  | [task-result-getter-1] | Finished task 17.0 in stage 4.0 (TID 28) in 13333 ms on dn17 (executor 18) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,032 | INFO  | [dispatcher-event-loop-1] | Starting task 81.0 in stage 4.0 (TID 52, dn08, executor 16, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,032 | INFO  | [task-result-getter-2] | Finished task 9.0 in stage 4.0 (TID 19) in 13374 ms on dn08 (executor 16) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,076 | INFO  | [dispatcher-event-loop-2] | Starting task 53.0 in stage 4.0 (TID 53, dn19, executor 11, partition 53, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,077 | INFO  | [task-result-getter-3] | Finished task 21.0 in stage 4.0 (TID 5) in 13432 ms on dn19 (executor 11) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,143 | INFO  | [dispatcher-event-loop-9] | Starting task 79.0 in stage 4.0 (TID 54, dn20, executor 13, partition 79, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,144 | INFO  | [dispatcher-event-loop-9] | Starting task 82.0 in stage 4.0 (TID 55, dn20, executor 13, partition 82, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,144 | INFO  | [task-result-getter-0] | Finished task 37.0 in stage 4.0 (TID 40) in 13476 ms on dn20 (executor 13) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,145 | INFO  | [task-result-getter-1] | Finished task 36.0 in stage 4.0 (TID 21) in 13486 ms on dn20 (executor 13) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,184 | INFO  | [task-result-getter-2] | Finished task 40.0 in stage 4.0 (TID 37) in 13517 ms on dn32 (executor 4) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,201 | INFO  | [task-result-getter-3] | Finished task 80.0 in stage 4.0 (TID 38) in 13533 ms on dn08 (executor 16) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,207 | INFO  | [dispatcher-event-loop-4] | Starting task 75.0 in stage 4.0 (TID 56, dn28, executor 3, partition 75, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,208 | INFO  | [task-result-getter-0] | Finished task 15.0 in stage 4.0 (TID 12) in 13555 ms on dn28 (executor 3) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,264 | INFO  | [dispatcher-event-loop-18] | Starting task 32.0 in stage 4.0 (TID 57, dn34, executor 6, partition 32, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,266 | INFO  | [task-result-getter-1] | Finished task 27.0 in stage 4.0 (TID 32) in 13601 ms on dn34 (executor 6) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,291 | INFO  | [dispatcher-event-loop-20] | Starting task 77.0 in stage 4.0 (TID 58, dn15, executor 12, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,291 | INFO  | [task-result-getter-2] | Finished task 10.0 in stage 4.0 (TID 17) in 13634 ms on dn15 (executor 12) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,315 | INFO  | [dispatcher-event-loop-22] | Starting task 59.0 in stage 4.0 (TID 59, dn19, executor 11, partition 59, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,316 | INFO  | [task-result-getter-3] | Finished task 26.0 in stage 4.0 (TID 25) in 13655 ms on dn19 (executor 11) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,318 | INFO  | [dispatcher-event-loop-24] | Starting task 83.0 in stage 4.0 (TID 60, dn15, executor 12, partition 83, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,319 | INFO  | [task-result-getter-0] | Finished task 46.0 in stage 4.0 (TID 36) in 13652 ms on dn15 (executor 12) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,346 | INFO  | [task-result-getter-1] | Finished task 38.0 in stage 4.0 (TID 31) in 13681 ms on dn28 (executor 3) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,351 | INFO  | [dispatcher-event-loop-13] | Starting task 64.0 in stage 4.0 (TID 61, dn17, executor 18, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,352 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 4.0 (TID 8) in 13702 ms on dn17 (executor 18) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,406 | INFO  | [dispatcher-event-loop-26] | Starting task 78.0 in stage 4.0 (TID 62, dn18, executor 10, partition 78, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,406 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 4.0 (TID 16) in 13749 ms on dn18 (executor 10) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,508 | INFO  | [dispatcher-event-loop-23] | Starting task 42.0 in stage 4.0 (TID 63, dn34, executor 6, partition 42, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,509 | INFO  | [task-result-getter-0] | Finished task 8.0 in stage 4.0 (TID 13) in 13855 ms on dn34 (executor 6) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,521 | INFO  | [dispatcher-event-loop-36] | Starting task 88.0 in stage 4.0 (TID 64, dn24, executor 9, partition 88, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,522 | INFO  | [task-result-getter-1] | Finished task 48.0 in stage 4.0 (TID 34) in 13856 ms on dn24 (executor 9) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,544 | INFO  | [task-result-getter-2] | Finished task 55.0 in stage 4.0 (TID 42) in 13875 ms on dn37 (executor 8) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,545 | INFO  | [task-result-getter-3] | Finished task 43.0 in stage 4.0 (TID 23) in 13885 ms on dn37 (executor 8) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,559 | INFO  | [dispatcher-event-loop-44] | Starting task 84.0 in stage 4.0 (TID 65, dn18, executor 10, partition 84, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,559 | INFO  | [task-result-getter-0] | Finished task 33.0 in stage 4.0 (TID 35) in 13892 ms on dn18 (executor 10) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,560 | INFO  | [dispatcher-event-loop-44] | Starting task 76.0 in stage 4.0 (TID 66, dn07, executor 14, partition 76, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,561 | INFO  | [task-result-getter-1] | Finished task 11.0 in stage 4.0 (TID 11) in 13909 ms on dn07 (executor 14) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,626 | INFO  | [dispatcher-event-loop-43] | Starting task 89.0 in stage 4.0 (TID 67, dn24, executor 9, partition 89, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,627 | INFO  | [task-result-getter-2] | Finished task 4.0 in stage 4.0 (TID 15) in 13972 ms on dn24 (executor 9) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,642 | INFO  | [task-result-getter-3] | Finished task 13.0 in stage 4.0 (TID 30) in 13978 ms on dn07 (executor 14) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,806 | INFO  | [task-result-getter-0] | Finished task 31.0 in stage 4.0 (TID 39) in 14137 ms on dn10 (executor 19) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,820 | INFO  | [dispatcher-event-loop-46] | Starting task 56.0 in stage 4.0 (TID 68, dn29, executor 1, partition 56, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,821 | INFO  | [task-result-getter-1] | Finished task 23.0 in stage 4.0 (TID 24) in 14160 ms on dn29 (executor 1) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,863 | INFO  | [task-result-getter-2] | Finished task 30.0 in stage 4.0 (TID 20) in 14204 ms on dn10 (executor 19) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,976 | INFO  | [dispatcher-event-loop-49] | Starting task 68.0 in stage 4.0 (TID 69, dn36, executor 20, partition 68, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:33,976 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 4.0 (TID 7) in 14327 ms on dn36 (executor 20) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,012 | INFO  | [dispatcher-event-loop-53] | Starting task 50.0 in stage 4.0 (TID 70, dn30, executor 2, partition 50, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,013 | INFO  | [task-result-getter-0] | Finished task 28.0 in stage 4.0 (TID 29) in 14349 ms on dn30 (executor 2) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,073 | INFO  | [dispatcher-event-loop-64] | Starting task 51.0 in stage 4.0 (TID 71, dn30, executor 2, partition 51, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,074 | INFO  | [task-result-getter-1] | Finished task 16.0 in stage 4.0 (TID 9) in 14424 ms on dn30 (executor 2) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,132 | INFO  | [task-result-getter-2] | Finished task 12.0 in stage 4.0 (TID 27) in 14470 ms on dn36 (executor 20) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,470 | INFO  | [dispatcher-event-loop-63] | Starting task 57.0 in stage 4.0 (TID 72, dn29, executor 1, partition 57, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:34,471 | INFO  | [task-result-getter-3] | Finished task 6.0 in stage 4.0 (TID 4) in 14830 ms on dn29 (executor 1) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,674 | INFO  | [dispatcher-event-loop-9] | Starting task 34.0 in stage 4.0 (TID 73, dn37, executor 8, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,675 | INFO  | [dispatcher-event-loop-9] | Starting task 35.0 in stage 4.0 (TID 74, dn10, executor 19, partition 35, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,676 | INFO  | [dispatcher-event-loop-9] | Starting task 39.0 in stage 4.0 (TID 75, dn32, executor 4, partition 39, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,676 | INFO  | [dispatcher-event-loop-9] | Starting task 41.0 in stage 4.0 (TID 76, dn28, executor 3, partition 41, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,677 | INFO  | [dispatcher-event-loop-9] | Starting task 49.0 in stage 4.0 (TID 77, dn08, executor 16, partition 49, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,678 | INFO  | [dispatcher-event-loop-9] | Starting task 60.0 in stage 4.0 (TID 78, dn36, executor 20, partition 60, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,679 | INFO  | [dispatcher-event-loop-9] | Starting task 61.0 in stage 4.0 (TID 79, dn07, executor 14, partition 61, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,679 | INFO  | [dispatcher-event-loop-9] | Starting task 62.0 in stage 4.0 (TID 80, dn16, executor 15, partition 62, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,680 | INFO  | [dispatcher-event-loop-9] | Starting task 63.0 in stage 4.0 (TID 81, dn37, executor 8, partition 63, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,681 | INFO  | [dispatcher-event-loop-9] | Starting task 65.0 in stage 4.0 (TID 82, dn10, executor 19, partition 65, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:37,681 | INFO  | [dispatcher-event-loop-9] | Starting task 66.0 in stage 4.0 (TID 83, dn16, executor 15, partition 66, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:40,330 | INFO  | [dispatcher-event-loop-13] | Starting task 67.0 in stage 4.0 (TID 84, dn27, executor 7, partition 67, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:40,331 | INFO  | [task-result-getter-0] | Finished task 47.0 in stage 4.0 (TID 44) in 9408 ms on dn27 (executor 7) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:40,487 | INFO  | [dispatcher-event-loop-36] | Starting task 69.0 in stage 4.0 (TID 85, dn27, executor 7, partition 69, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:40,488 | INFO  | [task-result-getter-1] | Finished task 52.0 in stage 4.0 (TID 45) in 9482 ms on dn27 (executor 7) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:40,981 | INFO  | [dispatcher-event-loop-44] | Starting task 70.0 in stage 4.0 (TID 86, dn20, executor 13, partition 70, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:40,982 | INFO  | [task-result-getter-2] | Finished task 79.0 in stage 4.0 (TID 54) in 7838 ms on dn20 (executor 13) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,256 | INFO  | [dispatcher-event-loop-56] | Starting task 72.0 in stage 4.0 (TID 87, dn14, executor 17, partition 72, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,257 | INFO  | [task-result-getter-3] | Finished task 25.0 in stage 4.0 (TID 48) in 8509 ms on dn14 (executor 17) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,362 | INFO  | [dispatcher-event-loop-41] | Starting task 85.0 in stage 4.0 (TID 88, dn17, executor 18, partition 85, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,363 | INFO  | [task-result-getter-0] | Finished task 29.0 in stage 4.0 (TID 51) in 8370 ms on dn17 (executor 18) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,375 | INFO  | [task-result-getter-1] | Finished task 81.0 in stage 4.0 (TID 52) in 8344 ms on dn08 (executor 16) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,417 | INFO  | [task-result-getter-2] | Finished task 82.0 in stage 4.0 (TID 55) in 8273 ms on dn20 (executor 13) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,496 | INFO  | [task-result-getter-3] | Finished task 54.0 in stage 4.0 (TID 49) in 8746 ms on dn14 (executor 17) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,555 | INFO  | [dispatcher-event-loop-66] | Starting task 86.0 in stage 4.0 (TID 89, dn15, executor 12, partition 86, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,556 | INFO  | [task-result-getter-0] | Finished task 83.0 in stage 4.0 (TID 60) in 8238 ms on dn15 (executor 12) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,706 | INFO  | [task-result-getter-1] | Finished task 58.0 in stage 4.0 (TID 50) in 8744 ms on dn32 (executor 4) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,779 | INFO  | [task-result-getter-2] | Finished task 77.0 in stage 4.0 (TID 58) in 8488 ms on dn15 (executor 12) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,866 | INFO  | [task-result-getter-3] | Finished task 64.0 in stage 4.0 (TID 61) in 8515 ms on dn17 (executor 18) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,977 | INFO  | [dispatcher-event-loop-50] | Starting task 71.0 in stage 4.0 (TID 90, dn34, executor 6, partition 71, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,978 | INFO  | [task-result-getter-0] | Finished task 32.0 in stage 4.0 (TID 57) in 8714 ms on dn34 (executor 6) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:41,995 | INFO  | [task-result-getter-1] | Finished task 78.0 in stage 4.0 (TID 62) in 8590 ms on dn18 (executor 10) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,092 | INFO  | [task-result-getter-2] | Finished task 42.0 in stage 4.0 (TID 63) in 8584 ms on dn34 (executor 6) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,152 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 4.0 (TID 64) in 8631 ms on dn24 (executor 9) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,185 | INFO  | [task-result-getter-0] | Finished task 84.0 in stage 4.0 (TID 65) in 8627 ms on dn18 (executor 10) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,189 | INFO  | [task-result-getter-1] | Finished task 75.0 in stage 4.0 (TID 56) in 8982 ms on dn28 (executor 3) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,200 | INFO  | [dispatcher-event-loop-65] | Starting task 87.0 in stage 4.0 (TID 91, dn19, executor 11, partition 87, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,201 | INFO  | [task-result-getter-2] | Finished task 59.0 in stage 4.0 (TID 59) in 8886 ms on dn19 (executor 11) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,426 | INFO  | [task-result-getter-3] | Finished task 89.0 in stage 4.0 (TID 67) in 8801 ms on dn24 (executor 9) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,499 | INFO  | [task-result-getter-0] | Finished task 68.0 in stage 4.0 (TID 69) in 8524 ms on dn36 (executor 20) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,588 | INFO  | [task-result-getter-1] | Finished task 76.0 in stage 4.0 (TID 66) in 9028 ms on dn07 (executor 14) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,595 | INFO  | [task-result-getter-2] | Finished task 53.0 in stage 4.0 (TID 53) in 9520 ms on dn19 (executor 11) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,764 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 4.0 (TID 71) in 8691 ms on dn30 (executor 2) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,935 | INFO  | [dispatcher-event-loop-1] | Starting task 74.0 in stage 4.0 (TID 92, dn22, executor 5, partition 74, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,935 | INFO  | [task-result-getter-0] | Finished task 44.0 in stage 4.0 (TID 46) in 10589 ms on dn22 (executor 5) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:42,956 | INFO  | [task-result-getter-1] | Finished task 50.0 in stage 4.0 (TID 70) in 8945 ms on dn30 (executor 2) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:43,043 | INFO  | [task-result-getter-2] | Finished task 45.0 in stage 4.0 (TID 47) in 10582 ms on dn22 (executor 5) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:43,398 | INFO  | [dispatcher-event-loop-10] | Starting task 73.0 in stage 4.0 (TID 93, dn29, executor 1, partition 73, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:43,399 | INFO  | [task-result-getter-3] | Finished task 56.0 in stage 4.0 (TID 68) in 9578 ms on dn29 (executor 1) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:43,481 | INFO  | [task-result-getter-0] | Finished task 57.0 in stage 4.0 (TID 72) in 9011 ms on dn29 (executor 1) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,061 | INFO  | [task-result-getter-1] | Finished task 66.0 in stage 4.0 (TID 83) in 8380 ms on dn16 (executor 15) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,062 | INFO  | [task-result-getter-2] | Finished task 62.0 in stage 4.0 (TID 80) in 8383 ms on dn16 (executor 15) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,114 | INFO  | [task-result-getter-3] | Finished task 65.0 in stage 4.0 (TID 82) in 8433 ms on dn10 (executor 19) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,191 | INFO  | [task-result-getter-0] | Finished task 35.0 in stage 4.0 (TID 74) in 8517 ms on dn10 (executor 19) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,444 | INFO  | [task-result-getter-1] | Finished task 63.0 in stage 4.0 (TID 81) in 8763 ms on dn37 (executor 8) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,518 | INFO  | [task-result-getter-2] | Finished task 39.0 in stage 4.0 (TID 75) in 8843 ms on dn32 (executor 4) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,717 | INFO  | [task-result-getter-3] | Finished task 60.0 in stage 4.0 (TID 78) in 9040 ms on dn36 (executor 20) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:46,833 | INFO  | [task-result-getter-0] | Finished task 41.0 in stage 4.0 (TID 76) in 9157 ms on dn28 (executor 3) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:47,074 | INFO  | [task-result-getter-1] | Finished task 34.0 in stage 4.0 (TID 73) in 9401 ms on dn37 (executor 8) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:47,118 | INFO  | [task-result-getter-2] | Finished task 49.0 in stage 4.0 (TID 77) in 9441 ms on dn08 (executor 16) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:47,203 | INFO  | [task-result-getter-3] | Finished task 61.0 in stage 4.0 (TID 79) in 9525 ms on dn07 (executor 14) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:49,625 | INFO  | [task-result-getter-0] | Finished task 70.0 in stage 4.0 (TID 86) in 8645 ms on dn20 (executor 13) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:49,895 | INFO  | [task-result-getter-1] | Finished task 85.0 in stage 4.0 (TID 88) in 8534 ms on dn17 (executor 18) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:50,003 | INFO  | [task-result-getter-2] | Finished task 86.0 in stage 4.0 (TID 89) in 8448 ms on dn15 (executor 12) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:50,427 | INFO  | [task-result-getter-3] | Finished task 72.0 in stage 4.0 (TID 87) in 9171 ms on dn14 (executor 17) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:50,474 | INFO  | [task-result-getter-0] | Finished task 67.0 in stage 4.0 (TID 84) in 10144 ms on dn27 (executor 7) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:50,546 | INFO  | [task-result-getter-1] | Finished task 69.0 in stage 4.0 (TID 85) in 10059 ms on dn27 (executor 7) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:51,106 | INFO  | [task-result-getter-2] | Finished task 87.0 in stage 4.0 (TID 91) in 8906 ms on dn19 (executor 11) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:51,147 | INFO  | [task-result-getter-3] | Finished task 71.0 in stage 4.0 (TID 90) in 9170 ms on dn34 (executor 6) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,830 | INFO  | [task-result-getter-0] | Finished task 74.0 in stage 4.0 (TID 92) in 9895 ms on dn22 (executor 5) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,872 | INFO  | [task-result-getter-1] | Finished task 73.0 in stage 4.0 (TID 93) in 9474 ms on dn29 (executor 1) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,872 | INFO  | [task-result-getter-1] | Removed TaskSet 4.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,873 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 4 (distinct at GraphWriter.scala:537) finished in 33.818 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,875 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,877 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,879 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 5) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,881 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,891 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 5 (MapPartitionsRDD[20] at filter at GraphWriter.scala:537), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,905 | INFO  | [dag-scheduler-event-loop] | Block broadcast_7 stored as values in memory (estimated size 4.4 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,908 | INFO  | [dag-scheduler-event-loop] | Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,909 | INFO  | [dispatcher-event-loop-16] | Added broadcast_7_piece0 in memory on dn37:22779 (size: 2.5 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,910 | INFO  | [dag-scheduler-event-loop] | Created broadcast 7 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,911 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at filter at GraphWriter.scala:537) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,911 | INFO  | [dag-scheduler-event-loop] | Adding task set 5.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,914 | INFO  | [dispatcher-event-loop-25] | Starting task 0.0 in stage 5.0 (TID 94, dn10, executor 19, partition 0, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,914 | INFO  | [dispatcher-event-loop-25] | Starting task 1.0 in stage 5.0 (TID 95, dn24, executor 9, partition 1, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,914 | INFO  | [dispatcher-event-loop-25] | Starting task 2.0 in stage 5.0 (TID 96, dn34, executor 6, partition 2, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,914 | INFO  | [dispatcher-event-loop-25] | Starting task 3.0 in stage 5.0 (TID 97, dn08, executor 16, partition 3, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,915 | INFO  | [dispatcher-event-loop-25] | Starting task 4.0 in stage 5.0 (TID 98, dn19, executor 11, partition 4, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,915 | INFO  | [dispatcher-event-loop-25] | Starting task 5.0 in stage 5.0 (TID 99, dn07, executor 14, partition 5, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,915 | INFO  | [dispatcher-event-loop-25] | Starting task 6.0 in stage 5.0 (TID 100, dn22, executor 5, partition 6, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,915 | INFO  | [dispatcher-event-loop-25] | Starting task 7.0 in stage 5.0 (TID 101, dn17, executor 18, partition 7, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,915 | INFO  | [dispatcher-event-loop-25] | Starting task 8.0 in stage 5.0 (TID 102, dn28, executor 3, partition 8, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,915 | INFO  | [dispatcher-event-loop-25] | Starting task 9.0 in stage 5.0 (TID 103, dn16, executor 15, partition 9, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,916 | INFO  | [dispatcher-event-loop-25] | Starting task 10.0 in stage 5.0 (TID 104, dn20, executor 13, partition 10, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,916 | INFO  | [dispatcher-event-loop-25] | Starting task 11.0 in stage 5.0 (TID 105, dn14, executor 17, partition 11, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,916 | INFO  | [dispatcher-event-loop-25] | Starting task 12.0 in stage 5.0 (TID 106, dn29, executor 1, partition 12, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,916 | INFO  | [dispatcher-event-loop-25] | Starting task 13.0 in stage 5.0 (TID 107, dn18, executor 10, partition 13, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,916 | INFO  | [dispatcher-event-loop-25] | Starting task 14.0 in stage 5.0 (TID 108, dn32, executor 4, partition 14, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,917 | INFO  | [dispatcher-event-loop-25] | Starting task 15.0 in stage 5.0 (TID 109, dn27, executor 7, partition 15, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,917 | INFO  | [dispatcher-event-loop-25] | Starting task 16.0 in stage 5.0 (TID 110, dn15, executor 12, partition 16, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,917 | INFO  | [dispatcher-event-loop-25] | Starting task 17.0 in stage 5.0 (TID 111, dn37, executor 8, partition 17, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,917 | INFO  | [dispatcher-event-loop-25] | Starting task 18.0 in stage 5.0 (TID 112, dn30, executor 2, partition 18, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,917 | INFO  | [dispatcher-event-loop-25] | Starting task 19.0 in stage 5.0 (TID 113, dn36, executor 20, partition 19, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,917 | INFO  | [dispatcher-event-loop-25] | Starting task 20.0 in stage 5.0 (TID 114, dn10, executor 19, partition 20, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,918 | INFO  | [dispatcher-event-loop-25] | Starting task 21.0 in stage 5.0 (TID 115, dn24, executor 9, partition 21, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,918 | INFO  | [dispatcher-event-loop-25] | Starting task 22.0 in stage 5.0 (TID 116, dn34, executor 6, partition 22, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,918 | INFO  | [dispatcher-event-loop-25] | Starting task 23.0 in stage 5.0 (TID 117, dn08, executor 16, partition 23, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,918 | INFO  | [dispatcher-event-loop-25] | Starting task 24.0 in stage 5.0 (TID 118, dn19, executor 11, partition 24, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,918 | INFO  | [dispatcher-event-loop-25] | Starting task 25.0 in stage 5.0 (TID 119, dn07, executor 14, partition 25, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,919 | INFO  | [dispatcher-event-loop-25] | Starting task 26.0 in stage 5.0 (TID 120, dn22, executor 5, partition 26, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,919 | INFO  | [dispatcher-event-loop-25] | Starting task 27.0 in stage 5.0 (TID 121, dn17, executor 18, partition 27, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,919 | INFO  | [dispatcher-event-loop-25] | Starting task 28.0 in stage 5.0 (TID 122, dn28, executor 3, partition 28, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,919 | INFO  | [dispatcher-event-loop-25] | Starting task 29.0 in stage 5.0 (TID 123, dn16, executor 15, partition 29, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,919 | INFO  | [dispatcher-event-loop-25] | Starting task 30.0 in stage 5.0 (TID 124, dn20, executor 13, partition 30, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,919 | INFO  | [dispatcher-event-loop-25] | Starting task 31.0 in stage 5.0 (TID 125, dn14, executor 17, partition 31, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,920 | INFO  | [dispatcher-event-loop-25] | Starting task 32.0 in stage 5.0 (TID 126, dn29, executor 1, partition 32, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,920 | INFO  | [dispatcher-event-loop-25] | Starting task 33.0 in stage 5.0 (TID 127, dn18, executor 10, partition 33, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,920 | INFO  | [dispatcher-event-loop-25] | Starting task 34.0 in stage 5.0 (TID 128, dn32, executor 4, partition 34, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,920 | INFO  | [dispatcher-event-loop-25] | Starting task 35.0 in stage 5.0 (TID 129, dn27, executor 7, partition 35, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,920 | INFO  | [dispatcher-event-loop-25] | Starting task 36.0 in stage 5.0 (TID 130, dn15, executor 12, partition 36, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,920 | INFO  | [dispatcher-event-loop-25] | Starting task 37.0 in stage 5.0 (TID 131, dn37, executor 8, partition 37, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,921 | INFO  | [dispatcher-event-loop-25] | Starting task 38.0 in stage 5.0 (TID 132, dn30, executor 2, partition 38, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,921 | INFO  | [dispatcher-event-loop-25] | Starting task 39.0 in stage 5.0 (TID 133, dn36, executor 20, partition 39, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,942 | INFO  | [dispatcher-event-loop-62] | Added broadcast_7_piece0 in memory on dn16:22668 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,948 | INFO  | [dispatcher-event-loop-61] | Added broadcast_7_piece0 in memory on dn22:22834 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,950 | INFO  | [dispatcher-event-loop-57] | Added broadcast_7_piece0 in memory on dn24:22839 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,952 | INFO  | [dispatcher-event-loop-7] | Added broadcast_7_piece0 in memory on dn17:22761 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,953 | INFO  | [dispatcher-event-loop-17] | Added broadcast_7_piece0 in memory on dn08:22604 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,958 | INFO  | [dispatcher-event-loop-2] | Added broadcast_7_piece0 in memory on dn36:22756 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,959 | INFO  | [dispatcher-event-loop-2] | Added broadcast_7_piece0 in memory on dn27:22790 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,959 | INFO  | [dispatcher-event-loop-2] | Added broadcast_7_piece0 in memory on dn14:22891 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,962 | INFO  | [dispatcher-event-loop-9] | Added broadcast_7_piece0 in memory on dn19:22830 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,963 | INFO  | [dispatcher-event-loop-9] | Added broadcast_7_piece0 in memory on dn20:22825 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,964 | INFO  | [dispatcher-event-loop-9] | Added broadcast_7_piece0 in memory on dn37:22861 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,965 | INFO  | [dispatcher-event-loop-25] | Added broadcast_7_piece0 in memory on dn32:22787 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,967 | INFO  | [dispatcher-event-loop-27] | Added broadcast_7_piece0 in memory on dn30:22608 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,978 | INFO  | [dispatcher-event-loop-19] | Added broadcast_7_piece0 in memory on dn10:22719 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,979 | INFO  | [dispatcher-event-loop-4] | Added broadcast_7_piece0 in memory on dn07:22897 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,981 | INFO  | [dispatcher-event-loop-18] | Added broadcast_7_piece0 in memory on dn29:22705 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,982 | INFO  | [dispatcher-event-loop-14] | Asked to send map output locations for shuffle 0 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,982 | INFO  | [dispatcher-event-loop-6] | Asked to send map output locations for shuffle 0 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,984 | INFO  | [dispatcher-event-loop-31] | Asked to send map output locations for shuffle 0 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,988 | INFO  | [dispatcher-event-loop-20] | Asked to send map output locations for shuffle 0 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,989 | INFO  | [dispatcher-event-loop-30] | Added broadcast_7_piece0 in memory on dn15:22640 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,990 | INFO  | [dispatcher-event-loop-24] | Added broadcast_7_piece0 in memory on dn18:22756 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,993 | INFO  | [dispatcher-event-loop-22] | Added broadcast_7_piece0 in memory on dn28:22784 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,994 | INFO  | [dispatcher-event-loop-32] | Asked to send map output locations for shuffle 0 to *.*.132.21:46253 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,995 | INFO  | [dispatcher-event-loop-21] | Asked to send map output locations for shuffle 0 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,999 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 0 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,999 | INFO  | [dispatcher-event-loop-42] | Added broadcast_7_piece0 in memory on dn34:22620 (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:52,999 | INFO  | [dispatcher-event-loop-26] | Asked to send map output locations for shuffle 0 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,000 | INFO  | [dispatcher-event-loop-28] | Asked to send map output locations for shuffle 0 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,000 | INFO  | [dispatcher-event-loop-39] | Asked to send map output locations for shuffle 0 to *.*.132.40:54846 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,003 | INFO  | [dispatcher-event-loop-23] | Asked to send map output locations for shuffle 0 to *.*.132.38:54888 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,004 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 0 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,007 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 0 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,014 | INFO  | [dispatcher-event-loop-40] | Asked to send map output locations for shuffle 0 to *.*.132.15:57922 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,021 | INFO  | [dispatcher-event-loop-33] | Asked to send map output locations for shuffle 0 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,024 | INFO  | [dispatcher-event-loop-38] | Asked to send map output locations for shuffle 0 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,030 | INFO  | [dispatcher-event-loop-11] | Asked to send map output locations for shuffle 0 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,030 | INFO  | [dispatcher-event-loop-44] | Asked to send map output locations for shuffle 0 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,035 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 0 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,037 | INFO  | [dispatcher-event-loop-47] | Asked to send map output locations for shuffle 0 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,039 | INFO  | [dispatcher-event-loop-43] | Starting task 40.0 in stage 5.0 (TID 134, dn14, executor 17, partition 40, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,040 | INFO  | [task-result-getter-2] | Finished task 31.0 in stage 5.0 (TID 125) in 121 ms on dn14 (executor 17) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,041 | INFO  | [dispatcher-event-loop-43] | Starting task 41.0 in stage 5.0 (TID 135, dn14, executor 17, partition 41, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,042 | INFO  | [task-result-getter-3] | Finished task 11.0 in stage 5.0 (TID 105) in 126 ms on dn14 (executor 17) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,043 | INFO  | [dispatcher-event-loop-43] | Starting task 42.0 in stage 5.0 (TID 136, dn17, executor 18, partition 42, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,043 | INFO  | [task-result-getter-0] | Finished task 7.0 in stage 5.0 (TID 101) in 128 ms on dn17 (executor 18) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,044 | INFO  | [dispatcher-event-loop-43] | Starting task 43.0 in stage 5.0 (TID 137, dn17, executor 18, partition 43, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,044 | INFO  | [task-result-getter-1] | Finished task 27.0 in stage 5.0 (TID 121) in 125 ms on dn17 (executor 18) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,051 | INFO  | [dispatcher-event-loop-66] | Starting task 44.0 in stage 5.0 (TID 138, dn16, executor 15, partition 44, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,051 | INFO  | [task-result-getter-2] | Finished task 9.0 in stage 5.0 (TID 103) in 136 ms on dn16 (executor 15) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,052 | INFO  | [dispatcher-event-loop-66] | Starting task 45.0 in stage 5.0 (TID 139, dn24, executor 9, partition 45, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,052 | INFO  | [task-result-getter-3] | Finished task 21.0 in stage 5.0 (TID 115) in 134 ms on dn24 (executor 9) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,053 | INFO  | [dispatcher-event-loop-49] | Starting task 46.0 in stage 5.0 (TID 140, dn24, executor 9, partition 46, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,054 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 5.0 (TID 95) in 140 ms on dn24 (executor 9) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,055 | INFO  | [dispatcher-event-loop-49] | Starting task 47.0 in stage 5.0 (TID 141, dn27, executor 7, partition 47, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,055 | INFO  | [task-result-getter-1] | Finished task 35.0 in stage 5.0 (TID 129) in 135 ms on dn27 (executor 7) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,056 | INFO  | [dispatcher-event-loop-49] | Starting task 48.0 in stage 5.0 (TID 142, dn16, executor 15, partition 48, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,056 | INFO  | [task-result-getter-2] | Finished task 29.0 in stage 5.0 (TID 123) in 137 ms on dn16 (executor 15) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,057 | INFO  | [dispatcher-event-loop-49] | Starting task 49.0 in stage 5.0 (TID 143, dn27, executor 7, partition 49, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,058 | INFO  | [task-result-getter-3] | Finished task 15.0 in stage 5.0 (TID 109) in 142 ms on dn27 (executor 7) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,058 | INFO  | [dispatcher-event-loop-49] | Starting task 50.0 in stage 5.0 (TID 144, dn20, executor 13, partition 50, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,059 | INFO  | [task-result-getter-0] | Finished task 30.0 in stage 5.0 (TID 124) in 140 ms on dn20 (executor 13) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,059 | INFO  | [dispatcher-event-loop-49] | Starting task 51.0 in stage 5.0 (TID 145, dn36, executor 20, partition 51, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,060 | INFO  | [task-result-getter-1] | Finished task 39.0 in stage 5.0 (TID 133) in 139 ms on dn36 (executor 20) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,061 | INFO  | [dispatcher-event-loop-49] | Starting task 52.0 in stage 5.0 (TID 146, dn20, executor 13, partition 52, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,062 | INFO  | [task-result-getter-2] | Finished task 10.0 in stage 5.0 (TID 104) in 145 ms on dn20 (executor 13) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,062 | INFO  | [dispatcher-event-loop-49] | Starting task 53.0 in stage 5.0 (TID 147, dn19, executor 11, partition 53, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,063 | INFO  | [task-result-getter-3] | Finished task 4.0 in stage 5.0 (TID 98) in 148 ms on dn19 (executor 11) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,064 | INFO  | [dispatcher-event-loop-49] | Starting task 54.0 in stage 5.0 (TID 148, dn17, executor 18, partition 54, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,064 | INFO  | [task-result-getter-0] | Finished task 43.0 in stage 5.0 (TID 137) in 20 ms on dn17 (executor 18) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,065 | INFO  | [dispatcher-event-loop-49] | Starting task 55.0 in stage 5.0 (TID 149, dn32, executor 4, partition 55, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,065 | INFO  | [task-result-getter-1] | Finished task 14.0 in stage 5.0 (TID 108) in 149 ms on dn32 (executor 4) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,066 | INFO  | [dispatcher-event-loop-49] | Starting task 56.0 in stage 5.0 (TID 150, dn36, executor 20, partition 56, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,067 | INFO  | [task-result-getter-2] | Finished task 19.0 in stage 5.0 (TID 113) in 150 ms on dn36 (executor 20) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,068 | INFO  | [dispatcher-event-loop-49] | Starting task 57.0 in stage 5.0 (TID 151, dn14, executor 17, partition 57, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,068 | INFO  | [task-result-getter-3] | Finished task 41.0 in stage 5.0 (TID 135) in 27 ms on dn14 (executor 17) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,069 | INFO  | [dispatcher-event-loop-49] | Starting task 58.0 in stage 5.0 (TID 152, dn19, executor 11, partition 58, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,069 | INFO  | [task-result-getter-0] | Finished task 24.0 in stage 5.0 (TID 118) in 151 ms on dn19 (executor 11) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,070 | INFO  | [dispatcher-event-loop-49] | Starting task 59.0 in stage 5.0 (TID 153, dn14, executor 17, partition 59, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,070 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 5.0 (TID 134) in 31 ms on dn14 (executor 17) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,071 | INFO  | [dispatcher-event-loop-49] | Starting task 60.0 in stage 5.0 (TID 154, dn17, executor 18, partition 60, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,071 | INFO  | [task-result-getter-2] | Finished task 42.0 in stage 5.0 (TID 136) in 29 ms on dn17 (executor 18) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,072 | INFO  | [dispatcher-event-loop-49] | Starting task 61.0 in stage 5.0 (TID 155, dn08, executor 16, partition 61, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,072 | INFO  | [task-result-getter-3] | Finished task 23.0 in stage 5.0 (TID 117) in 154 ms on dn08 (executor 16) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,073 | INFO  | [dispatcher-event-loop-49] | Starting task 62.0 in stage 5.0 (TID 156, dn24, executor 9, partition 62, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,073 | INFO  | [task-result-getter-0] | Finished task 46.0 in stage 5.0 (TID 140) in 20 ms on dn24 (executor 9) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,074 | INFO  | [dispatcher-event-loop-49] | Starting task 63.0 in stage 5.0 (TID 157, dn08, executor 16, partition 63, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,074 | INFO  | [task-result-getter-1] | Finished task 3.0 in stage 5.0 (TID 97) in 160 ms on dn08 (executor 16) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,075 | INFO  | [dispatcher-event-loop-49] | Starting task 64.0 in stage 5.0 (TID 158, dn16, executor 15, partition 64, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,075 | INFO  | [task-result-getter-2] | Finished task 44.0 in stage 5.0 (TID 138) in 24 ms on dn16 (executor 15) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,076 | INFO  | [dispatcher-event-loop-49] | Starting task 65.0 in stage 5.0 (TID 159, dn24, executor 9, partition 65, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,076 | INFO  | [task-result-getter-3] | Finished task 45.0 in stage 5.0 (TID 139) in 24 ms on dn24 (executor 9) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,077 | INFO  | [dispatcher-event-loop-49] | Starting task 66.0 in stage 5.0 (TID 160, dn27, executor 7, partition 66, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,077 | INFO  | [task-result-getter-0] | Finished task 49.0 in stage 5.0 (TID 143) in 20 ms on dn27 (executor 7) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,078 | INFO  | [dispatcher-event-loop-49] | Starting task 67.0 in stage 5.0 (TID 161, dn30, executor 2, partition 67, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,078 | INFO  | [task-result-getter-1] | Finished task 18.0 in stage 5.0 (TID 112) in 161 ms on dn30 (executor 2) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,079 | INFO  | [dispatcher-event-loop-49] | Starting task 68.0 in stage 5.0 (TID 162, dn30, executor 2, partition 68, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,079 | INFO  | [task-result-getter-2] | Finished task 38.0 in stage 5.0 (TID 132) in 158 ms on dn30 (executor 2) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,080 | INFO  | [dispatcher-event-loop-49] | Starting task 69.0 in stage 5.0 (TID 163, dn36, executor 20, partition 69, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,080 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 5.0 (TID 145) in 21 ms on dn36 (executor 20) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,081 | INFO  | [dispatcher-event-loop-49] | Starting task 70.0 in stage 5.0 (TID 164, dn27, executor 7, partition 70, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,081 | INFO  | [task-result-getter-0] | Finished task 47.0 in stage 5.0 (TID 141) in 27 ms on dn27 (executor 7) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,081 | INFO  | [dispatcher-event-loop-49] | Starting task 71.0 in stage 5.0 (TID 165, dn10, executor 19, partition 71, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,082 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 5.0 (TID 94) in 169 ms on dn10 (executor 19) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,082 | INFO  | [dispatcher-event-loop-49] | Starting task 72.0 in stage 5.0 (TID 166, dn22, executor 5, partition 72, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,083 | INFO  | [task-result-getter-2] | Finished task 26.0 in stage 5.0 (TID 120) in 165 ms on dn22 (executor 5) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,083 | INFO  | [dispatcher-event-loop-49] | Starting task 73.0 in stage 5.0 (TID 167, dn22, executor 5, partition 73, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,085 | INFO  | [dispatcher-event-loop-49] | Starting task 74.0 in stage 5.0 (TID 168, dn17, executor 18, partition 74, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,086 | INFO  | [task-result-getter-3] | Finished task 6.0 in stage 5.0 (TID 100) in 170 ms on dn22 (executor 5) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,086 | INFO  | [task-result-getter-0] | Finished task 54.0 in stage 5.0 (TID 148) in 23 ms on dn17 (executor 18) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,087 | INFO  | [dispatcher-event-loop-49] | Starting task 75.0 in stage 5.0 (TID 169, dn10, executor 19, partition 75, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,087 | INFO  | [task-result-getter-1] | Finished task 20.0 in stage 5.0 (TID 114) in 170 ms on dn10 (executor 19) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,088 | INFO  | [dispatcher-event-loop-49] | Starting task 76.0 in stage 5.0 (TID 170, dn20, executor 13, partition 76, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,088 | INFO  | [task-result-getter-2] | Finished task 50.0 in stage 5.0 (TID 144) in 30 ms on dn20 (executor 13) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,089 | INFO  | [dispatcher-event-loop-49] | Starting task 77.0 in stage 5.0 (TID 171, dn18, executor 10, partition 77, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,089 | INFO  | [task-result-getter-3] | Finished task 13.0 in stage 5.0 (TID 107) in 173 ms on dn18 (executor 10) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,090 | INFO  | [dispatcher-event-loop-49] | Starting task 78.0 in stage 5.0 (TID 172, dn20, executor 13, partition 78, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,090 | INFO  | [task-result-getter-0] | Finished task 52.0 in stage 5.0 (TID 146) in 29 ms on dn20 (executor 13) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,091 | INFO  | [dispatcher-event-loop-49] | Starting task 79.0 in stage 5.0 (TID 173, dn37, executor 8, partition 79, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,091 | INFO  | [task-result-getter-1] | Finished task 37.0 in stage 5.0 (TID 131) in 171 ms on dn37 (executor 8) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,091 | INFO  | [dispatcher-event-loop-49] | Starting task 80.0 in stage 5.0 (TID 174, dn16, executor 15, partition 80, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,092 | INFO  | [task-result-getter-2] | Finished task 48.0 in stage 5.0 (TID 142) in 36 ms on dn16 (executor 15) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,092 | INFO  | [dispatcher-event-loop-49] | Starting task 81.0 in stage 5.0 (TID 175, dn18, executor 10, partition 81, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,093 | INFO  | [task-result-getter-3] | Finished task 33.0 in stage 5.0 (TID 127) in 173 ms on dn18 (executor 10) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,093 | INFO  | [dispatcher-event-loop-49] | Starting task 82.0 in stage 5.0 (TID 176, dn32, executor 4, partition 82, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,093 | INFO  | [task-result-getter-0] | Finished task 55.0 in stage 5.0 (TID 149) in 29 ms on dn32 (executor 4) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,094 | INFO  | [dispatcher-event-loop-49] | Starting task 83.0 in stage 5.0 (TID 177, dn29, executor 1, partition 83, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,094 | INFO  | [task-result-getter-1] | Finished task 32.0 in stage 5.0 (TID 126) in 175 ms on dn29 (executor 1) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,095 | INFO  | [dispatcher-event-loop-49] | Starting task 84.0 in stage 5.0 (TID 178, dn19, executor 11, partition 84, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,095 | INFO  | [task-result-getter-2] | Finished task 53.0 in stage 5.0 (TID 147) in 33 ms on dn19 (executor 11) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,095 | INFO  | [dispatcher-event-loop-49] | Starting task 85.0 in stage 5.0 (TID 179, dn29, executor 1, partition 85, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,096 | INFO  | [task-result-getter-3] | Finished task 12.0 in stage 5.0 (TID 106) in 180 ms on dn29 (executor 1) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,096 | INFO  | [dispatcher-event-loop-49] | Starting task 86.0 in stage 5.0 (TID 180, dn19, executor 11, partition 86, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,097 | INFO  | [task-result-getter-0] | Finished task 58.0 in stage 5.0 (TID 152) in 27 ms on dn19 (executor 11) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,097 | INFO  | [dispatcher-event-loop-49] | Starting task 87.0 in stage 5.0 (TID 181, dn14, executor 17, partition 87, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,097 | INFO  | [task-result-getter-1] | Finished task 57.0 in stage 5.0 (TID 151) in 29 ms on dn14 (executor 17) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,098 | INFO  | [dispatcher-event-loop-49] | Starting task 88.0 in stage 5.0 (TID 182, dn28, executor 3, partition 88, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,098 | INFO  | [task-result-getter-2] | Finished task 8.0 in stage 5.0 (TID 102) in 183 ms on dn28 (executor 3) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,099 | INFO  | [dispatcher-event-loop-49] | Starting task 89.0 in stage 5.0 (TID 183, dn17, executor 18, partition 89, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,099 | INFO  | [task-result-getter-3] | Finished task 60.0 in stage 5.0 (TID 154) in 28 ms on dn17 (executor 18) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,100 | INFO  | [task-result-getter-1] | Finished task 28.0 in stage 5.0 (TID 122) in 181 ms on dn28 (executor 3) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,100 | INFO  | [task-result-getter-0] | Finished task 17.0 in stage 5.0 (TID 111) in 183 ms on dn37 (executor 8) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,100 | INFO  | [task-result-getter-2] | Finished task 62.0 in stage 5.0 (TID 156) in 27 ms on dn24 (executor 9) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,101 | INFO  | [task-result-getter-1] | Finished task 64.0 in stage 5.0 (TID 158) in 26 ms on dn16 (executor 15) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,101 | INFO  | [task-result-getter-3] | Finished task 22.0 in stage 5.0 (TID 116) in 183 ms on dn34 (executor 6) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,101 | INFO  | [task-result-getter-0] | Finished task 65.0 in stage 5.0 (TID 159) in 25 ms on dn24 (executor 9) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,102 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 5.0 (TID 96) in 188 ms on dn34 (executor 6) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,102 | INFO  | [task-result-getter-1] | Finished task 63.0 in stage 5.0 (TID 157) in 28 ms on dn08 (executor 16) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,103 | INFO  | [task-result-getter-3] | Finished task 56.0 in stage 5.0 (TID 150) in 37 ms on dn36 (executor 20) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,103 | INFO  | [task-result-getter-0] | Finished task 61.0 in stage 5.0 (TID 155) in 31 ms on dn08 (executor 16) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,104 | INFO  | [task-result-getter-2] | Finished task 66.0 in stage 5.0 (TID 160) in 27 ms on dn27 (executor 7) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,105 | INFO  | [task-result-getter-1] | Finished task 16.0 in stage 5.0 (TID 110) in 188 ms on dn15 (executor 12) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,105 | INFO  | [task-result-getter-3] | Finished task 59.0 in stage 5.0 (TID 153) in 35 ms on dn14 (executor 17) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,106 | INFO  | [task-result-getter-0] | Finished task 36.0 in stage 5.0 (TID 130) in 186 ms on dn15 (executor 12) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,107 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 5.0 (TID 99) in 192 ms on dn07 (executor 14) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,108 | INFO  | [task-result-getter-1] | Finished task 68.0 in stage 5.0 (TID 162) in 29 ms on dn30 (executor 2) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,109 | INFO  | [task-result-getter-3] | Finished task 67.0 in stage 5.0 (TID 161) in 30 ms on dn30 (executor 2) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,109 | INFO  | [task-result-getter-0] | Finished task 70.0 in stage 5.0 (TID 164) in 29 ms on dn27 (executor 7) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,110 | INFO  | [task-result-getter-2] | Finished task 25.0 in stage 5.0 (TID 119) in 192 ms on dn07 (executor 14) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,110 | INFO  | [task-result-getter-1] | Finished task 74.0 in stage 5.0 (TID 168) in 25 ms on dn17 (executor 18) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,111 | INFO  | [task-result-getter-0] | Finished task 75.0 in stage 5.0 (TID 169) in 25 ms on dn10 (executor 19) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,112 | INFO  | [task-result-getter-2] | Finished task 76.0 in stage 5.0 (TID 170) in 25 ms on dn20 (executor 13) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,112 | INFO  | [task-result-getter-3] | Finished task 69.0 in stage 5.0 (TID 163) in 32 ms on dn36 (executor 20) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,113 | INFO  | [task-result-getter-1] | Finished task 73.0 in stage 5.0 (TID 167) in 30 ms on dn22 (executor 5) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,114 | INFO  | [task-result-getter-0] | Finished task 78.0 in stage 5.0 (TID 172) in 24 ms on dn20 (executor 13) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,115 | INFO  | [task-result-getter-2] | Finished task 80.0 in stage 5.0 (TID 174) in 24 ms on dn16 (executor 15) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,115 | INFO  | [task-result-getter-3] | Finished task 72.0 in stage 5.0 (TID 166) in 33 ms on dn22 (executor 5) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,116 | INFO  | [task-result-getter-1] | Finished task 71.0 in stage 5.0 (TID 165) in 35 ms on dn10 (executor 19) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,116 | INFO  | [task-result-getter-0] | Finished task 84.0 in stage 5.0 (TID 178) in 22 ms on dn19 (executor 11) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,117 | INFO  | [task-result-getter-2] | Finished task 89.0 in stage 5.0 (TID 183) in 19 ms on dn17 (executor 18) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,118 | INFO  | [task-result-getter-3] | Finished task 86.0 in stage 5.0 (TID 180) in 22 ms on dn19 (executor 11) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,118 | INFO  | [task-result-getter-1] | Finished task 81.0 in stage 5.0 (TID 175) in 26 ms on dn18 (executor 10) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,119 | INFO  | [task-result-getter-0] | Finished task 85.0 in stage 5.0 (TID 179) in 24 ms on dn29 (executor 1) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,119 | INFO  | [task-result-getter-3] | Finished task 83.0 in stage 5.0 (TID 177) in 25 ms on dn29 (executor 1) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,120 | INFO  | [task-result-getter-2] | Finished task 77.0 in stage 5.0 (TID 171) in 31 ms on dn18 (executor 10) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,120 | INFO  | [task-result-getter-1] | Finished task 79.0 in stage 5.0 (TID 173) in 30 ms on dn37 (executor 8) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,121 | INFO  | [task-result-getter-0] | Finished task 87.0 in stage 5.0 (TID 181) in 24 ms on dn14 (executor 17) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,121 | INFO  | [task-result-getter-3] | Finished task 82.0 in stage 5.0 (TID 176) in 28 ms on dn32 (executor 4) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,122 | INFO  | [task-result-getter-2] | Finished task 88.0 in stage 5.0 (TID 182) in 24 ms on dn28 (executor 3) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,815 | INFO  | [task-result-getter-1] | Finished task 34.0 in stage 5.0 (TID 128) in 894 ms on dn32 (executor 4) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,815 | INFO  | [task-result-getter-1] | Removed TaskSet 5.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,816 | INFO  | [dag-scheduler-event-loop] | ResultStage 5 (collect at GraphWriter.scala:537) finished in 0.911 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:53,817 | INFO  | [Driver] | Job 4 finished: collect at GraphWriter.scala:537, took 35.006387 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,195 | INFO  | [Driver] | Check mapping rule successfully. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,201 | INFO  | [Driver] | Start to load entity: entity1. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,270 | INFO  | [Driver] | Starting job: foreachPartition at GraphWriter.scala:455 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,273 | INFO  | [dag-scheduler-event-loop] | Registering RDD 22 (keyBy at GraphWriter.scala:446) as input to shuffle 1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,274 | INFO  | [dag-scheduler-event-loop] | Got job 5 (foreachPartition at GraphWriter.scala:455) with 90 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,274 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 7 (foreachPartition at GraphWriter.scala:455) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,275 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List(ShuffleMapStage 6) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,275 | INFO  | [dag-scheduler-event-loop] | Missing parents: List(ShuffleMapStage 6) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,277 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 6 (MapPartitionsRDD[22] at keyBy at GraphWriter.scala:446), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,301 | INFO  | [dag-scheduler-event-loop] | Block broadcast_8 stored as values in memory (estimated size 30.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,305 | INFO  | [dag-scheduler-event-loop] | Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,306 | INFO  | [dispatcher-event-loop-48] | Added broadcast_8_piece0 in memory on dn37:22779 (size: 9.6 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,307 | INFO  | [dag-scheduler-event-loop] | Created broadcast 8 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,311 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[22] at keyBy at GraphWriter.scala:446) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,312 | INFO  | [dag-scheduler-event-loop] | Adding task set 6.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,318 | INFO  | [dispatcher-event-loop-41] | Starting task 11.0 in stage 6.0 (TID 184, dn07, executor 14, partition 11, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,319 | INFO  | [dispatcher-event-loop-41] | Starting task 20.0 in stage 6.0 (TID 185, dn16, executor 15, partition 20, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,319 | INFO  | [dispatcher-event-loop-41] | Starting task 0.0 in stage 6.0 (TID 186, dn27, executor 7, partition 0, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,319 | INFO  | [dispatcher-event-loop-41] | Starting task 4.0 in stage 6.0 (TID 187, dn24, executor 9, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,320 | INFO  | [dispatcher-event-loop-41] | Starting task 10.0 in stage 6.0 (TID 188, dn15, executor 12, partition 10, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,320 | INFO  | [dispatcher-event-loop-41] | Starting task 30.0 in stage 6.0 (TID 189, dn10, executor 19, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,320 | INFO  | [dispatcher-event-loop-41] | Starting task 36.0 in stage 6.0 (TID 190, dn20, executor 13, partition 36, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,320 | INFO  | [dispatcher-event-loop-41] | Starting task 21.0 in stage 6.0 (TID 191, dn19, executor 11, partition 21, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,320 | INFO  | [dispatcher-event-loop-41] | Starting task 3.0 in stage 6.0 (TID 192, dn18, executor 10, partition 3, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,321 | INFO  | [dispatcher-event-loop-41] | Starting task 22.0 in stage 6.0 (TID 193, dn14, executor 17, partition 22, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,321 | INFO  | [dispatcher-event-loop-41] | Starting task 1.0 in stage 6.0 (TID 194, dn36, executor 20, partition 1, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,321 | INFO  | [dispatcher-event-loop-41] | Starting task 8.0 in stage 6.0 (TID 195, dn34, executor 6, partition 8, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,321 | INFO  | [dispatcher-event-loop-41] | Starting task 6.0 in stage 6.0 (TID 196, dn29, executor 1, partition 6, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,322 | INFO  | [dispatcher-event-loop-41] | Starting task 9.0 in stage 6.0 (TID 197, dn08, executor 16, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,322 | INFO  | [dispatcher-event-loop-41] | Starting task 2.0 in stage 6.0 (TID 198, dn17, executor 18, partition 2, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,322 | INFO  | [dispatcher-event-loop-41] | Starting task 15.0 in stage 6.0 (TID 199, dn28, executor 3, partition 15, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,322 | INFO  | [dispatcher-event-loop-41] | Starting task 7.0 in stage 6.0 (TID 200, dn32, executor 4, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,322 | INFO  | [dispatcher-event-loop-41] | Starting task 5.0 in stage 6.0 (TID 201, dn22, executor 5, partition 5, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,323 | INFO  | [dispatcher-event-loop-41] | Starting task 16.0 in stage 6.0 (TID 202, dn30, executor 2, partition 16, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,323 | INFO  | [dispatcher-event-loop-41] | Starting task 43.0 in stage 6.0 (TID 203, dn37, executor 8, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,323 | INFO  | [dispatcher-event-loop-41] | Starting task 13.0 in stage 6.0 (TID 204, dn07, executor 14, partition 13, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,323 | INFO  | [dispatcher-event-loop-41] | Starting task 23.0 in stage 6.0 (TID 205, dn16, executor 15, partition 23, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,323 | INFO  | [dispatcher-event-loop-41] | Starting task 14.0 in stage 6.0 (TID 206, dn27, executor 7, partition 14, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,324 | INFO  | [dispatcher-event-loop-41] | Starting task 48.0 in stage 6.0 (TID 207, dn24, executor 9, partition 48, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,324 | INFO  | [dispatcher-event-loop-41] | Starting task 27.0 in stage 6.0 (TID 208, dn15, executor 12, partition 27, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,324 | INFO  | [dispatcher-event-loop-41] | Starting task 31.0 in stage 6.0 (TID 209, dn10, executor 19, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,324 | INFO  | [dispatcher-event-loop-41] | Starting task 37.0 in stage 6.0 (TID 210, dn20, executor 13, partition 37, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,324 | INFO  | [dispatcher-event-loop-41] | Starting task 26.0 in stage 6.0 (TID 211, dn19, executor 11, partition 26, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,325 | INFO  | [dispatcher-event-loop-41] | Starting task 33.0 in stage 6.0 (TID 212, dn18, executor 10, partition 33, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,325 | INFO  | [dispatcher-event-loop-41] | Starting task 24.0 in stage 6.0 (TID 213, dn14, executor 17, partition 24, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,325 | INFO  | [dispatcher-event-loop-41] | Starting task 12.0 in stage 6.0 (TID 214, dn36, executor 20, partition 12, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,325 | INFO  | [dispatcher-event-loop-41] | Starting task 32.0 in stage 6.0 (TID 215, dn34, executor 6, partition 32, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,325 | INFO  | [dispatcher-event-loop-41] | Starting task 54.0 in stage 6.0 (TID 216, dn29, executor 1, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,326 | INFO  | [dispatcher-event-loop-41] | Starting task 38.0 in stage 6.0 (TID 217, dn08, executor 16, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,326 | INFO  | [dispatcher-event-loop-41] | Starting task 17.0 in stage 6.0 (TID 218, dn17, executor 18, partition 17, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,326 | INFO  | [dispatcher-event-loop-41] | Starting task 58.0 in stage 6.0 (TID 219, dn28, executor 3, partition 58, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,327 | INFO  | [dispatcher-event-loop-41] | Starting task 40.0 in stage 6.0 (TID 220, dn32, executor 4, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,327 | INFO  | [dispatcher-event-loop-41] | Starting task 18.0 in stage 6.0 (TID 221, dn22, executor 5, partition 18, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,327 | INFO  | [dispatcher-event-loop-41] | Starting task 28.0 in stage 6.0 (TID 222, dn30, executor 2, partition 28, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,327 | INFO  | [dispatcher-event-loop-41] | Starting task 55.0 in stage 6.0 (TID 223, dn37, executor 8, partition 55, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,345 | INFO  | [dispatcher-event-loop-40] | Added broadcast_8_piece0 in memory on dn27:22790 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,346 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn16:22668 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,346 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn22:22834 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,347 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn37:22861 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,347 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn15:22640 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,347 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn10:22719 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,348 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn30:22608 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,348 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn32:22787 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,348 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn19:22830 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,349 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn07:22897 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,349 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn08:22604 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,349 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn24:22839 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,350 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn17:22761 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,350 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn36:22756 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,351 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn14:22891 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,351 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn18:22756 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,351 | INFO  | [dispatcher-event-loop-33] | Added broadcast_8_piece0 in memory on dn29:22705 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,357 | INFO  | [dispatcher-event-loop-66] | Added broadcast_8_piece0 in memory on dn28:22784 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,365 | INFO  | [dispatcher-event-loop-45] | Added broadcast_8_piece0 in memory on dn20:22825 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:42:54,365 | INFO  | [dispatcher-event-loop-45] | Added broadcast_8_piece0 in memory on dn34:22620 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,571 | INFO  | [dispatcher-event-loop-20] | Starting task 29.0 in stage 6.0 (TID 224, dn17, executor 18, partition 29, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,571 | INFO  | [task-result-getter-0] | Finished task 17.0 in stage 6.0 (TID 218) in 7245 ms on dn17 (executor 18) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,688 | INFO  | [dispatcher-event-loop-22] | Starting task 44.0 in stage 6.0 (TID 225, dn32, executor 4, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,689 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 6.0 (TID 200) in 7367 ms on dn32 (executor 4) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,753 | INFO  | [task-result-getter-2] | Finished task 23.0 in stage 6.0 (TID 205) in 7430 ms on dn16 (executor 15) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,774 | INFO  | [dispatcher-event-loop-13] | Starting task 64.0 in stage 6.0 (TID 226, dn17, executor 18, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,774 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 6.0 (TID 198) in 7452 ms on dn17 (executor 18) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,810 | INFO  | [dispatcher-event-loop-39] | Starting task 78.0 in stage 6.0 (TID 227, dn18, executor 10, partition 78, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,811 | INFO  | [task-result-getter-0] | Finished task 3.0 in stage 6.0 (TID 192) in 7491 ms on dn18 (executor 10) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,883 | INFO  | [dispatcher-event-loop-29] | Starting task 80.0 in stage 6.0 (TID 228, dn08, executor 16, partition 80, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,884 | INFO  | [task-result-getter-3] | Finished task 9.0 in stage 6.0 (TID 197) in 7563 ms on dn08 (executor 16) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,898 | INFO  | [dispatcher-event-loop-36] | Starting task 79.0 in stage 6.0 (TID 229, dn20, executor 13, partition 79, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,899 | INFO  | [task-result-getter-2] | Finished task 37.0 in stage 6.0 (TID 210) in 7575 ms on dn20 (executor 13) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,900 | INFO  | [dispatcher-event-loop-40] | Starting task 47.0 in stage 6.0 (TID 230, dn10, executor 19, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,900 | INFO  | [task-result-getter-1] | Finished task 31.0 in stage 6.0 (TID 209) in 7576 ms on dn10 (executor 19) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,914 | INFO  | [task-result-getter-0] | Finished task 20.0 in stage 6.0 (TID 185) in 7595 ms on dn16 (executor 15) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,958 | INFO  | [dispatcher-event-loop-44] | Starting task 56.0 in stage 6.0 (TID 231, dn29, executor 1, partition 56, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,958 | INFO  | [task-result-getter-3] | Finished task 6.0 in stage 6.0 (TID 196) in 7637 ms on dn29 (executor 1) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,959 | INFO  | [dispatcher-event-loop-44] | Starting task 82.0 in stage 6.0 (TID 232, dn20, executor 13, partition 82, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,960 | INFO  | [task-result-getter-2] | Finished task 36.0 in stage 6.0 (TID 190) in 7640 ms on dn20 (executor 13) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,971 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 6.0 (TID 220) in 7645 ms on dn32 (executor 4) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,981 | INFO  | [dispatcher-event-loop-48] | Starting task 46.0 in stage 6.0 (TID 233, dn15, executor 12, partition 46, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,982 | INFO  | [task-result-getter-0] | Finished task 27.0 in stage 6.0 (TID 208) in 7658 ms on dn15 (executor 12) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,992 | INFO  | [dispatcher-event-loop-43] | Starting task 81.0 in stage 6.0 (TID 234, dn08, executor 16, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:01,992 | INFO  | [task-result-getter-3] | Finished task 38.0 in stage 6.0 (TID 217) in 7666 ms on dn08 (executor 16) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,013 | INFO  | [dispatcher-event-loop-35] | Starting task 77.0 in stage 6.0 (TID 235, dn15, executor 12, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,013 | INFO  | [task-result-getter-2] | Finished task 10.0 in stage 6.0 (TID 188) in 7694 ms on dn15 (executor 12) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,033 | INFO  | [task-result-getter-1] | Finished task 30.0 in stage 6.0 (TID 189) in 7713 ms on dn10 (executor 19) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,048 | INFO  | [dispatcher-event-loop-33] | Starting task 84.0 in stage 6.0 (TID 236, dn18, executor 10, partition 84, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,048 | INFO  | [task-result-getter-0] | Finished task 33.0 in stage 6.0 (TID 212) in 7724 ms on dn18 (executor 10) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,082 | INFO  | [dispatcher-event-loop-58] | Starting task 57.0 in stage 6.0 (TID 237, dn29, executor 1, partition 57, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,082 | INFO  | [task-result-getter-3] | Finished task 54.0 in stage 6.0 (TID 216) in 7757 ms on dn29 (executor 1) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,198 | INFO  | [dispatcher-event-loop-64] | Starting task 53.0 in stage 6.0 (TID 238, dn19, executor 11, partition 53, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,199 | INFO  | [task-result-getter-2] | Finished task 21.0 in stage 6.0 (TID 191) in 7879 ms on dn19 (executor 11) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,325 | INFO  | [task-result-getter-1] | Finished task 43.0 in stage 6.0 (TID 203) in 8002 ms on dn37 (executor 8) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,328 | INFO  | [dispatcher-event-loop-67] | Starting task 76.0 in stage 6.0 (TID 239, dn07, executor 14, partition 76, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,328 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 6.0 (TID 184) in 8010 ms on dn07 (executor 14) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,338 | INFO  | [dispatcher-event-loop-62] | Starting task 59.0 in stage 6.0 (TID 240, dn19, executor 11, partition 59, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,339 | INFO  | [task-result-getter-3] | Finished task 26.0 in stage 6.0 (TID 211) in 8014 ms on dn19 (executor 11) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,342 | INFO  | [task-result-getter-2] | Finished task 55.0 in stage 6.0 (TID 223) in 8015 ms on dn37 (executor 8) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,540 | INFO  | [task-result-getter-1] | Finished task 13.0 in stage 6.0 (TID 204) in 8217 ms on dn07 (executor 14) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,583 | INFO  | [dispatcher-event-loop-68] | Starting task 25.0 in stage 6.0 (TID 241, dn14, executor 17, partition 25, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,583 | INFO  | [task-result-getter-0] | Finished task 24.0 in stage 6.0 (TID 213) in 8258 ms on dn14 (executor 17) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,646 | INFO  | [dispatcher-event-loop-0] | Starting task 75.0 in stage 6.0 (TID 242, dn28, executor 3, partition 75, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,646 | INFO  | [task-result-getter-3] | Finished task 15.0 in stage 6.0 (TID 199) in 8324 ms on dn28 (executor 3) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,679 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 6.0 (TID 219) in 8352 ms on dn28 (executor 3) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,683 | INFO  | [dispatcher-event-loop-8] | Starting task 62.0 in stage 6.0 (TID 243, dn14, executor 17, partition 62, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,684 | INFO  | [task-result-getter-1] | Finished task 22.0 in stage 6.0 (TID 193) in 8363 ms on dn14 (executor 17) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,685 | INFO  | [dispatcher-event-loop-1] | Starting task 42.0 in stage 6.0 (TID 244, dn34, executor 6, partition 42, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,686 | INFO  | [task-result-getter-0] | Finished task 8.0 in stage 6.0 (TID 195) in 8365 ms on dn34 (executor 6) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,720 | INFO  | [dispatcher-event-loop-7] | Starting task 52.0 in stage 6.0 (TID 245, dn34, executor 6, partition 52, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,720 | INFO  | [task-result-getter-3] | Finished task 32.0 in stage 6.0 (TID 215) in 8395 ms on dn34 (executor 6) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,836 | INFO  | [dispatcher-event-loop-15] | Starting task 19.0 in stage 6.0 (TID 246, dn27, executor 7, partition 19, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,837 | INFO  | [task-result-getter-2] | Finished task 14.0 in stage 6.0 (TID 206) in 8514 ms on dn27 (executor 7) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,935 | INFO  | [dispatcher-event-loop-2] | Starting task 88.0 in stage 6.0 (TID 247, dn24, executor 9, partition 88, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,935 | INFO  | [task-result-getter-1] | Finished task 48.0 in stage 6.0 (TID 207) in 8611 ms on dn24 (executor 9) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,936 | INFO  | [dispatcher-event-loop-2] | Starting task 89.0 in stage 6.0 (TID 248, dn24, executor 9, partition 89, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,937 | INFO  | [task-result-getter-0] | Finished task 4.0 in stage 6.0 (TID 187) in 8618 ms on dn24 (executor 9) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:02,952 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 6.0 (TID 186) in 8633 ms on dn27 (executor 7) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,046 | INFO  | [dispatcher-event-loop-19] | Starting task 68.0 in stage 6.0 (TID 249, dn36, executor 20, partition 68, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,047 | INFO  | [task-result-getter-2] | Finished task 12.0 in stage 6.0 (TID 214) in 8722 ms on dn36 (executor 20) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,049 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 6.0 (TID 194) in 8727 ms on dn36 (executor 20) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,071 | INFO  | [dispatcher-event-loop-6] | Starting task 50.0 in stage 6.0 (TID 250, dn30, executor 2, partition 50, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,072 | INFO  | [task-result-getter-0] | Finished task 28.0 in stage 6.0 (TID 222) in 8744 ms on dn30 (executor 2) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,073 | INFO  | [dispatcher-event-loop-31] | Starting task 51.0 in stage 6.0 (TID 251, dn30, executor 2, partition 51, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,074 | INFO  | [task-result-getter-3] | Finished task 16.0 in stage 6.0 (TID 202) in 8752 ms on dn30 (executor 2) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,336 | INFO  | [dispatcher-event-loop-32] | Starting task 45.0 in stage 6.0 (TID 252, dn22, executor 5, partition 45, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,337 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 6.0 (TID 201) in 9015 ms on dn22 (executor 5) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,551 | INFO  | [dispatcher-event-loop-4] | Starting task 71.0 in stage 6.0 (TID 253, dn22, executor 5, partition 71, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:03,552 | INFO  | [task-result-getter-1] | Finished task 18.0 in stage 6.0 (TID 221) in 9225 ms on dn22 (executor 5) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,673 | INFO  | [dispatcher-event-loop-41] | Starting task 34.0 in stage 6.0 (TID 254, dn27, executor 7, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,674 | INFO  | [dispatcher-event-loop-41] | Starting task 35.0 in stage 6.0 (TID 255, dn10, executor 19, partition 35, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,675 | INFO  | [dispatcher-event-loop-41] | Starting task 39.0 in stage 6.0 (TID 256, dn16, executor 15, partition 39, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,675 | INFO  | [dispatcher-event-loop-41] | Starting task 41.0 in stage 6.0 (TID 257, dn28, executor 3, partition 41, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,676 | INFO  | [dispatcher-event-loop-41] | Starting task 49.0 in stage 6.0 (TID 258, dn32, executor 4, partition 49, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,677 | INFO  | [dispatcher-event-loop-41] | Starting task 60.0 in stage 6.0 (TID 259, dn37, executor 8, partition 60, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,678 | INFO  | [dispatcher-event-loop-41] | Starting task 61.0 in stage 6.0 (TID 260, dn07, executor 14, partition 61, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,679 | INFO  | [dispatcher-event-loop-41] | Starting task 63.0 in stage 6.0 (TID 261, dn36, executor 20, partition 63, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,679 | INFO  | [dispatcher-event-loop-41] | Starting task 65.0 in stage 6.0 (TID 262, dn16, executor 15, partition 65, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:06,680 | INFO  | [dispatcher-event-loop-41] | Starting task 66.0 in stage 6.0 (TID 263, dn37, executor 8, partition 66, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:08,997 | INFO  | [dispatcher-event-loop-68] | Starting task 67.0 in stage 6.0 (TID 264, dn17, executor 18, partition 67, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:08,998 | INFO  | [task-result-getter-0] | Finished task 29.0 in stage 6.0 (TID 224) in 7428 ms on dn17 (executor 18) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,301 | INFO  | [dispatcher-event-loop-0] | Starting task 70.0 in stage 6.0 (TID 265, dn17, executor 18, partition 70, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,302 | INFO  | [task-result-getter-3] | Finished task 64.0 in stage 6.0 (TID 226) in 7529 ms on dn17 (executor 18) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,438 | INFO  | [task-result-getter-2] | Finished task 79.0 in stage 6.0 (TID 229) in 7540 ms on dn20 (executor 13) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,445 | INFO  | [dispatcher-event-loop-71] | Starting task 83.0 in stage 6.0 (TID 266, dn15, executor 12, partition 83, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,445 | INFO  | [task-result-getter-1] | Finished task 77.0 in stage 6.0 (TID 235) in 7433 ms on dn15 (executor 12) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,527 | INFO  | [dispatcher-event-loop-1] | Starting task 86.0 in stage 6.0 (TID 267, dn15, executor 12, partition 86, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,527 | INFO  | [task-result-getter-0] | Finished task 46.0 in stage 6.0 (TID 233) in 7547 ms on dn15 (executor 12) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,609 | INFO  | [task-result-getter-3] | Finished task 44.0 in stage 6.0 (TID 225) in 7921 ms on dn32 (executor 4) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,627 | INFO  | [task-result-getter-2] | Finished task 80.0 in stage 6.0 (TID 228) in 7744 ms on dn08 (executor 16) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,640 | INFO  | [task-result-getter-1] | Finished task 81.0 in stage 6.0 (TID 234) in 7648 ms on dn08 (executor 16) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,662 | INFO  | [dispatcher-event-loop-15] | Starting task 69.0 in stage 6.0 (TID 268, dn29, executor 1, partition 69, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,662 | INFO  | [task-result-getter-0] | Finished task 56.0 in stage 6.0 (TID 231) in 7705 ms on dn29 (executor 1) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,751 | INFO  | [dispatcher-event-loop-2] | Starting task 73.0 in stage 6.0 (TID 269, dn29, executor 1, partition 73, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,752 | INFO  | [task-result-getter-3] | Finished task 57.0 in stage 6.0 (TID 237) in 7671 ms on dn29 (executor 1) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,819 | INFO  | [task-result-getter-2] | Finished task 82.0 in stage 6.0 (TID 232) in 7860 ms on dn20 (executor 13) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:09,977 | INFO  | [task-result-getter-1] | Finished task 47.0 in stage 6.0 (TID 230) in 8078 ms on dn10 (executor 19) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,219 | INFO  | [dispatcher-event-loop-19] | Starting task 85.0 in stage 6.0 (TID 270, dn18, executor 10, partition 85, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,220 | INFO  | [task-result-getter-0] | Finished task 78.0 in stage 6.0 (TID 227) in 8410 ms on dn18 (executor 10) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,266 | INFO  | [dispatcher-event-loop-14] | Starting task 87.0 in stage 6.0 (TID 271, dn19, executor 11, partition 87, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,267 | INFO  | [task-result-getter-3] | Finished task 59.0 in stage 6.0 (TID 240) in 7928 ms on dn19 (executor 11) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,277 | INFO  | [dispatcher-event-loop-31] | Starting task 72.0 in stage 6.0 (TID 272, dn14, executor 17, partition 72, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,277 | INFO  | [task-result-getter-2] | Finished task 25.0 in stage 6.0 (TID 241) in 7695 ms on dn14 (executor 17) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,320 | INFO  | [task-result-getter-1] | Finished task 42.0 in stage 6.0 (TID 244) in 7635 ms on dn34 (executor 6) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,398 | INFO  | [task-result-getter-0] | Finished task 75.0 in stage 6.0 (TID 242) in 7753 ms on dn28 (executor 3) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,415 | INFO  | [task-result-getter-3] | Finished task 52.0 in stage 6.0 (TID 245) in 7696 ms on dn34 (executor 6) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,443 | INFO  | [task-result-getter-2] | Finished task 53.0 in stage 6.0 (TID 238) in 8246 ms on dn19 (executor 11) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,536 | INFO  | [task-result-getter-1] | Finished task 84.0 in stage 6.0 (TID 236) in 8489 ms on dn18 (executor 10) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,658 | INFO  | [task-result-getter-0] | Finished task 62.0 in stage 6.0 (TID 243) in 7975 ms on dn14 (executor 17) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:10,975 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 6.0 (TID 247) in 8041 ms on dn24 (executor 9) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,011 | INFO  | [task-result-getter-2] | Finished task 19.0 in stage 6.0 (TID 246) in 8175 ms on dn27 (executor 7) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,027 | INFO  | [task-result-getter-1] | Finished task 89.0 in stage 6.0 (TID 248) in 8091 ms on dn24 (executor 9) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,146 | INFO  | [task-result-getter-0] | Finished task 68.0 in stage 6.0 (TID 249) in 8100 ms on dn36 (executor 20) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,150 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 6.0 (TID 251) in 8077 ms on dn30 (executor 2) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,216 | INFO  | [task-result-getter-2] | Finished task 76.0 in stage 6.0 (TID 239) in 8889 ms on dn07 (executor 14) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,295 | INFO  | [dispatcher-event-loop-34] | Starting task 74.0 in stage 6.0 (TID 273, dn22, executor 5, partition 74, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,296 | INFO  | [task-result-getter-1] | Finished task 71.0 in stage 6.0 (TID 253) in 7745 ms on dn22 (executor 5) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,392 | INFO  | [task-result-getter-0] | Finished task 45.0 in stage 6.0 (TID 252) in 8056 ms on dn22 (executor 5) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:11,505 | INFO  | [task-result-getter-3] | Finished task 50.0 in stage 6.0 (TID 250) in 8435 ms on dn30 (executor 2) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,056 | INFO  | [task-result-getter-2] | Finished task 41.0 in stage 6.0 (TID 257) in 7381 ms on dn28 (executor 3) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,232 | INFO  | [task-result-getter-1] | Finished task 65.0 in stage 6.0 (TID 262) in 7553 ms on dn16 (executor 15) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,279 | INFO  | [task-result-getter-0] | Finished task 63.0 in stage 6.0 (TID 261) in 7600 ms on dn36 (executor 20) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,373 | INFO  | [task-result-getter-3] | Finished task 49.0 in stage 6.0 (TID 258) in 7697 ms on dn32 (executor 4) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,406 | INFO  | [task-result-getter-2] | Finished task 39.0 in stage 6.0 (TID 256) in 7731 ms on dn16 (executor 15) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,513 | INFO  | [task-result-getter-1] | Finished task 35.0 in stage 6.0 (TID 255) in 7838 ms on dn10 (executor 19) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,568 | INFO  | [task-result-getter-0] | Finished task 61.0 in stage 6.0 (TID 260) in 7891 ms on dn07 (executor 14) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,756 | INFO  | [task-result-getter-3] | Finished task 34.0 in stage 6.0 (TID 254) in 8083 ms on dn27 (executor 7) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:14,953 | INFO  | [task-result-getter-2] | Finished task 66.0 in stage 6.0 (TID 263) in 8273 ms on dn37 (executor 8) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:15,000 | INFO  | [task-result-getter-1] | Finished task 60.0 in stage 6.0 (TID 259) in 8323 ms on dn37 (executor 8) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:16,497 | INFO  | [task-result-getter-0] | Finished task 83.0 in stage 6.0 (TID 266) in 7053 ms on dn15 (executor 12) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:16,788 | INFO  | [task-result-getter-3] | Finished task 86.0 in stage 6.0 (TID 267) in 7260 ms on dn15 (executor 12) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:16,924 | INFO  | [task-result-getter-2] | Finished task 67.0 in stage 6.0 (TID 264) in 7928 ms on dn17 (executor 18) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:17,008 | INFO  | [task-result-getter-1] | Finished task 69.0 in stage 6.0 (TID 268) in 7347 ms on dn29 (executor 1) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:17,075 | INFO  | [task-result-getter-0] | Finished task 73.0 in stage 6.0 (TID 269) in 7324 ms on dn29 (executor 1) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:17,395 | INFO  | [task-result-getter-3] | Finished task 70.0 in stage 6.0 (TID 265) in 8095 ms on dn17 (executor 18) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:17,793 | INFO  | [task-result-getter-2] | Finished task 87.0 in stage 6.0 (TID 271) in 7527 ms on dn19 (executor 11) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:18,639 | INFO  | [task-result-getter-1] | Finished task 85.0 in stage 6.0 (TID 270) in 8419 ms on dn18 (executor 10) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:18,767 | INFO  | [task-result-getter-0] | Finished task 72.0 in stage 6.0 (TID 272) in 8491 ms on dn14 (executor 17) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,251 | INFO  | [task-result-getter-3] | Finished task 74.0 in stage 6.0 (TID 273) in 8956 ms on dn22 (executor 5) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,252 | INFO  | [task-result-getter-3] | Removed TaskSet 6.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,252 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 6 (keyBy at GraphWriter.scala:446) finished in 25.960 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,253 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,253 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,253 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 7) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,253 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,255 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 7 (MapPartitionsRDD[24] at values at GraphWriter.scala:455), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,284 | INFO  | [dag-scheduler-event-loop] | Block broadcast_9 stored as values in memory (estimated size 7.4 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,287 | INFO  | [dag-scheduler-event-loop] | Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.1 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,288 | INFO  | [dispatcher-event-loop-40] | Added broadcast_9_piece0 in memory on dn37:22779 (size: 4.1 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,288 | INFO  | [dag-scheduler-event-loop] | Created broadcast 9 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,289 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ResultStage 7 (MapPartitionsRDD[24] at values at GraphWriter.scala:455) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,289 | INFO  | [dag-scheduler-event-loop] | Adding task set 7.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,291 | INFO  | [dispatcher-event-loop-49] | Starting task 64.0 in stage 7.0 (TID 274, dn22, executor 5, partition 64, NODE_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,292 | INFO  | [dispatcher-event-loop-49] | Starting task 77.0 in stage 7.0 (TID 275, dn14, executor 17, partition 77, NODE_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,293 | INFO  | [dispatcher-event-loop-49] | Starting task 71.0 in stage 7.0 (TID 276, dn29, executor 1, partition 71, NODE_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,293 | INFO  | [dispatcher-event-loop-49] | Starting task 37.0 in stage 7.0 (TID 277, dn18, executor 10, partition 37, NODE_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,294 | INFO  | [dispatcher-event-loop-49] | Starting task 0.0 in stage 7.0 (TID 278, dn19, executor 11, partition 0, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,294 | INFO  | [dispatcher-event-loop-49] | Starting task 1.0 in stage 7.0 (TID 279, dn17, executor 18, partition 1, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,295 | INFO  | [dispatcher-event-loop-49] | Starting task 2.0 in stage 7.0 (TID 280, dn22, executor 5, partition 2, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,295 | INFO  | [dispatcher-event-loop-49] | Starting task 3.0 in stage 7.0 (TID 281, dn07, executor 14, partition 3, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,295 | INFO  | [dispatcher-event-loop-49] | Starting task 4.0 in stage 7.0 (TID 282, dn36, executor 20, partition 4, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,296 | INFO  | [dispatcher-event-loop-49] | Starting task 5.0 in stage 7.0 (TID 283, dn14, executor 17, partition 5, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,296 | INFO  | [dispatcher-event-loop-49] | Starting task 6.0 in stage 7.0 (TID 284, dn30, executor 2, partition 6, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,297 | INFO  | [dispatcher-event-loop-49] | Starting task 7.0 in stage 7.0 (TID 285, dn24, executor 9, partition 7, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,297 | INFO  | [dispatcher-event-loop-49] | Starting task 8.0 in stage 7.0 (TID 286, dn16, executor 15, partition 8, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,298 | INFO  | [dispatcher-event-loop-49] | Starting task 9.0 in stage 7.0 (TID 287, dn08, executor 16, partition 9, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,298 | INFO  | [dispatcher-event-loop-49] | Starting task 10.0 in stage 7.0 (TID 288, dn15, executor 12, partition 10, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,298 | INFO  | [dispatcher-event-loop-49] | Starting task 11.0 in stage 7.0 (TID 289, dn10, executor 19, partition 11, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,299 | INFO  | [dispatcher-event-loop-49] | Starting task 12.0 in stage 7.0 (TID 290, dn27, executor 7, partition 12, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,299 | INFO  | [dispatcher-event-loop-49] | Starting task 13.0 in stage 7.0 (TID 291, dn29, executor 1, partition 13, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,300 | INFO  | [dispatcher-event-loop-49] | Starting task 14.0 in stage 7.0 (TID 292, dn20, executor 13, partition 14, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,300 | INFO  | [dispatcher-event-loop-49] | Starting task 15.0 in stage 7.0 (TID 293, dn34, executor 6, partition 15, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,300 | INFO  | [dispatcher-event-loop-49] | Starting task 16.0 in stage 7.0 (TID 294, dn18, executor 10, partition 16, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,301 | INFO  | [dispatcher-event-loop-49] | Starting task 17.0 in stage 7.0 (TID 295, dn37, executor 8, partition 17, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,301 | INFO  | [dispatcher-event-loop-49] | Starting task 18.0 in stage 7.0 (TID 296, dn32, executor 4, partition 18, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,302 | INFO  | [dispatcher-event-loop-49] | Starting task 19.0 in stage 7.0 (TID 297, dn28, executor 3, partition 19, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,302 | INFO  | [dispatcher-event-loop-49] | Starting task 20.0 in stage 7.0 (TID 298, dn19, executor 11, partition 20, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,302 | INFO  | [dispatcher-event-loop-49] | Starting task 21.0 in stage 7.0 (TID 299, dn17, executor 18, partition 21, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,303 | INFO  | [dispatcher-event-loop-49] | Starting task 22.0 in stage 7.0 (TID 300, dn07, executor 14, partition 22, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,303 | INFO  | [dispatcher-event-loop-49] | Starting task 23.0 in stage 7.0 (TID 301, dn36, executor 20, partition 23, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,304 | INFO  | [dispatcher-event-loop-49] | Starting task 24.0 in stage 7.0 (TID 302, dn30, executor 2, partition 24, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,304 | INFO  | [dispatcher-event-loop-49] | Starting task 25.0 in stage 7.0 (TID 303, dn24, executor 9, partition 25, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,304 | INFO  | [dispatcher-event-loop-49] | Starting task 26.0 in stage 7.0 (TID 304, dn16, executor 15, partition 26, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,305 | INFO  | [dispatcher-event-loop-49] | Starting task 27.0 in stage 7.0 (TID 305, dn08, executor 16, partition 27, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,305 | INFO  | [dispatcher-event-loop-49] | Starting task 28.0 in stage 7.0 (TID 306, dn15, executor 12, partition 28, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,306 | INFO  | [dispatcher-event-loop-49] | Starting task 29.0 in stage 7.0 (TID 307, dn10, executor 19, partition 29, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,306 | INFO  | [dispatcher-event-loop-49] | Starting task 30.0 in stage 7.0 (TID 308, dn27, executor 7, partition 30, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,306 | INFO  | [dispatcher-event-loop-49] | Starting task 31.0 in stage 7.0 (TID 309, dn20, executor 13, partition 31, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,306 | INFO  | [dispatcher-event-loop-49] | Starting task 32.0 in stage 7.0 (TID 310, dn34, executor 6, partition 32, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,306 | INFO  | [dispatcher-event-loop-49] | Starting task 33.0 in stage 7.0 (TID 311, dn37, executor 8, partition 33, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,307 | INFO  | [dispatcher-event-loop-49] | Starting task 34.0 in stage 7.0 (TID 312, dn32, executor 4, partition 34, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,307 | INFO  | [dispatcher-event-loop-49] | Starting task 35.0 in stage 7.0 (TID 313, dn28, executor 3, partition 35, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,327 | INFO  | [dispatcher-event-loop-21] | Added broadcast_9_piece0 in memory on dn16:22668 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,329 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn22:22834 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,330 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn34:22620 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,330 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn15:22640 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,331 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn30:22608 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,331 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn17:22761 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,332 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn24:22839 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,332 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn27:22790 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,333 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn20:22825 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,334 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn08:22604 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,334 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn19:22830 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,335 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn36:22756 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,335 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn37:22861 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,336 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn14:22891 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,336 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn32:22787 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,337 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn07:22897 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,337 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn18:22756 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,338 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn10:22719 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,338 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn29:22705 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,339 | INFO  | [dispatcher-event-loop-4] | Added broadcast_9_piece0 in memory on dn28:22784 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,399 | INFO  | [dispatcher-event-loop-46] | Asked to send map output locations for shuffle 1 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,402 | INFO  | [dispatcher-event-loop-35] | Asked to send map output locations for shuffle 1 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,406 | INFO  | [dispatcher-event-loop-51] | Asked to send map output locations for shuffle 1 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,406 | INFO  | [dispatcher-event-loop-33] | Asked to send map output locations for shuffle 1 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,407 | INFO  | [dispatcher-event-loop-52] | Asked to send map output locations for shuffle 1 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,407 | INFO  | [dispatcher-event-loop-66] | Asked to send map output locations for shuffle 1 to *.*.132.21:46253 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,410 | INFO  | [dispatcher-event-loop-58] | Asked to send map output locations for shuffle 1 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,412 | INFO  | [dispatcher-event-loop-45] | Asked to send map output locations for shuffle 1 to *.*.132.40:54846 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,412 | INFO  | [dispatcher-event-loop-64] | Asked to send map output locations for shuffle 1 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,414 | INFO  | [dispatcher-event-loop-53] | Asked to send map output locations for shuffle 1 to *.*.132.38:54888 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,417 | INFO  | [dispatcher-event-loop-59] | Asked to send map output locations for shuffle 1 to *.*.132.15:57922 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,419 | INFO  | [dispatcher-event-loop-50] | Asked to send map output locations for shuffle 1 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,419 | INFO  | [dispatcher-event-loop-63] | Asked to send map output locations for shuffle 1 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,422 | INFO  | [dispatcher-event-loop-62] | Asked to send map output locations for shuffle 1 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,423 | INFO  | [dispatcher-event-loop-55] | Asked to send map output locations for shuffle 1 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,424 | INFO  | [dispatcher-event-loop-60] | Asked to send map output locations for shuffle 1 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,424 | INFO  | [dispatcher-event-loop-54] | Asked to send map output locations for shuffle 1 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,427 | INFO  | [dispatcher-event-loop-69] | Asked to send map output locations for shuffle 1 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,433 | INFO  | [dispatcher-event-loop-65] | Asked to send map output locations for shuffle 1 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:20,444 | INFO  | [dispatcher-event-loop-68] | Asked to send map output locations for shuffle 1 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:24,428 | INFO  | [dispatcher-event-loop-27] | Starting task 36.0 in stage 7.0 (TID 314, dn20, executor 13, partition 36, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:24,434 | INFO  | [task-result-getter-2] | Finished task 14.0 in stage 7.0 (TID 292) in 4135 ms on dn20 (executor 13) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:25,483 | INFO  | [dispatcher-event-loop-30] | Starting task 38.0 in stage 7.0 (TID 315, dn18, executor 10, partition 38, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:25,484 | INFO  | [task-result-getter-1] | Finished task 37.0 in stage 7.0 (TID 277) in 5191 ms on dn18 (executor 10) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:25,548 | INFO  | [dispatcher-event-loop-22] | Starting task 39.0 in stage 7.0 (TID 316, dn20, executor 13, partition 39, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:25,549 | INFO  | [task-result-getter-0] | Finished task 31.0 in stage 7.0 (TID 309) in 5242 ms on dn20 (executor 13) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:25,551 | INFO  | [dispatcher-event-loop-21] | Starting task 40.0 in stage 7.0 (TID 317, dn36, executor 20, partition 40, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:25,551 | INFO  | [task-result-getter-3] | Finished task 4.0 in stage 7.0 (TID 282) in 5256 ms on dn36 (executor 20) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,091 | INFO  | [dispatcher-event-loop-49] | Starting task 41.0 in stage 7.0 (TID 318, dn29, executor 1, partition 41, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,091 | INFO  | [task-result-getter-2] | Finished task 71.0 in stage 7.0 (TID 276) in 5799 ms on dn29 (executor 1) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,261 | INFO  | [dispatcher-event-loop-11] | Starting task 42.0 in stage 7.0 (TID 319, dn18, executor 10, partition 42, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,261 | INFO  | [task-result-getter-1] | Finished task 38.0 in stage 7.0 (TID 315) in 778 ms on dn18 (executor 10) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,340 | INFO  | [dispatcher-event-loop-44] | Starting task 43.0 in stage 7.0 (TID 320, dn18, executor 10, partition 43, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,341 | INFO  | [task-result-getter-0] | Finished task 16.0 in stage 7.0 (TID 294) in 6041 ms on dn18 (executor 10) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,342 | INFO  | [dispatcher-event-loop-44] | Starting task 44.0 in stage 7.0 (TID 321, dn29, executor 1, partition 44, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,342 | INFO  | [task-result-getter-3] | Finished task 13.0 in stage 7.0 (TID 291) in 6043 ms on dn29 (executor 1) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,508 | INFO  | [dispatcher-event-loop-43] | Starting task 45.0 in stage 7.0 (TID 322, dn37, executor 8, partition 45, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,509 | INFO  | [task-result-getter-2] | Finished task 17.0 in stage 7.0 (TID 295) in 6208 ms on dn37 (executor 8) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,511 | INFO  | [dispatcher-event-loop-41] | Starting task 46.0 in stage 7.0 (TID 323, dn07, executor 14, partition 46, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,512 | INFO  | [task-result-getter-1] | Finished task 3.0 in stage 7.0 (TID 281) in 6217 ms on dn07 (executor 14) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,633 | INFO  | [dispatcher-event-loop-51] | Starting task 47.0 in stage 7.0 (TID 324, dn14, executor 17, partition 47, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,634 | INFO  | [task-result-getter-0] | Finished task 77.0 in stage 7.0 (TID 275) in 6342 ms on dn14 (executor 17) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,709 | INFO  | [dispatcher-event-loop-66] | Starting task 48.0 in stage 7.0 (TID 325, dn37, executor 8, partition 48, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,710 | INFO  | [task-result-getter-3] | Finished task 33.0 in stage 7.0 (TID 311) in 6403 ms on dn37 (executor 8) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,816 | INFO  | [dispatcher-event-loop-53] | Starting task 49.0 in stage 7.0 (TID 326, dn07, executor 14, partition 49, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:26,817 | INFO  | [task-result-getter-2] | Finished task 22.0 in stage 7.0 (TID 300) in 6513 ms on dn07 (executor 14) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,132 | INFO  | [dispatcher-event-loop-50] | Starting task 50.0 in stage 7.0 (TID 327, dn37, executor 8, partition 50, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,133 | INFO  | [task-result-getter-1] | Finished task 45.0 in stage 7.0 (TID 322) in 625 ms on dn37 (executor 8) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,155 | INFO  | [dispatcher-event-loop-67] | Starting task 51.0 in stage 7.0 (TID 328, dn36, executor 20, partition 51, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,156 | INFO  | [task-result-getter-0] | Finished task 23.0 in stage 7.0 (TID 301) in 6853 ms on dn36 (executor 20) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,174 | INFO  | [dispatcher-event-loop-62] | Starting task 52.0 in stage 7.0 (TID 329, dn17, executor 18, partition 52, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,175 | INFO  | [task-result-getter-3] | Finished task 21.0 in stage 7.0 (TID 299) in 6873 ms on dn17 (executor 18) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,375 | INFO  | [dispatcher-event-loop-68] | Starting task 53.0 in stage 7.0 (TID 330, dn29, executor 1, partition 53, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,376 | INFO  | [task-result-getter-2] | Finished task 41.0 in stage 7.0 (TID 318) in 1286 ms on dn29 (executor 1) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,555 | INFO  | [dispatcher-event-loop-5] | Starting task 54.0 in stage 7.0 (TID 331, dn34, executor 6, partition 54, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,556 | INFO  | [task-result-getter-1] | Finished task 15.0 in stage 7.0 (TID 293) in 7255 ms on dn34 (executor 6) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,694 | INFO  | [dispatcher-event-loop-61] | Starting task 55.0 in stage 7.0 (TID 332, dn34, executor 6, partition 55, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,695 | INFO  | [task-result-getter-0] | Finished task 32.0 in stage 7.0 (TID 310) in 7389 ms on dn34 (executor 6) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,803 | INFO  | [dispatcher-event-loop-1] | Starting task 56.0 in stage 7.0 (TID 333, dn32, executor 4, partition 56, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,803 | INFO  | [task-result-getter-3] | Finished task 34.0 in stage 7.0 (TID 312) in 7496 ms on dn32 (executor 4) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,812 | INFO  | [dispatcher-event-loop-17] | Starting task 57.0 in stage 7.0 (TID 334, dn20, executor 13, partition 57, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:27,812 | INFO  | [task-result-getter-2] | Finished task 36.0 in stage 7.0 (TID 314) in 3384 ms on dn20 (executor 13) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,001 | INFO  | [dispatcher-event-loop-15] | Starting task 58.0 in stage 7.0 (TID 335, dn08, executor 16, partition 58, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,002 | INFO  | [task-result-getter-1] | Finished task 9.0 in stage 7.0 (TID 287) in 7705 ms on dn08 (executor 16) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,084 | INFO  | [dispatcher-event-loop-9] | Starting task 59.0 in stage 7.0 (TID 336, dn08, executor 16, partition 59, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,084 | INFO  | [task-result-getter-0] | Finished task 27.0 in stage 7.0 (TID 305) in 7779 ms on dn08 (executor 16) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,227 | INFO  | [dispatcher-event-loop-25] | Starting task 60.0 in stage 7.0 (TID 337, dn24, executor 9, partition 60, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,227 | INFO  | [task-result-getter-3] | Finished task 25.0 in stage 7.0 (TID 303) in 7923 ms on dn24 (executor 9) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,751 | INFO  | [dispatcher-event-loop-31] | Starting task 61.0 in stage 7.0 (TID 338, dn36, executor 20, partition 61, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:28,753 | INFO  | [task-result-getter-2] | Finished task 51.0 in stage 7.0 (TID 328) in 1598 ms on dn36 (executor 20) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,204 | INFO  | [dispatcher-event-loop-20] | Starting task 62.0 in stage 7.0 (TID 339, dn30, executor 2, partition 62, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,204 | INFO  | [task-result-getter-1] | Finished task 6.0 in stage 7.0 (TID 284) in 8908 ms on dn30 (executor 2) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,737 | INFO  | [dispatcher-event-loop-32] | Starting task 63.0 in stage 7.0 (TID 340, dn24, executor 9, partition 63, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,737 | INFO  | [task-result-getter-0] | Finished task 7.0 in stage 7.0 (TID 285) in 9440 ms on dn24 (executor 9) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,739 | INFO  | [dispatcher-event-loop-22] | Starting task 65.0 in stage 7.0 (TID 341, dn32, executor 4, partition 65, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,740 | INFO  | [task-result-getter-3] | Finished task 18.0 in stage 7.0 (TID 296) in 9439 ms on dn32 (executor 4) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,756 | INFO  | [dispatcher-event-loop-13] | Starting task 66.0 in stage 7.0 (TID 342, dn24, executor 9, partition 66, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:29,757 | INFO  | [task-result-getter-2] | Finished task 63.0 in stage 7.0 (TID 340) in 21 ms on dn24 (executor 9) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,048 | INFO  | [dispatcher-event-loop-39] | Starting task 67.0 in stage 7.0 (TID 343, dn28, executor 3, partition 67, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,049 | INFO  | [task-result-getter-1] | Finished task 19.0 in stage 7.0 (TID 297) in 9748 ms on dn28 (executor 3) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,138 | INFO  | [dispatcher-event-loop-29] | Starting task 68.0 in stage 7.0 (TID 344, dn10, executor 19, partition 68, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,139 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 7.0 (TID 289) in 9841 ms on dn10 (executor 19) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,643 | INFO  | [dispatcher-event-loop-11] | Starting task 69.0 in stage 7.0 (TID 345, dn08, executor 16, partition 69, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,643 | INFO  | [task-result-getter-3] | Finished task 59.0 in stage 7.0 (TID 336) in 2559 ms on dn08 (executor 16) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,710 | INFO  | [dispatcher-event-loop-44] | Starting task 70.0 in stage 7.0 (TID 346, dn08, executor 16, partition 70, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,711 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 7.0 (TID 335) in 2710 ms on dn08 (executor 16) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,828 | INFO  | [dispatcher-event-loop-4] | Starting task 72.0 in stage 7.0 (TID 347, dn14, executor 17, partition 72, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:30,828 | INFO  | [task-result-getter-1] | Finished task 47.0 in stage 7.0 (TID 324) in 4196 ms on dn14 (executor 17) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,018 | INFO  | [dispatcher-event-loop-35] | Starting task 73.0 in stage 7.0 (TID 348, dn28, executor 3, partition 73, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,019 | INFO  | [task-result-getter-0] | Finished task 35.0 in stage 7.0 (TID 313) in 10712 ms on dn28 (executor 3) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,201 | INFO  | [dispatcher-event-loop-33] | Starting task 74.0 in stage 7.0 (TID 349, dn08, executor 16, partition 74, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,202 | INFO  | [task-result-getter-3] | Finished task 69.0 in stage 7.0 (TID 345) in 560 ms on dn08 (executor 16) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,203 | INFO  | [dispatcher-event-loop-52] | Starting task 75.0 in stage 7.0 (TID 350, dn19, executor 11, partition 75, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,204 | INFO  | [task-result-getter-2] | Finished task 20.0 in stage 7.0 (TID 298) in 10902 ms on dn19 (executor 11) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,268 | INFO  | [dispatcher-event-loop-45] | Starting task 76.0 in stage 7.0 (TID 351, dn10, executor 19, partition 76, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,269 | INFO  | [task-result-getter-1] | Finished task 29.0 in stage 7.0 (TID 307) in 10964 ms on dn10 (executor 19) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,387 | INFO  | [dispatcher-event-loop-53] | Starting task 78.0 in stage 7.0 (TID 352, dn28, executor 3, partition 78, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,388 | INFO  | [task-result-getter-0] | Finished task 67.0 in stage 7.0 (TID 343) in 1340 ms on dn28 (executor 3) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,515 | INFO  | [dispatcher-event-loop-50] | Starting task 79.0 in stage 7.0 (TID 353, dn28, executor 3, partition 79, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,515 | INFO  | [task-result-getter-3] | Finished task 73.0 in stage 7.0 (TID 348) in 497 ms on dn28 (executor 3) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,580 | INFO  | [dispatcher-event-loop-67] | Starting task 80.0 in stage 7.0 (TID 354, dn14, executor 17, partition 80, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,581 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 7.0 (TID 283) in 11284 ms on dn14 (executor 17) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,593 | INFO  | [dispatcher-event-loop-62] | Starting task 81.0 in stage 7.0 (TID 355, dn07, executor 14, partition 81, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,594 | INFO  | [task-result-getter-1] | Finished task 46.0 in stage 7.0 (TID 323) in 5083 ms on dn07 (executor 14) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,617 | INFO  | [dispatcher-event-loop-60] | Starting task 82.0 in stage 7.0 (TID 356, dn36, executor 20, partition 82, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,618 | INFO  | [task-result-getter-0] | Finished task 61.0 in stage 7.0 (TID 338) in 2868 ms on dn36 (executor 20) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,704 | INFO  | [dispatcher-event-loop-65] | Starting task 83.0 in stage 7.0 (TID 357, dn20, executor 13, partition 83, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,704 | INFO  | [task-result-getter-3] | Finished task 57.0 in stage 7.0 (TID 334) in 3892 ms on dn20 (executor 13) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,752 | INFO  | [dispatcher-event-loop-0] | Starting task 84.0 in stage 7.0 (TID 358, dn17, executor 18, partition 84, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,752 | INFO  | [task-result-getter-2] | Finished task 1.0 in stage 7.0 (TID 279) in 11458 ms on dn17 (executor 18) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,818 | INFO  | [dispatcher-event-loop-61] | Starting task 85.0 in stage 7.0 (TID 359, dn07, executor 14, partition 85, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,818 | INFO  | [task-result-getter-1] | Finished task 49.0 in stage 7.0 (TID 326) in 5002 ms on dn07 (executor 14) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,917 | INFO  | [dispatcher-event-loop-1] | Starting task 86.0 in stage 7.0 (TID 360, dn19, executor 11, partition 86, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:31,917 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 7.0 (TID 278) in 11623 ms on dn19 (executor 11) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,066 | INFO  | [dispatcher-event-loop-17] | Starting task 87.0 in stage 7.0 (TID 361, dn36, executor 20, partition 87, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,067 | INFO  | [task-result-getter-3] | Finished task 40.0 in stage 7.0 (TID 317) in 6517 ms on dn36 (executor 20) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,209 | INFO  | [dispatcher-event-loop-15] | Starting task 88.0 in stage 7.0 (TID 362, dn28, executor 3, partition 88, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,210 | INFO  | [task-result-getter-2] | Finished task 79.0 in stage 7.0 (TID 353) in 696 ms on dn28 (executor 3) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,374 | INFO  | [dispatcher-event-loop-9] | Starting task 89.0 in stage 7.0 (TID 363, dn20, executor 13, partition 89, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,374 | INFO  | [task-result-getter-1] | Finished task 83.0 in stage 7.0 (TID 357) in 670 ms on dn20 (executor 13) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,451 | INFO  | [task-result-getter-0] | Finished task 39.0 in stage 7.0 (TID 316) in 6903 ms on dn20 (executor 13) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,451 | INFO  | [task-result-getter-3] | Finished task 53.0 in stage 7.0 (TID 330) in 5076 ms on dn29 (executor 1) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,564 | INFO  | [task-result-getter-2] | Finished task 44.0 in stage 7.0 (TID 321) in 6223 ms on dn29 (executor 1) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,706 | INFO  | [task-result-getter-1] | Finished task 62.0 in stage 7.0 (TID 339) in 3503 ms on dn30 (executor 2) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,717 | INFO  | [task-result-getter-0] | Finished task 43.0 in stage 7.0 (TID 320) in 6377 ms on dn18 (executor 10) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,731 | INFO  | [task-result-getter-3] | Finished task 55.0 in stage 7.0 (TID 332) in 5036 ms on dn34 (executor 6) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,820 | INFO  | [task-result-getter-2] | Finished task 87.0 in stage 7.0 (TID 361) in 754 ms on dn36 (executor 20) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,921 | INFO  | [task-result-getter-1] | Finished task 89.0 in stage 7.0 (TID 363) in 547 ms on dn20 (executor 13) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:32,931 | INFO  | [task-result-getter-0] | Finished task 24.0 in stage 7.0 (TID 302) in 12628 ms on dn30 (executor 2) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:33,186 | INFO  | [task-result-getter-3] | Finished task 42.0 in stage 7.0 (TID 319) in 6925 ms on dn18 (executor 10) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:33,204 | INFO  | [task-result-getter-2] | Finished task 52.0 in stage 7.0 (TID 329) in 6030 ms on dn17 (executor 18) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:33,360 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 7.0 (TID 280) in 13066 ms on dn22 (executor 5) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:33,558 | INFO  | [task-result-getter-0] | Finished task 64.0 in stage 7.0 (TID 274) in 13267 ms on dn22 (executor 5) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:33,631 | INFO  | [task-result-getter-3] | Finished task 82.0 in stage 7.0 (TID 356) in 2013 ms on dn36 (executor 20) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:33,712 | INFO  | [task-result-getter-2] | Finished task 68.0 in stage 7.0 (TID 344) in 3574 ms on dn10 (executor 19) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:34,201 | INFO  | [task-result-getter-1] | Finished task 76.0 in stage 7.0 (TID 351) in 2933 ms on dn10 (executor 19) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:34,310 | INFO  | [task-result-getter-0] | Finished task 65.0 in stage 7.0 (TID 341) in 4571 ms on dn32 (executor 4) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:34,384 | INFO  | [task-result-getter-3] | Finished task 30.0 in stage 7.0 (TID 308) in 14078 ms on dn27 (executor 7) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:34,665 | INFO  | [task-result-getter-2] | Finished task 10.0 in stage 7.0 (TID 288) in 14367 ms on dn15 (executor 12) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:34,858 | INFO  | [task-result-getter-1] | Finished task 12.0 in stage 7.0 (TID 290) in 14559 ms on dn27 (executor 7) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:34,985 | INFO  | [task-result-getter-0] | Finished task 56.0 in stage 7.0 (TID 333) in 7183 ms on dn32 (executor 4) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,059 | INFO  | [task-result-getter-3] | Finished task 66.0 in stage 7.0 (TID 342) in 5303 ms on dn24 (executor 9) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,309 | INFO  | [task-result-getter-2] | Finished task 78.0 in stage 7.0 (TID 352) in 3922 ms on dn28 (executor 3) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,395 | INFO  | [task-result-getter-1] | Finished task 72.0 in stage 7.0 (TID 347) in 4567 ms on dn14 (executor 17) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,400 | INFO  | [task-result-getter-0] | Finished task 70.0 in stage 7.0 (TID 346) in 4690 ms on dn08 (executor 16) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,401 | INFO  | [task-result-getter-3] | Finished task 74.0 in stage 7.0 (TID 349) in 4200 ms on dn08 (executor 16) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,517 | INFO  | [task-result-getter-2] | Finished task 28.0 in stage 7.0 (TID 306) in 15212 ms on dn15 (executor 12) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,518 | INFO  | [task-result-getter-1] | Finished task 54.0 in stage 7.0 (TID 331) in 7963 ms on dn34 (executor 6) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,531 | INFO  | [task-result-getter-0] | Finished task 8.0 in stage 7.0 (TID 286) in 15234 ms on dn16 (executor 15) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,670 | INFO  | [task-result-getter-3] | Finished task 86.0 in stage 7.0 (TID 360) in 3754 ms on dn19 (executor 11) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,799 | INFO  | [task-result-getter-2] | Finished task 84.0 in stage 7.0 (TID 358) in 4048 ms on dn17 (executor 18) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,850 | INFO  | [task-result-getter-1] | Finished task 26.0 in stage 7.0 (TID 304) in 15546 ms on dn16 (executor 15) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:35,934 | INFO  | [task-result-getter-0] | Finished task 60.0 in stage 7.0 (TID 337) in 7708 ms on dn24 (executor 9) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:36,101 | INFO  | [task-result-getter-3] | Finished task 81.0 in stage 7.0 (TID 355) in 4508 ms on dn07 (executor 14) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:36,180 | INFO  | [task-result-getter-2] | Finished task 75.0 in stage 7.0 (TID 350) in 4977 ms on dn19 (executor 11) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:36,281 | INFO  | [task-result-getter-1] | Finished task 85.0 in stage 7.0 (TID 359) in 4463 ms on dn07 (executor 14) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:36,494 | INFO  | [task-result-getter-0] | Finished task 80.0 in stage 7.0 (TID 354) in 4914 ms on dn14 (executor 17) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:36,617 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 7.0 (TID 362) in 4408 ms on dn28 (executor 3) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,177 | INFO  | [task-result-getter-2] | Finished task 50.0 in stage 7.0 (TID 327) in 10045 ms on dn37 (executor 8) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,259 | INFO  | [task-result-getter-1] | Finished task 48.0 in stage 7.0 (TID 325) in 10550 ms on dn37 (executor 8) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,259 | INFO  | [task-result-getter-1] | Removed TaskSet 7.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,260 | INFO  | [dag-scheduler-event-loop] | ResultStage 7 (foreachPartition at GraphWriter.scala:455) finished in 16.981 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,262 | INFO  | [Driver] | Job 5 finished: foreachPartition at GraphWriter.scala:455, took 42.991024 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,265 | INFO  | [Driver] | Finished to load entity: entity1. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,266 | INFO  | [Driver] | Start to load entity: entity2. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,326 | INFO  | [Driver] | Starting job: foreachPartition at GraphWriter.scala:455 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,329 | INFO  | [dag-scheduler-event-loop] | Registering RDD 26 (keyBy at GraphWriter.scala:446) as input to shuffle 2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,331 | INFO  | [dag-scheduler-event-loop] | Got job 6 (foreachPartition at GraphWriter.scala:455) with 90 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,331 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 9 (foreachPartition at GraphWriter.scala:455) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,331 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List(ShuffleMapStage 8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,331 | INFO  | [dag-scheduler-event-loop] | Missing parents: List(ShuffleMapStage 8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,334 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 8 (MapPartitionsRDD[26] at keyBy at GraphWriter.scala:446), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,356 | INFO  | [dag-scheduler-event-loop] | Block broadcast_10 stored as values in memory (estimated size 30.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,363 | INFO  | [dag-scheduler-event-loop] | Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,364 | INFO  | [dispatcher-event-loop-2] | Added broadcast_10_piece0 in memory on dn37:22779 (size: 9.6 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,364 | INFO  | [dag-scheduler-event-loop] | Created broadcast 10 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,366 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[26] at keyBy at GraphWriter.scala:446) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,366 | INFO  | [dag-scheduler-event-loop] | Adding task set 8.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,373 | INFO  | [dispatcher-event-loop-9] | Starting task 0.0 in stage 8.0 (TID 364, dn27, executor 7, partition 0, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,373 | INFO  | [dispatcher-event-loop-9] | Starting task 2.0 in stage 8.0 (TID 365, dn28, executor 3, partition 2, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,374 | INFO  | [dispatcher-event-loop-9] | Starting task 9.0 in stage 8.0 (TID 366, dn08, executor 16, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,374 | INFO  | [dispatcher-event-loop-9] | Starting task 3.0 in stage 8.0 (TID 367, dn18, executor 10, partition 3, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,375 | INFO  | [dispatcher-event-loop-9] | Starting task 30.0 in stage 8.0 (TID 368, dn10, executor 19, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,375 | INFO  | [dispatcher-event-loop-9] | Starting task 10.0 in stage 8.0 (TID 369, dn15, executor 12, partition 10, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,376 | INFO  | [dispatcher-event-loop-9] | Starting task 4.0 in stage 8.0 (TID 370, dn37, executor 8, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,376 | INFO  | [dispatcher-event-loop-9] | Starting task 6.0 in stage 8.0 (TID 371, dn29, executor 1, partition 6, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,377 | INFO  | [dispatcher-event-loop-9] | Starting task 36.0 in stage 8.0 (TID 372, dn20, executor 13, partition 36, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,377 | INFO  | [dispatcher-event-loop-9] | Starting task 22.0 in stage 8.0 (TID 373, dn14, executor 17, partition 22, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,378 | INFO  | [dispatcher-event-loop-9] | Starting task 8.0 in stage 8.0 (TID 374, dn34, executor 6, partition 8, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,378 | INFO  | [dispatcher-event-loop-9] | Starting task 16.0 in stage 8.0 (TID 375, dn30, executor 2, partition 16, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,379 | INFO  | [dispatcher-event-loop-9] | Starting task 48.0 in stage 8.0 (TID 376, dn24, executor 9, partition 48, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,379 | INFO  | [dispatcher-event-loop-9] | Starting task 21.0 in stage 8.0 (TID 377, dn19, executor 11, partition 21, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,379 | INFO  | [dispatcher-event-loop-9] | Starting task 20.0 in stage 8.0 (TID 378, dn16, executor 15, partition 20, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,380 | INFO  | [dispatcher-event-loop-9] | Starting task 11.0 in stage 8.0 (TID 379, dn07, executor 14, partition 11, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,380 | INFO  | [dispatcher-event-loop-9] | Starting task 17.0 in stage 8.0 (TID 380, dn17, executor 18, partition 17, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,381 | INFO  | [dispatcher-event-loop-9] | Starting task 1.0 in stage 8.0 (TID 381, dn22, executor 5, partition 1, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,381 | INFO  | [dispatcher-event-loop-9] | Starting task 7.0 in stage 8.0 (TID 382, dn32, executor 4, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,382 | INFO  | [dispatcher-event-loop-9] | Starting task 12.0 in stage 8.0 (TID 383, dn36, executor 20, partition 12, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,382 | INFO  | [dispatcher-event-loop-9] | Starting task 14.0 in stage 8.0 (TID 384, dn27, executor 7, partition 14, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,383 | INFO  | [dispatcher-event-loop-9] | Starting task 15.0 in stage 8.0 (TID 385, dn28, executor 3, partition 15, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,383 | INFO  | [dispatcher-event-loop-9] | Starting task 38.0 in stage 8.0 (TID 386, dn08, executor 16, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,384 | INFO  | [dispatcher-event-loop-9] | Starting task 33.0 in stage 8.0 (TID 387, dn18, executor 10, partition 33, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,384 | INFO  | [dispatcher-event-loop-9] | Starting task 31.0 in stage 8.0 (TID 388, dn10, executor 19, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,385 | INFO  | [dispatcher-event-loop-9] | Starting task 27.0 in stage 8.0 (TID 389, dn15, executor 12, partition 27, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,385 | INFO  | [dispatcher-event-loop-9] | Starting task 43.0 in stage 8.0 (TID 390, dn37, executor 8, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,386 | INFO  | [dispatcher-event-loop-9] | Starting task 23.0 in stage 8.0 (TID 391, dn29, executor 1, partition 23, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,386 | INFO  | [dispatcher-event-loop-9] | Starting task 37.0 in stage 8.0 (TID 392, dn20, executor 13, partition 37, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,386 | INFO  | [dispatcher-event-loop-9] | Starting task 24.0 in stage 8.0 (TID 393, dn14, executor 17, partition 24, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,387 | INFO  | [dispatcher-event-loop-9] | Starting task 32.0 in stage 8.0 (TID 394, dn34, executor 6, partition 32, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,387 | INFO  | [dispatcher-event-loop-9] | Starting task 26.0 in stage 8.0 (TID 395, dn30, executor 2, partition 26, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,387 | INFO  | [dispatcher-event-loop-9] | Starting task 88.0 in stage 8.0 (TID 396, dn24, executor 9, partition 88, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,387 | INFO  | [dispatcher-event-loop-9] | Starting task 53.0 in stage 8.0 (TID 397, dn19, executor 11, partition 53, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,388 | INFO  | [dispatcher-event-loop-9] | Starting task 13.0 in stage 8.0 (TID 398, dn07, executor 14, partition 13, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,388 | INFO  | [dispatcher-event-loop-9] | Starting task 29.0 in stage 8.0 (TID 399, dn17, executor 18, partition 29, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,388 | INFO  | [dispatcher-event-loop-9] | Starting task 5.0 in stage 8.0 (TID 400, dn22, executor 5, partition 5, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,389 | INFO  | [dispatcher-event-loop-9] | Starting task 40.0 in stage 8.0 (TID 401, dn32, executor 4, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,389 | INFO  | [dispatcher-event-loop-9] | Starting task 68.0 in stage 8.0 (TID 402, dn36, executor 20, partition 68, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,406 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn36:22756 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,407 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn08:22604 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,408 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn10:22719 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,408 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn24:22839 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,409 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn29:22705 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,409 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn28:22784 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,410 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn15:22640 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,411 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn37:22861 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,411 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn30:22608 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,412 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn18:22756 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,413 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn07:22897 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,413 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn20:22825 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,414 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn16:22668 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,415 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn27:22790 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,416 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn19:22830 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,416 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn17:22761 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,417 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn34:22620 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,417 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn22:22834 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,417 | INFO  | [dispatcher-event-loop-5] | Added broadcast_10_piece0 in memory on dn14:22891 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:37,432 | INFO  | [dispatcher-event-loop-31] | Added broadcast_10_piece0 in memory on dn32:22787 (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:40,673 | INFO  | [dispatcher-event-loop-23] | Starting task 18.0 in stage 8.0 (TID 403, dn16, executor 15, partition 18, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:48,849 | INFO  | [dispatcher-event-loop-17] | Starting task 84.0 in stage 8.0 (TID 404, dn36, executor 20, partition 84, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:48,850 | INFO  | [task-result-getter-0] | Finished task 12.0 in stage 8.0 (TID 383) in 11469 ms on dn36 (executor 20) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:48,895 | INFO  | [task-result-getter-3] | Finished task 68.0 in stage 8.0 (TID 402) in 11506 ms on dn36 (executor 20) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:48,994 | INFO  | [dispatcher-event-loop-10] | Starting task 55.0 in stage 8.0 (TID 405, dn37, executor 8, partition 55, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:48,994 | INFO  | [task-result-getter-2] | Finished task 43.0 in stage 8.0 (TID 390) in 11609 ms on dn37 (executor 8) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,140 | INFO  | [dispatcher-event-loop-2] | Starting task 64.0 in stage 8.0 (TID 406, dn37, executor 8, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,141 | INFO  | [task-result-getter-1] | Finished task 4.0 in stage 8.0 (TID 370) in 11765 ms on dn37 (executor 8) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,420 | INFO  | [dispatcher-event-loop-12] | Starting task 76.0 in stage 8.0 (TID 407, dn07, executor 14, partition 76, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,421 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 8.0 (TID 379) in 12041 ms on dn07 (executor 14) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,616 | INFO  | [dispatcher-event-loop-19] | Starting task 89.0 in stage 8.0 (TID 408, dn24, executor 9, partition 89, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,617 | INFO  | [task-result-getter-3] | Finished task 48.0 in stage 8.0 (TID 376) in 12239 ms on dn24 (executor 9) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,619 | INFO  | [task-result-getter-2] | Finished task 88.0 in stage 8.0 (TID 396) in 12232 ms on dn24 (executor 9) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,628 | INFO  | [dispatcher-event-loop-18] | Starting task 19.0 in stage 8.0 (TID 409, dn27, executor 7, partition 19, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,629 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 8.0 (TID 364) in 12257 ms on dn27 (executor 7) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,684 | INFO  | [dispatcher-event-loop-6] | Starting task 44.0 in stage 8.0 (TID 410, dn22, executor 5, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,685 | INFO  | [task-result-getter-0] | Finished task 5.0 in stage 8.0 (TID 400) in 12297 ms on dn22 (executor 5) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,701 | INFO  | [dispatcher-event-loop-24] | Starting task 46.0 in stage 8.0 (TID 411, dn27, executor 7, partition 46, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,702 | INFO  | [task-result-getter-3] | Finished task 14.0 in stage 8.0 (TID 384) in 12320 ms on dn27 (executor 7) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,729 | INFO  | [dispatcher-event-loop-32] | Starting task 77.0 in stage 8.0 (TID 412, dn07, executor 14, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,729 | INFO  | [task-result-getter-2] | Finished task 13.0 in stage 8.0 (TID 398) in 12341 ms on dn07 (executor 14) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,802 | INFO  | [dispatcher-event-loop-21] | Starting task 45.0 in stage 8.0 (TID 413, dn22, executor 5, partition 45, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,803 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 8.0 (TID 381) in 12422 ms on dn22 (executor 5) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,850 | INFO  | [dispatcher-event-loop-13] | Starting task 78.0 in stage 8.0 (TID 414, dn18, executor 10, partition 78, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,850 | INFO  | [task-result-getter-0] | Finished task 3.0 in stage 8.0 (TID 367) in 12476 ms on dn18 (executor 10) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:49,908 | INFO  | [task-result-getter-3] | Finished task 20.0 in stage 8.0 (TID 378) in 12529 ms on dn16 (executor 15) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,060 | INFO  | [dispatcher-event-loop-23] | Starting task 85.0 in stage 8.0 (TID 415, dn18, executor 10, partition 85, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,060 | INFO  | [task-result-getter-2] | Finished task 33.0 in stage 8.0 (TID 387) in 12676 ms on dn18 (executor 10) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,302 | INFO  | [dispatcher-event-loop-28] | Starting task 54.0 in stage 8.0 (TID 416, dn29, executor 1, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,303 | INFO  | [task-result-getter-1] | Finished task 23.0 in stage 8.0 (TID 391) in 12917 ms on dn29 (executor 1) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,336 | INFO  | [dispatcher-event-loop-40] | Starting task 58.0 in stage 8.0 (TID 417, dn32, executor 4, partition 58, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,336 | INFO  | [task-result-getter-0] | Finished task 7.0 in stage 8.0 (TID 382) in 12955 ms on dn32 (executor 4) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,449 | INFO  | [dispatcher-event-loop-34] | Starting task 65.0 in stage 8.0 (TID 418, dn17, executor 18, partition 65, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,449 | INFO  | [task-result-getter-3] | Finished task 17.0 in stage 8.0 (TID 380) in 13069 ms on dn17 (executor 18) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,459 | INFO  | [dispatcher-event-loop-4] | Starting task 59.0 in stage 8.0 (TID 419, dn19, executor 11, partition 59, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,459 | INFO  | [task-result-getter-2] | Finished task 21.0 in stage 8.0 (TID 377) in 13080 ms on dn19 (executor 11) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,463 | INFO  | [dispatcher-event-loop-41] | Starting task 80.0 in stage 8.0 (TID 420, dn08, executor 16, partition 80, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,463 | INFO  | [task-result-getter-1] | Finished task 9.0 in stage 8.0 (TID 366) in 13089 ms on dn08 (executor 16) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,494 | INFO  | [task-result-getter-0] | Finished task 40.0 in stage 8.0 (TID 401) in 13105 ms on dn32 (executor 4) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,518 | INFO  | [dispatcher-event-loop-51] | Starting task 75.0 in stage 8.0 (TID 421, dn28, executor 3, partition 75, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,519 | INFO  | [task-result-getter-3] | Finished task 15.0 in stage 8.0 (TID 385) in 13136 ms on dn28 (executor 3) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,534 | INFO  | [dispatcher-event-loop-48] | Starting task 56.0 in stage 8.0 (TID 422, dn29, executor 1, partition 56, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,534 | INFO  | [task-result-getter-2] | Finished task 6.0 in stage 8.0 (TID 371) in 13158 ms on dn29 (executor 1) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,545 | INFO  | [dispatcher-event-loop-58] | Starting task 81.0 in stage 8.0 (TID 423, dn08, executor 16, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,545 | INFO  | [task-result-getter-1] | Finished task 38.0 in stage 8.0 (TID 386) in 13162 ms on dn08 (executor 16) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,579 | INFO  | [dispatcher-event-loop-66] | Starting task 66.0 in stage 8.0 (TID 424, dn17, executor 18, partition 66, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,579 | INFO  | [task-result-getter-0] | Finished task 29.0 in stage 8.0 (TID 399) in 13191 ms on dn17 (executor 18) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,582 | INFO  | [dispatcher-event-loop-53] | Starting task 86.0 in stage 8.0 (TID 425, dn19, executor 11, partition 86, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,582 | INFO  | [task-result-getter-3] | Finished task 53.0 in stage 8.0 (TID 397) in 13195 ms on dn19 (executor 11) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,624 | INFO  | [dispatcher-event-loop-63] | Starting task 82.0 in stage 8.0 (TID 426, dn28, executor 3, partition 82, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,625 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 8.0 (TID 365) in 13252 ms on dn28 (executor 3) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,686 | INFO  | [dispatcher-event-loop-67] | Starting task 79.0 in stage 8.0 (TID 427, dn20, executor 13, partition 79, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,686 | INFO  | [task-result-getter-1] | Finished task 37.0 in stage 8.0 (TID 392) in 13300 ms on dn20 (executor 13) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,790 | INFO  | [task-result-getter-0] | Finished task 36.0 in stage 8.0 (TID 372) in 13414 ms on dn20 (executor 13) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,800 | INFO  | [dispatcher-event-loop-69] | Starting task 83.0 in stage 8.0 (TID 428, dn15, executor 12, partition 83, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,801 | INFO  | [task-result-getter-3] | Finished task 27.0 in stage 8.0 (TID 389) in 13416 ms on dn15 (executor 12) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:50,817 | INFO  | [task-result-getter-2] | Finished task 10.0 in stage 8.0 (TID 369) in 13442 ms on dn15 (executor 12) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,014 | INFO  | [dispatcher-event-loop-71] | Starting task 47.0 in stage 8.0 (TID 429, dn10, executor 19, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,014 | INFO  | [task-result-getter-1] | Finished task 31.0 in stage 8.0 (TID 388) in 13630 ms on dn10 (executor 19) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,079 | INFO  | [task-result-getter-0] | Finished task 30.0 in stage 8.0 (TID 368) in 13704 ms on dn10 (executor 19) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,693 | INFO  | [dispatcher-event-loop-57] | Starting task 42.0 in stage 8.0 (TID 430, dn34, executor 6, partition 42, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,694 | INFO  | [task-result-getter-3] | Finished task 32.0 in stage 8.0 (TID 394) in 14308 ms on dn34 (executor 6) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,831 | INFO  | [dispatcher-event-loop-10] | Starting task 52.0 in stage 8.0 (TID 431, dn34, executor 6, partition 52, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:51,831 | INFO  | [task-result-getter-2] | Finished task 8.0 in stage 8.0 (TID 374) in 14454 ms on dn34 (executor 6) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,040 | INFO  | [dispatcher-event-loop-2] | Starting task 28.0 in stage 8.0 (TID 432, dn30, executor 2, partition 28, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,041 | INFO  | [task-result-getter-1] | Finished task 16.0 in stage 8.0 (TID 375) in 14662 ms on dn30 (executor 2) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,041 | INFO  | [dispatcher-event-loop-2] | Starting task 50.0 in stage 8.0 (TID 433, dn30, executor 2, partition 50, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,042 | INFO  | [task-result-getter-0] | Finished task 26.0 in stage 8.0 (TID 395) in 14655 ms on dn30 (executor 2) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,728 | INFO  | [task-result-getter-3] | Finished task 18.0 in stage 8.0 (TID 403) in 12056 ms on dn16 (executor 15) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,766 | INFO  | [dispatcher-event-loop-6] | Starting task 25.0 in stage 8.0 (TID 434, dn14, executor 17, partition 25, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,766 | INFO  | [task-result-getter-2] | Finished task 22.0 in stage 8.0 (TID 373) in 15389 ms on dn14 (executor 17) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,846 | INFO  | [dispatcher-event-loop-24] | Starting task 62.0 in stage 8.0 (TID 435, dn14, executor 17, partition 62, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:52,847 | INFO  | [task-result-getter-1] | Finished task 24.0 in stage 8.0 (TID 393) in 15461 ms on dn14 (executor 17) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,673 | INFO  | [dispatcher-event-loop-56] | Starting task 34.0 in stage 8.0 (TID 436, dn20, executor 13, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,674 | INFO  | [dispatcher-event-loop-56] | Starting task 35.0 in stage 8.0 (TID 437, dn32, executor 4, partition 35, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,675 | INFO  | [dispatcher-event-loop-56] | Starting task 39.0 in stage 8.0 (TID 438, dn16, executor 15, partition 39, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,676 | INFO  | [dispatcher-event-loop-56] | Starting task 41.0 in stage 8.0 (TID 439, dn15, executor 12, partition 41, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,676 | INFO  | [dispatcher-event-loop-56] | Starting task 49.0 in stage 8.0 (TID 440, dn10, executor 19, partition 49, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,677 | INFO  | [dispatcher-event-loop-56] | Starting task 51.0 in stage 8.0 (TID 441, dn24, executor 9, partition 51, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,678 | INFO  | [dispatcher-event-loop-56] | Starting task 57.0 in stage 8.0 (TID 442, dn36, executor 20, partition 57, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:43:56,678 | INFO  | [dispatcher-event-loop-56] | Starting task 60.0 in stage 8.0 (TID 443, dn16, executor 15, partition 60, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,001 | INFO  | [dispatcher-event-loop-54] | Starting task 61.0 in stage 8.0 (TID 444, dn37, executor 8, partition 61, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,001 | INFO  | [task-result-getter-0] | Finished task 55.0 in stage 8.0 (TID 405) in 11008 ms on dn37 (executor 8) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,100 | INFO  | [dispatcher-event-loop-69] | Starting task 63.0 in stage 8.0 (TID 445, dn36, executor 20, partition 63, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,101 | INFO  | [task-result-getter-3] | Finished task 84.0 in stage 8.0 (TID 404) in 11253 ms on dn36 (executor 20) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,309 | INFO  | [dispatcher-event-loop-68] | Starting task 67.0 in stage 8.0 (TID 446, dn37, executor 8, partition 67, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,309 | INFO  | [task-result-getter-2] | Finished task 64.0 in stage 8.0 (TID 406) in 11169 ms on dn37 (executor 8) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,480 | INFO  | [dispatcher-event-loop-1] | Starting task 69.0 in stage 8.0 (TID 447, dn24, executor 9, partition 69, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,481 | INFO  | [task-result-getter-1] | Finished task 89.0 in stage 8.0 (TID 408) in 10865 ms on dn24 (executor 9) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,864 | INFO  | [dispatcher-event-loop-10] | Starting task 71.0 in stage 8.0 (TID 448, dn22, executor 5, partition 71, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:00,865 | INFO  | [task-result-getter-0] | Finished task 44.0 in stage 8.0 (TID 410) in 11181 ms on dn22 (executor 5) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:01,206 | INFO  | [task-result-getter-3] | Finished task 76.0 in stage 8.0 (TID 407) in 11786 ms on dn07 (executor 14) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:01,209 | INFO  | [dispatcher-event-loop-25] | Starting task 74.0 in stage 8.0 (TID 449, dn22, executor 5, partition 74, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:01,209 | INFO  | [task-result-getter-2] | Finished task 45.0 in stage 8.0 (TID 413) in 11407 ms on dn22 (executor 5) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:01,234 | INFO  | [task-result-getter-1] | Finished task 77.0 in stage 8.0 (TID 412) in 11506 ms on dn07 (executor 14) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:01,710 | INFO  | [task-result-getter-0] | Finished task 19.0 in stage 8.0 (TID 409) in 12082 ms on dn27 (executor 7) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:01,806 | INFO  | [task-result-getter-3] | Finished task 46.0 in stage 8.0 (TID 411) in 12105 ms on dn27 (executor 7) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,240 | INFO  | [task-result-getter-2] | Finished task 79.0 in stage 8.0 (TID 427) in 11555 ms on dn20 (executor 13) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,302 | INFO  | [task-result-getter-1] | Finished task 81.0 in stage 8.0 (TID 423) in 11758 ms on dn08 (executor 16) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,399 | INFO  | [dispatcher-event-loop-22] | Starting task 70.0 in stage 8.0 (TID 450, dn17, executor 18, partition 70, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,400 | INFO  | [task-result-getter-0] | Finished task 65.0 in stage 8.0 (TID 418) in 11952 ms on dn17 (executor 18) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,456 | INFO  | [task-result-getter-3] | Finished task 78.0 in stage 8.0 (TID 414) in 12607 ms on dn18 (executor 10) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,601 | INFO  | [task-result-getter-2] | Finished task 80.0 in stage 8.0 (TID 420) in 12138 ms on dn08 (executor 16) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,817 | INFO  | [task-result-getter-1] | Finished task 85.0 in stage 8.0 (TID 415) in 12758 ms on dn18 (executor 10) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,871 | INFO  | [task-result-getter-0] | Finished task 66.0 in stage 8.0 (TID 424) in 12291 ms on dn17 (executor 18) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,892 | INFO  | [task-result-getter-3] | Finished task 75.0 in stage 8.0 (TID 421) in 12374 ms on dn28 (executor 3) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,992 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 8.0 (TID 417) in 12656 ms on dn32 (executor 4) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,998 | INFO  | [dispatcher-event-loop-49] | Starting task 87.0 in stage 8.0 (TID 451, dn19, executor 11, partition 87, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:02,999 | INFO  | [task-result-getter-1] | Finished task 59.0 in stage 8.0 (TID 419) in 12541 ms on dn19 (executor 11) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,100 | INFO  | [task-result-getter-0] | Finished task 83.0 in stage 8.0 (TID 428) in 12300 ms on dn15 (executor 12) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,195 | INFO  | [task-result-getter-3] | Finished task 82.0 in stage 8.0 (TID 426) in 12571 ms on dn28 (executor 3) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,462 | INFO  | [dispatcher-event-loop-34] | Starting task 73.0 in stage 8.0 (TID 452, dn29, executor 1, partition 73, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,462 | INFO  | [task-result-getter-2] | Finished task 54.0 in stage 8.0 (TID 416) in 13160 ms on dn29 (executor 1) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,527 | INFO  | [task-result-getter-1] | Finished task 86.0 in stage 8.0 (TID 425) in 12945 ms on dn19 (executor 11) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,804 | INFO  | [task-result-getter-0] | Finished task 56.0 in stage 8.0 (TID 422) in 13271 ms on dn29 (executor 1) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:03,877 | INFO  | [task-result-getter-3] | Finished task 47.0 in stage 8.0 (TID 429) in 12864 ms on dn10 (executor 19) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:05,024 | INFO  | [task-result-getter-2] | Finished task 42.0 in stage 8.0 (TID 430) in 13331 ms on dn34 (executor 6) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:05,147 | INFO  | [task-result-getter-1] | Finished task 52.0 in stage 8.0 (TID 431) in 13317 ms on dn34 (executor 6) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:05,984 | INFO  | [dispatcher-event-loop-55] | Starting task 72.0 in stage 8.0 (TID 453, dn14, executor 17, partition 72, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:05,987 | INFO  | [task-result-getter-0] | Finished task 25.0 in stage 8.0 (TID 434) in 13221 ms on dn14 (executor 17) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:06,410 | INFO  | [task-result-getter-3] | Finished task 62.0 in stage 8.0 (TID 435) in 13565 ms on dn14 (executor 17) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:06,434 | INFO  | [task-result-getter-2] | Finished task 28.0 in stage 8.0 (TID 432) in 14394 ms on dn30 (executor 2) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:06,529 | INFO  | [task-result-getter-1] | Finished task 50.0 in stage 8.0 (TID 433) in 14488 ms on dn30 (executor 2) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:07,275 | INFO  | [task-result-getter-0] | Finished task 51.0 in stage 8.0 (TID 441) in 10598 ms on dn24 (executor 9) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:08,203 | INFO  | [task-result-getter-3] | Finished task 57.0 in stage 8.0 (TID 442) in 11526 ms on dn36 (executor 20) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:08,592 | INFO  | [task-result-getter-2] | Finished task 41.0 in stage 8.0 (TID 439) in 11917 ms on dn15 (executor 12) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:08,620 | INFO  | [task-result-getter-1] | Finished task 35.0 in stage 8.0 (TID 437) in 11946 ms on dn32 (executor 4) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:08,808 | INFO  | [task-result-getter-0] | Finished task 34.0 in stage 8.0 (TID 436) in 12134 ms on dn20 (executor 13) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:08,841 | INFO  | [task-result-getter-3] | Finished task 60.0 in stage 8.0 (TID 443) in 12163 ms on dn16 (executor 15) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:08,881 | INFO  | [task-result-getter-2] | Finished task 39.0 in stage 8.0 (TID 438) in 12206 ms on dn16 (executor 15) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:09,457 | INFO  | [task-result-getter-1] | Finished task 49.0 in stage 8.0 (TID 440) in 12781 ms on dn10 (executor 19) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:10,507 | INFO  | [task-result-getter-0] | Finished task 69.0 in stage 8.0 (TID 447) in 10027 ms on dn24 (executor 9) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:10,699 | INFO  | [task-result-getter-3] | Finished task 61.0 in stage 8.0 (TID 444) in 10699 ms on dn37 (executor 8) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:10,718 | INFO  | [task-result-getter-2] | Finished task 63.0 in stage 8.0 (TID 445) in 10618 ms on dn36 (executor 20) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:10,898 | INFO  | [task-result-getter-1] | Finished task 67.0 in stage 8.0 (TID 446) in 10590 ms on dn37 (executor 8) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:11,586 | INFO  | [task-result-getter-0] | Finished task 71.0 in stage 8.0 (TID 448) in 10722 ms on dn22 (executor 5) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:12,171 | INFO  | [task-result-getter-3] | Finished task 74.0 in stage 8.0 (TID 449) in 10963 ms on dn22 (executor 5) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:14,150 | INFO  | [task-result-getter-2] | Finished task 70.0 in stage 8.0 (TID 450) in 11751 ms on dn17 (executor 18) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:14,991 | INFO  | [task-result-getter-1] | Finished task 73.0 in stage 8.0 (TID 452) in 11530 ms on dn29 (executor 1) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:15,708 | INFO  | [task-result-getter-0] | Finished task 87.0 in stage 8.0 (TID 451) in 12710 ms on dn19 (executor 11) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,663 | INFO  | [task-result-getter-3] | Finished task 72.0 in stage 8.0 (TID 453) in 14679 ms on dn14 (executor 17) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,663 | INFO  | [task-result-getter-3] | Removed TaskSet 8.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,664 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 8 (keyBy at GraphWriter.scala:446) finished in 43.314 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,665 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,665 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,665 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,665 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,667 | INFO  | [dag-scheduler-event-loop] | Submitting ResultStage 9 (MapPartitionsRDD[28] at values at GraphWriter.scala:455), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,696 | INFO  | [dag-scheduler-event-loop] | Block broadcast_11 stored as values in memory (estimated size 7.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,700 | INFO  | [dag-scheduler-event-loop] | Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.1 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,701 | INFO  | [dispatcher-event-loop-19] | Added broadcast_11_piece0 in memory on dn37:22779 (size: 4.1 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,702 | INFO  | [dag-scheduler-event-loop] | Created broadcast 11 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,704 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ResultStage 9 (MapPartitionsRDD[28] at values at GraphWriter.scala:455) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,704 | INFO  | [dag-scheduler-event-loop] | Adding task set 9.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,706 | INFO  | [dispatcher-event-loop-14] | Starting task 0.0 in stage 9.0 (TID 454, dn37, executor 8, partition 0, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,707 | INFO  | [dispatcher-event-loop-14] | Starting task 1.0 in stage 9.0 (TID 455, dn10, executor 19, partition 1, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,707 | INFO  | [dispatcher-event-loop-14] | Starting task 2.0 in stage 9.0 (TID 456, dn27, executor 7, partition 2, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,708 | INFO  | [dispatcher-event-loop-14] | Starting task 3.0 in stage 9.0 (TID 457, dn24, executor 9, partition 3, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,708 | INFO  | [dispatcher-event-loop-14] | Starting task 4.0 in stage 9.0 (TID 458, dn15, executor 12, partition 4, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,709 | INFO  | [dispatcher-event-loop-14] | Starting task 5.0 in stage 9.0 (TID 459, dn16, executor 15, partition 5, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,709 | INFO  | [dispatcher-event-loop-14] | Starting task 6.0 in stage 9.0 (TID 460, dn17, executor 18, partition 6, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,709 | INFO  | [dispatcher-event-loop-14] | Starting task 7.0 in stage 9.0 (TID 461, dn28, executor 3, partition 7, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,710 | INFO  | [dispatcher-event-loop-14] | Starting task 8.0 in stage 9.0 (TID 462, dn36, executor 20, partition 8, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,710 | INFO  | [dispatcher-event-loop-14] | Starting task 9.0 in stage 9.0 (TID 463, dn34, executor 6, partition 9, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,710 | INFO  | [dispatcher-event-loop-14] | Starting task 10.0 in stage 9.0 (TID 464, dn18, executor 10, partition 10, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,711 | INFO  | [dispatcher-event-loop-14] | Starting task 11.0 in stage 9.0 (TID 465, dn08, executor 16, partition 11, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,711 | INFO  | [dispatcher-event-loop-14] | Starting task 12.0 in stage 9.0 (TID 466, dn20, executor 13, partition 12, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,712 | INFO  | [dispatcher-event-loop-14] | Starting task 13.0 in stage 9.0 (TID 467, dn14, executor 17, partition 13, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,712 | INFO  | [dispatcher-event-loop-14] | Starting task 14.0 in stage 9.0 (TID 468, dn29, executor 1, partition 14, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,712 | INFO  | [dispatcher-event-loop-14] | Starting task 15.0 in stage 9.0 (TID 469, dn30, executor 2, partition 15, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,713 | INFO  | [dispatcher-event-loop-14] | Starting task 16.0 in stage 9.0 (TID 470, dn32, executor 4, partition 16, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,713 | INFO  | [dispatcher-event-loop-14] | Starting task 17.0 in stage 9.0 (TID 471, dn07, executor 14, partition 17, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,713 | INFO  | [dispatcher-event-loop-14] | Starting task 18.0 in stage 9.0 (TID 472, dn19, executor 11, partition 18, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,714 | INFO  | [dispatcher-event-loop-14] | Starting task 19.0 in stage 9.0 (TID 473, dn22, executor 5, partition 19, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,714 | INFO  | [dispatcher-event-loop-14] | Starting task 20.0 in stage 9.0 (TID 474, dn37, executor 8, partition 20, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,714 | INFO  | [dispatcher-event-loop-14] | Starting task 21.0 in stage 9.0 (TID 475, dn10, executor 19, partition 21, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,715 | INFO  | [dispatcher-event-loop-14] | Starting task 22.0 in stage 9.0 (TID 476, dn27, executor 7, partition 22, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,715 | INFO  | [dispatcher-event-loop-14] | Starting task 23.0 in stage 9.0 (TID 477, dn24, executor 9, partition 23, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,715 | INFO  | [dispatcher-event-loop-14] | Starting task 24.0 in stage 9.0 (TID 478, dn15, executor 12, partition 24, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,716 | INFO  | [dispatcher-event-loop-14] | Starting task 25.0 in stage 9.0 (TID 479, dn16, executor 15, partition 25, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,716 | INFO  | [dispatcher-event-loop-14] | Starting task 26.0 in stage 9.0 (TID 480, dn17, executor 18, partition 26, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,716 | INFO  | [dispatcher-event-loop-14] | Starting task 27.0 in stage 9.0 (TID 481, dn28, executor 3, partition 27, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,717 | INFO  | [dispatcher-event-loop-14] | Starting task 28.0 in stage 9.0 (TID 482, dn36, executor 20, partition 28, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,717 | INFO  | [dispatcher-event-loop-14] | Starting task 29.0 in stage 9.0 (TID 483, dn34, executor 6, partition 29, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,717 | INFO  | [dispatcher-event-loop-14] | Starting task 30.0 in stage 9.0 (TID 484, dn18, executor 10, partition 30, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,718 | INFO  | [dispatcher-event-loop-14] | Starting task 31.0 in stage 9.0 (TID 485, dn08, executor 16, partition 31, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,718 | INFO  | [dispatcher-event-loop-14] | Starting task 32.0 in stage 9.0 (TID 486, dn20, executor 13, partition 32, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,718 | INFO  | [dispatcher-event-loop-14] | Starting task 33.0 in stage 9.0 (TID 487, dn14, executor 17, partition 33, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,719 | INFO  | [dispatcher-event-loop-14] | Starting task 34.0 in stage 9.0 (TID 488, dn29, executor 1, partition 34, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,719 | INFO  | [dispatcher-event-loop-14] | Starting task 35.0 in stage 9.0 (TID 489, dn30, executor 2, partition 35, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,719 | INFO  | [dispatcher-event-loop-14] | Starting task 36.0 in stage 9.0 (TID 490, dn32, executor 4, partition 36, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,720 | INFO  | [dispatcher-event-loop-14] | Starting task 37.0 in stage 9.0 (TID 491, dn07, executor 14, partition 37, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,720 | INFO  | [dispatcher-event-loop-14] | Starting task 38.0 in stage 9.0 (TID 492, dn19, executor 11, partition 38, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,720 | INFO  | [dispatcher-event-loop-14] | Starting task 39.0 in stage 9.0 (TID 493, dn22, executor 5, partition 39, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,736 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn34:22620 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,737 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn24:22839 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,738 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn29:22705 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,739 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn36:22756 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,739 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn08:22604 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,740 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn37:22861 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,740 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn32:22787 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,741 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn22:22834 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,742 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn10:22719 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,742 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn18:22756 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,743 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn27:22790 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,744 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn17:22761 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,745 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn28:22784 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,745 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn15:22640 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,746 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn30:22608 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,746 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn14:22891 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,747 | INFO  | [dispatcher-event-loop-30] | Asked to send map output locations for shuffle 2 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,747 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn20:22825 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,749 | INFO  | [dispatcher-event-loop-32] | Asked to send map output locations for shuffle 2 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,749 | INFO  | [dispatcher-event-loop-22] | Asked to send map output locations for shuffle 2 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,750 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn16:22668 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,750 | INFO  | [dispatcher-event-loop-57] | Added broadcast_11_piece0 in memory on dn19:22830 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,750 | INFO  | [dispatcher-event-loop-21] | Asked to send map output locations for shuffle 2 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,751 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 2 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,751 | INFO  | [dispatcher-event-loop-42] | Added broadcast_11_piece0 in memory on dn07:22897 (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,751 | INFO  | [dispatcher-event-loop-23] | Asked to send map output locations for shuffle 2 to *.*.132.40:54846 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,751 | INFO  | [dispatcher-event-loop-26] | Asked to send map output locations for shuffle 2 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,752 | INFO  | [dispatcher-event-loop-39] | Asked to send map output locations for shuffle 2 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,752 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 2 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,753 | INFO  | [dispatcher-event-loop-28] | Asked to send map output locations for shuffle 2 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,754 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 2 to *.*.132.15:57922 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,756 | INFO  | [dispatcher-event-loop-40] | Asked to send map output locations for shuffle 2 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,759 | INFO  | [dispatcher-event-loop-49] | Asked to send map output locations for shuffle 2 to *.*.132.38:54888 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,761 | INFO  | [dispatcher-event-loop-38] | Asked to send map output locations for shuffle 2 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,761 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 2 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,761 | INFO  | [dispatcher-event-loop-47] | Asked to send map output locations for shuffle 2 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,761 | INFO  | [dispatcher-event-loop-11] | Asked to send map output locations for shuffle 2 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,763 | INFO  | [dispatcher-event-loop-34] | Asked to send map output locations for shuffle 2 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,763 | INFO  | [dispatcher-event-loop-44] | Asked to send map output locations for shuffle 2 to *.*.132.21:46253 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:44:20,765 | INFO  | [dispatcher-event-loop-56] | Asked to send map output locations for shuffle 2 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:52,655 | INFO  | [dispatcher-event-loop-30] | Starting task 40.0 in stage 9.0 (TID 494, dn24, executor 9, partition 40, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:52,657 | INFO  | [task-result-getter-2] | Finished task 23.0 in stage 9.0 (TID 477) in 511942 ms on dn24 (executor 9) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:53,613 | INFO  | [dispatcher-event-loop-13] | Starting task 41.0 in stage 9.0 (TID 495, dn36, executor 20, partition 41, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:53,614 | INFO  | [task-result-getter-1] | Finished task 8.0 in stage 9.0 (TID 462) in 512904 ms on dn36 (executor 20) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:55,120 | INFO  | [dispatcher-event-loop-40] | Starting task 42.0 in stage 9.0 (TID 496, dn36, executor 20, partition 42, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:55,121 | INFO  | [task-result-getter-0] | Finished task 28.0 in stage 9.0 (TID 482) in 514404 ms on dn36 (executor 20) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:55,598 | INFO  | [dispatcher-event-loop-34] | Starting task 43.0 in stage 9.0 (TID 497, dn29, executor 1, partition 43, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:55,599 | INFO  | [task-result-getter-3] | Finished task 14.0 in stage 9.0 (TID 468) in 514887 ms on dn29 (executor 1) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:56,595 | INFO  | [dispatcher-event-loop-48] | Starting task 44.0 in stage 9.0 (TID 498, dn29, executor 1, partition 44, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:56,595 | INFO  | [task-result-getter-2] | Finished task 34.0 in stage 9.0 (TID 488) in 515876 ms on dn29 (executor 1) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:58,663 | INFO  | [dispatcher-event-loop-54] | Starting task 45.0 in stage 9.0 (TID 499, dn16, executor 15, partition 45, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:52:58,664 | INFO  | [task-result-getter-1] | Finished task 5.0 in stage 9.0 (TID 459) in 517956 ms on dn16 (executor 15) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:02,256 | INFO  | [dispatcher-event-loop-2] | Starting task 46.0 in stage 9.0 (TID 500, dn17, executor 18, partition 46, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:02,257 | INFO  | [task-result-getter-0] | Finished task 26.0 in stage 9.0 (TID 480) in 521541 ms on dn17 (executor 18) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:02,540 | INFO  | [dispatcher-event-loop-14] | Starting task 47.0 in stage 9.0 (TID 501, dn19, executor 11, partition 47, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:02,541 | INFO  | [task-result-getter-3] | Finished task 38.0 in stage 9.0 (TID 492) in 521821 ms on dn19 (executor 11) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:03,414 | INFO  | [dispatcher-event-loop-6] | Starting task 48.0 in stage 9.0 (TID 502, dn24, executor 9, partition 48, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:03,415 | INFO  | [task-result-getter-2] | Finished task 3.0 in stage 9.0 (TID 457) in 522707 ms on dn24 (executor 9) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:03,615 | INFO  | [dispatcher-event-loop-20] | Starting task 49.0 in stage 9.0 (TID 503, dn18, executor 10, partition 49, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:03,616 | INFO  | [task-result-getter-1] | Finished task 10.0 in stage 9.0 (TID 464) in 522906 ms on dn18 (executor 10) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:05,807 | INFO  | [dispatcher-event-loop-49] | Starting task 50.0 in stage 9.0 (TID 504, dn28, executor 3, partition 50, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:05,807 | INFO  | [task-result-getter-0] | Finished task 7.0 in stage 9.0 (TID 461) in 525098 ms on dn28 (executor 3) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:05,998 | INFO  | [dispatcher-event-loop-11] | Starting task 51.0 in stage 9.0 (TID 505, dn32, executor 4, partition 51, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:05,999 | INFO  | [task-result-getter-3] | Finished task 16.0 in stage 9.0 (TID 470) in 525286 ms on dn32 (executor 4) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:08,657 | INFO  | [dispatcher-event-loop-45] | Starting task 52.0 in stage 9.0 (TID 506, dn18, executor 10, partition 52, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:08,658 | INFO  | [task-result-getter-2] | Finished task 30.0 in stage 9.0 (TID 484) in 527941 ms on dn18 (executor 10) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:09,215 | INFO  | [dispatcher-event-loop-50] | Starting task 53.0 in stage 9.0 (TID 507, dn07, executor 14, partition 53, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:09,216 | INFO  | [task-result-getter-1] | Finished task 37.0 in stage 9.0 (TID 491) in 528496 ms on dn07 (executor 14) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:09,841 | INFO  | [dispatcher-event-loop-62] | Starting task 54.0 in stage 9.0 (TID 508, dn30, executor 2, partition 54, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:09,841 | INFO  | [task-result-getter-0] | Finished task 15.0 in stage 9.0 (TID 469) in 529129 ms on dn30 (executor 2) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:09,891 | INFO  | [dispatcher-event-loop-54] | Starting task 55.0 in stage 9.0 (TID 509, dn22, executor 5, partition 55, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:09,891 | INFO  | [task-result-getter-3] | Finished task 39.0 in stage 9.0 (TID 493) in 529171 ms on dn22 (executor 5) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:10,497 | INFO  | [dispatcher-event-loop-0] | Starting task 56.0 in stage 9.0 (TID 510, dn16, executor 15, partition 56, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:10,498 | INFO  | [task-result-getter-2] | Finished task 25.0 in stage 9.0 (TID 479) in 529782 ms on dn16 (executor 15) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:10,903 | INFO  | [dispatcher-event-loop-1] | Starting task 57.0 in stage 9.0 (TID 511, dn34, executor 6, partition 57, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:10,904 | INFO  | [task-result-getter-1] | Finished task 29.0 in stage 9.0 (TID 483) in 530187 ms on dn34 (executor 6) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:11,274 | INFO  | [dispatcher-event-loop-10] | Starting task 58.0 in stage 9.0 (TID 512, dn20, executor 13, partition 58, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:11,274 | INFO  | [task-result-getter-0] | Finished task 32.0 in stage 9.0 (TID 486) in 530556 ms on dn20 (executor 13) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:11,607 | INFO  | [dispatcher-event-loop-9] | Starting task 59.0 in stage 9.0 (TID 513, dn28, executor 3, partition 59, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:11,608 | INFO  | [task-result-getter-3] | Finished task 27.0 in stage 9.0 (TID 481) in 530892 ms on dn28 (executor 3) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:12,393 | INFO  | [dispatcher-event-loop-18] | Starting task 60.0 in stage 9.0 (TID 514, dn19, executor 11, partition 60, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:12,394 | INFO  | [task-result-getter-2] | Finished task 18.0 in stage 9.0 (TID 472) in 531681 ms on dn19 (executor 11) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:13,557 | INFO  | [dispatcher-event-loop-32] | Starting task 61.0 in stage 9.0 (TID 515, dn30, executor 2, partition 61, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:13,557 | INFO  | [task-result-getter-1] | Finished task 35.0 in stage 9.0 (TID 489) in 532838 ms on dn30 (executor 2) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,102 | INFO  | [dispatcher-event-loop-42] | Starting task 62.0 in stage 9.0 (TID 516, dn32, executor 4, partition 62, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,102 | INFO  | [task-result-getter-0] | Finished task 36.0 in stage 9.0 (TID 490) in 533383 ms on dn32 (executor 4) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,211 | INFO  | [dispatcher-event-loop-26] | Starting task 63.0 in stage 9.0 (TID 517, dn27, executor 7, partition 63, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,212 | INFO  | [task-result-getter-3] | Finished task 2.0 in stage 9.0 (TID 456) in 533505 ms on dn27 (executor 7) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,273 | INFO  | [dispatcher-event-loop-29] | Starting task 64.0 in stage 9.0 (TID 518, dn07, executor 14, partition 64, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,274 | INFO  | [task-result-getter-2] | Finished task 17.0 in stage 9.0 (TID 471) in 533561 ms on dn07 (executor 14) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,380 | INFO  | [dispatcher-event-loop-36] | Starting task 65.0 in stage 9.0 (TID 519, dn34, executor 6, partition 65, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,381 | INFO  | [task-result-getter-1] | Finished task 9.0 in stage 9.0 (TID 463) in 533671 ms on dn34 (executor 6) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,725 | INFO  | [dispatcher-event-loop-38] | Starting task 66.0 in stage 9.0 (TID 520, dn20, executor 13, partition 66, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,726 | INFO  | [task-result-getter-0] | Finished task 12.0 in stage 9.0 (TID 466) in 534015 ms on dn20 (executor 13) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,842 | INFO  | [dispatcher-event-loop-47] | Starting task 67.0 in stage 9.0 (TID 521, dn17, executor 18, partition 67, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,843 | INFO  | [task-result-getter-3] | Finished task 6.0 in stage 9.0 (TID 460) in 534134 ms on dn17 (executor 18) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,851 | INFO  | [dispatcher-event-loop-34] | Starting task 68.0 in stage 9.0 (TID 522, dn15, executor 12, partition 68, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,851 | INFO  | [task-result-getter-2] | Finished task 4.0 in stage 9.0 (TID 458) in 534143 ms on dn15 (executor 12) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,977 | INFO  | [dispatcher-event-loop-56] | Starting task 69.0 in stage 9.0 (TID 523, dn37, executor 8, partition 69, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:14,977 | INFO  | [task-result-getter-1] | Finished task 20.0 in stage 9.0 (TID 474) in 534263 ms on dn37 (executor 8) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,265 | INFO  | [dispatcher-event-loop-45] | Starting task 70.0 in stage 9.0 (TID 524, dn22, executor 5, partition 70, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,265 | INFO  | [task-result-getter-0] | Finished task 19.0 in stage 9.0 (TID 473) in 535551 ms on dn22 (executor 5) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,267 | INFO  | [dispatcher-event-loop-53] | Starting task 71.0 in stage 9.0 (TID 525, dn15, executor 12, partition 71, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,268 | INFO  | [task-result-getter-3] | Finished task 24.0 in stage 9.0 (TID 478) in 535553 ms on dn15 (executor 12) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,287 | INFO  | [dispatcher-event-loop-70] | Starting task 72.0 in stage 9.0 (TID 526, dn27, executor 7, partition 72, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,287 | INFO  | [task-result-getter-2] | Finished task 22.0 in stage 9.0 (TID 476) in 535572 ms on dn27 (executor 7) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,632 | INFO  | [dispatcher-event-loop-54] | Starting task 73.0 in stage 9.0 (TID 527, dn10, executor 19, partition 73, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:16,633 | INFO  | [task-result-getter-1] | Finished task 21.0 in stage 9.0 (TID 475) in 535919 ms on dn10 (executor 19) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:17,089 | INFO  | [dispatcher-event-loop-68] | Starting task 74.0 in stage 9.0 (TID 528, dn37, executor 8, partition 74, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:17,090 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 9.0 (TID 454) in 536384 ms on dn37 (executor 8) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,376 | INFO  | [dispatcher-event-loop-9] | Starting task 75.0 in stage 9.0 (TID 529, dn08, executor 16, partition 75, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,376 | INFO  | [task-result-getter-3] | Finished task 11.0 in stage 9.0 (TID 465) in 538665 ms on dn08 (executor 16) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,468 | INFO  | [dispatcher-event-loop-12] | Starting task 76.0 in stage 9.0 (TID 530, dn14, executor 17, partition 76, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,468 | INFO  | [task-result-getter-2] | Finished task 13.0 in stage 9.0 (TID 467) in 538757 ms on dn14 (executor 17) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,775 | INFO  | [dispatcher-event-loop-14] | Starting task 77.0 in stage 9.0 (TID 531, dn10, executor 19, partition 77, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,775 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 9.0 (TID 455) in 539068 ms on dn10 (executor 19) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,890 | INFO  | [dispatcher-event-loop-18] | Starting task 78.0 in stage 9.0 (TID 532, dn08, executor 16, partition 78, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:19,890 | INFO  | [task-result-getter-0] | Finished task 31.0 in stage 9.0 (TID 485) in 539172 ms on dn08 (executor 16) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:25,886 | INFO  | [dispatcher-event-loop-35] | Starting task 79.0 in stage 9.0 (TID 533, dn14, executor 17, partition 79, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 17:53:25,887 | INFO  | [task-result-getter-3] | Finished task 33.0 in stage 9.0 (TID 487) in 545169 ms on dn14 (executor 17) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:08,799 | INFO  | [dispatcher-event-loop-14] | Starting task 80.0 in stage 9.0 (TID 534, dn29, executor 1, partition 80, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:08,800 | INFO  | [task-result-getter-2] | Finished task 43.0 in stage 9.0 (TID 497) in 553202 ms on dn29 (executor 1) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:12,405 | INFO  | [dispatcher-event-loop-28] | Starting task 81.0 in stage 9.0 (TID 535, dn36, executor 20, partition 81, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:12,406 | INFO  | [task-result-getter-1] | Finished task 41.0 in stage 9.0 (TID 495) in 558793 ms on dn36 (executor 20) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:13,680 | INFO  | [dispatcher-event-loop-47] | Starting task 82.0 in stage 9.0 (TID 536, dn16, executor 15, partition 82, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:13,681 | INFO  | [task-result-getter-0] | Finished task 45.0 in stage 9.0 (TID 499) in 555018 ms on dn16 (executor 15) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:14,272 | INFO  | [dispatcher-event-loop-56] | Starting task 83.0 in stage 9.0 (TID 537, dn24, executor 9, partition 83, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:14,272 | INFO  | [task-result-getter-3] | Finished task 48.0 in stage 9.0 (TID 502) in 550858 ms on dn24 (executor 9) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:15,563 | INFO  | [dispatcher-event-loop-35] | Starting task 84.0 in stage 9.0 (TID 538, dn29, executor 1, partition 84, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:15,564 | INFO  | [task-result-getter-2] | Finished task 44.0 in stage 9.0 (TID 498) in 558970 ms on dn29 (executor 1) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:15,649 | INFO  | [dispatcher-event-loop-66] | Starting task 85.0 in stage 9.0 (TID 539, dn24, executor 9, partition 85, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:15,649 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 9.0 (TID 494) in 562995 ms on dn24 (executor 9) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:16,476 | INFO  | [dispatcher-event-loop-55] | Starting task 86.0 in stage 9.0 (TID 540, dn18, executor 10, partition 86, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:16,477 | INFO  | [task-result-getter-0] | Finished task 49.0 in stage 9.0 (TID 503) in 552862 ms on dn18 (executor 10) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:18,193 | INFO  | [dispatcher-event-loop-1] | Starting task 87.0 in stage 9.0 (TID 541, dn07, executor 14, partition 87, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:18,193 | INFO  | [task-result-getter-3] | Finished task 64.0 in stage 9.0 (TID 518) in 543920 ms on dn07 (executor 14) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:19,244 | INFO  | [dispatcher-event-loop-16] | Starting task 88.0 in stage 9.0 (TID 542, dn19, executor 11, partition 88, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:19,245 | INFO  | [task-result-getter-2] | Finished task 60.0 in stage 9.0 (TID 514) in 546852 ms on dn19 (executor 11) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:19,737 | INFO  | [dispatcher-event-loop-12] | Starting task 89.0 in stage 9.0 (TID 543, dn30, executor 2, partition 89, PROCESS_LOCAL, 7640 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:19,737 | INFO  | [task-result-getter-1] | Finished task 54.0 in stage 9.0 (TID 508) in 549897 ms on dn30 (executor 2) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:19,999 | INFO  | [task-result-getter-0] | Finished task 65.0 in stage 9.0 (TID 519) in 545619 ms on dn34 (executor 6) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:20,078 | INFO  | [task-result-getter-3] | Finished task 50.0 in stage 9.0 (TID 504) in 554271 ms on dn28 (executor 3) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:20,182 | INFO  | [task-result-getter-2] | Finished task 66.0 in stage 9.0 (TID 520) in 545457 ms on dn20 (executor 13) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:20,551 | INFO  | [task-result-getter-1] | Finished task 58.0 in stage 9.0 (TID 512) in 549277 ms on dn20 (executor 13) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:20,819 | INFO  | [task-result-getter-0] | Finished task 46.0 in stage 9.0 (TID 500) in 558563 ms on dn17 (executor 18) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:22,590 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 9.0 (TID 505) in 556592 ms on dn32 (executor 4) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:22,958 | INFO  | [task-result-getter-2] | Finished task 62.0 in stage 9.0 (TID 516) in 548857 ms on dn32 (executor 4) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:23,447 | INFO  | [task-result-getter-1] | Finished task 47.0 in stage 9.0 (TID 501) in 560907 ms on dn19 (executor 11) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:24,767 | INFO  | [task-result-getter-0] | Finished task 53.0 in stage 9.0 (TID 507) in 555552 ms on dn07 (executor 14) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:25,679 | INFO  | [task-result-getter-3] | Finished task 56.0 in stage 9.0 (TID 510) in 555182 ms on dn16 (executor 15) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:26,850 | INFO  | [task-result-getter-2] | Finished task 42.0 in stage 9.0 (TID 496) in 571730 ms on dn36 (executor 20) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:27,573 | INFO  | [task-result-getter-1] | Finished task 52.0 in stage 9.0 (TID 506) in 558916 ms on dn18 (executor 10) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:33,087 | INFO  | [task-result-getter-0] | Finished task 59.0 in stage 9.0 (TID 513) in 561480 ms on dn28 (executor 3) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:33,269 | INFO  | [task-result-getter-3] | Finished task 71.0 in stage 9.0 (TID 525) in 557002 ms on dn15 (executor 12) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:34,844 | INFO  | [task-result-getter-2] | Finished task 77.0 in stage 9.0 (TID 531) in 555070 ms on dn10 (executor 19) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:34,859 | INFO  | [task-result-getter-1] | Finished task 61.0 in stage 9.0 (TID 515) in 561303 ms on dn30 (executor 2) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:35,086 | INFO  | [task-result-getter-0] | Finished task 57.0 in stage 9.0 (TID 511) in 564183 ms on dn34 (executor 6) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:35,442 | INFO  | [task-result-getter-3] | Finished task 63.0 in stage 9.0 (TID 517) in 561232 ms on dn27 (executor 7) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:36,007 | INFO  | [task-result-getter-2] | Finished task 67.0 in stage 9.0 (TID 521) in 561164 ms on dn17 (executor 18) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:38,812 | INFO  | [task-result-getter-1] | Finished task 68.0 in stage 9.0 (TID 522) in 563962 ms on dn15 (executor 12) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:39,265 | INFO  | [task-result-getter-0] | Finished task 74.0 in stage 9.0 (TID 528) in 562176 ms on dn37 (executor 8) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:39,901 | INFO  | [task-result-getter-3] | Finished task 55.0 in stage 9.0 (TID 509) in 570010 ms on dn22 (executor 5) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:42,913 | INFO  | [task-result-getter-2] | Finished task 73.0 in stage 9.0 (TID 527) in 566281 ms on dn10 (executor 19) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:43,822 | INFO  | [task-result-getter-1] | Finished task 76.0 in stage 9.0 (TID 530) in 564355 ms on dn14 (executor 17) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:44,372 | INFO  | [task-result-getter-0] | Finished task 70.0 in stage 9.0 (TID 524) in 568108 ms on dn22 (executor 5) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:44,448 | INFO  | [task-result-getter-3] | Finished task 75.0 in stage 9.0 (TID 529) in 565072 ms on dn08 (executor 16) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:44,638 | INFO  | [task-result-getter-2] | Finished task 78.0 in stage 9.0 (TID 532) in 564748 ms on dn08 (executor 16) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:44,741 | INFO  | [task-result-getter-1] | Finished task 72.0 in stage 9.0 (TID 526) in 568454 ms on dn27 (executor 7) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:45,671 | INFO  | [task-result-getter-0] | Finished task 69.0 in stage 9.0 (TID 523) in 570695 ms on dn37 (executor 8) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:02:48,337 | INFO  | [task-result-getter-3] | Finished task 79.0 in stage 9.0 (TID 533) in 562451 ms on dn14 (executor 17) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:35,480 | INFO  | [task-result-getter-2] | Finished task 80.0 in stage 9.0 (TID 534) in 446682 ms on dn29 (executor 1) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:48,761 | INFO  | [task-result-getter-1] | Finished task 83.0 in stage 9.0 (TID 537) in 454490 ms on dn24 (executor 9) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:50,179 | INFO  | [task-result-getter-0] | Finished task 82.0 in stage 9.0 (TID 536) in 456499 ms on dn16 (executor 15) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:51,194 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 9.0 (TID 542) in 451950 ms on dn19 (executor 11) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:51,651 | INFO  | [task-result-getter-2] | Finished task 81.0 in stage 9.0 (TID 535) in 459246 ms on dn36 (executor 20) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:54,486 | INFO  | [task-result-getter-1] | Finished task 84.0 in stage 9.0 (TID 538) in 458923 ms on dn29 (executor 1) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:54,556 | INFO  | [task-result-getter-0] | Finished task 89.0 in stage 9.0 (TID 543) in 454820 ms on dn30 (executor 2) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:55,758 | INFO  | [task-result-getter-3] | Finished task 87.0 in stage 9.0 (TID 541) in 457566 ms on dn07 (executor 14) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,194 | INFO  | [task-result-getter-2] | Finished task 86.0 in stage 9.0 (TID 540) in 459718 ms on dn18 (executor 10) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,959 | INFO  | [task-result-getter-1] | Finished task 85.0 in stage 9.0 (TID 539) in 461311 ms on dn24 (executor 9) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,960 | INFO  | [task-result-getter-1] | Removed TaskSet 9.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,961 | INFO  | [dag-scheduler-event-loop] | ResultStage 9 (foreachPartition at GraphWriter.scala:455) finished in 1536.271 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,962 | INFO  | [Driver] | Job 6 finished: foreachPartition at GraphWriter.scala:455, took 1579.635697 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,965 | INFO  | [Driver] | Finished to load entity: entity2. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:56,973 | INFO  | [Driver] | Start to load relationships. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,128 | INFO  | [Driver] | Starting job: foreachPartition at GraphWriter.scala:485 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,134 | INFO  | [dag-scheduler-event-loop] | Registering RDD 30 (distinct at GraphWriter.scala:253) as input to shuffle 7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,138 | INFO  | [dag-scheduler-event-loop] | Registering RDD 33 (mapPartitions at GraphWriter.scala:253) as input to shuffle 4 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,141 | INFO  | [dag-scheduler-event-loop] | Registering RDD 34 (keyBy at GraphWriter.scala:258) as input to shuffle 3 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,142 | INFO  | [dag-scheduler-event-loop] | Registering RDD 38 (map at GraphWriter.scala:266) as input to shuffle 5 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,143 | INFO  | [dag-scheduler-event-loop] | Registering RDD 40 (distinct at GraphWriter.scala:253) as input to shuffle 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,143 | INFO  | [dag-scheduler-event-loop] | Registering RDD 43 (mapPartitions at GraphWriter.scala:253) as input to shuffle 6 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,145 | INFO  | [dag-scheduler-event-loop] | Got job 7 (foreachPartition at GraphWriter.scala:485) with 90 output partitions | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,145 | INFO  | [dag-scheduler-event-loop] | Final stage: ResultStage 16 (foreachPartition at GraphWriter.scala:485) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,145 | INFO  | [dag-scheduler-event-loop] | Parents of final stage: List(ShuffleMapStage 15, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,146 | INFO  | [dag-scheduler-event-loop] | Missing parents: List(ShuffleMapStage 15, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,149 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 10 (MapPartitionsRDD[30] at distinct at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,171 | INFO  | [dag-scheduler-event-loop] | Block broadcast_12 stored as values in memory (estimated size 30.7 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,177 | INFO  | [dag-scheduler-event-loop] | Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.7 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,178 | INFO  | [dispatcher-event-loop-41] | Added broadcast_12_piece0 in memory on dn37:22779 (size: 9.7 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,179 | INFO  | [dag-scheduler-event-loop] | Created broadcast 12 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,180 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[30] at distinct at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,180 | INFO  | [dag-scheduler-event-loop] | Adding task set 10.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,184 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,185 | INFO  | [dispatcher-event-loop-46] | Starting task 21.0 in stage 10.0 (TID 544, dn19, executor 11, partition 21, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,186 | INFO  | [dispatcher-event-loop-46] | Starting task 4.0 in stage 10.0 (TID 545, dn24, executor 9, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,186 | INFO  | [dispatcher-event-loop-46] | Starting task 36.0 in stage 10.0 (TID 546, dn20, executor 13, partition 36, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,186 | INFO  | [dispatcher-event-loop-46] | Starting task 30.0 in stage 10.0 (TID 547, dn10, executor 19, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,187 | INFO  | [dispatcher-event-loop-46] | Starting task 10.0 in stage 10.0 (TID 548, dn15, executor 12, partition 10, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,187 | INFO  | [dispatcher-event-loop-46] | Starting task 0.0 in stage 10.0 (TID 549, dn27, executor 7, partition 0, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,188 | INFO  | [dispatcher-event-loop-46] | Starting task 8.0 in stage 10.0 (TID 550, dn34, executor 6, partition 8, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,188 | INFO  | [dispatcher-event-loop-46] | Starting task 9.0 in stage 10.0 (TID 551, dn08, executor 16, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,189 | INFO  | [dispatcher-event-loop-46] | Starting task 16.0 in stage 10.0 (TID 552, dn30, executor 2, partition 16, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,189 | INFO  | [dispatcher-event-loop-46] | Starting task 2.0 in stage 10.0 (TID 553, dn17, executor 18, partition 2, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,190 | INFO  | [dispatcher-event-loop-46] | Starting task 20.0 in stage 10.0 (TID 554, dn16, executor 15, partition 20, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,191 | INFO  | [dispatcher-event-loop-46] | Starting task 11.0 in stage 10.0 (TID 555, dn07, executor 14, partition 11, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,191 | INFO  | [dispatcher-event-loop-46] | Starting task 15.0 in stage 10.0 (TID 556, dn28, executor 3, partition 15, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,192 | INFO  | [dag-scheduler-event-loop] | Block broadcast_13 stored as values in memory (estimated size 30.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,192 | INFO  | [dispatcher-event-loop-46] | Starting task 22.0 in stage 10.0 (TID 557, dn14, executor 17, partition 22, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,192 | INFO  | [dispatcher-event-loop-46] | Starting task 6.0 in stage 10.0 (TID 558, dn29, executor 1, partition 6, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,193 | INFO  | [dispatcher-event-loop-46] | Starting task 1.0 in stage 10.0 (TID 559, dn36, executor 20, partition 1, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,193 | INFO  | [dispatcher-event-loop-46] | Starting task 3.0 in stage 10.0 (TID 560, dn18, executor 10, partition 3, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,194 | INFO  | [dispatcher-event-loop-46] | Starting task 7.0 in stage 10.0 (TID 561, dn32, executor 4, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,194 | INFO  | [dispatcher-event-loop-46] | Starting task 43.0 in stage 10.0 (TID 562, dn37, executor 8, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,195 | INFO  | [dispatcher-event-loop-46] | Starting task 5.0 in stage 10.0 (TID 563, dn22, executor 5, partition 5, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,195 | INFO  | [dispatcher-event-loop-46] | Starting task 26.0 in stage 10.0 (TID 564, dn19, executor 11, partition 26, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,196 | INFO  | [dispatcher-event-loop-46] | Starting task 48.0 in stage 10.0 (TID 565, dn24, executor 9, partition 48, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,196 | INFO  | [dispatcher-event-loop-46] | Starting task 37.0 in stage 10.0 (TID 566, dn20, executor 13, partition 37, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,197 | INFO  | [dispatcher-event-loop-46] | Starting task 31.0 in stage 10.0 (TID 567, dn10, executor 19, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,197 | INFO  | [dispatcher-event-loop-46] | Starting task 27.0 in stage 10.0 (TID 568, dn15, executor 12, partition 27, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,198 | INFO  | [dispatcher-event-loop-46] | Starting task 14.0 in stage 10.0 (TID 569, dn27, executor 7, partition 14, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,198 | INFO  | [dag-scheduler-event-loop] | Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,198 | INFO  | [dispatcher-event-loop-46] | Starting task 32.0 in stage 10.0 (TID 570, dn34, executor 6, partition 32, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,199 | INFO  | [dispatcher-event-loop-46] | Starting task 38.0 in stage 10.0 (TID 571, dn08, executor 16, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,199 | INFO  | [dispatcher-event-loop-33] | Added broadcast_13_piece0 in memory on dn37:22779 (size: 9.5 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,199 | INFO  | [dispatcher-event-loop-46] | Starting task 28.0 in stage 10.0 (TID 572, dn30, executor 2, partition 28, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,199 | INFO  | [dag-scheduler-event-loop] | Created broadcast 13 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,200 | INFO  | [dispatcher-event-loop-46] | Starting task 17.0 in stage 10.0 (TID 573, dn17, executor 18, partition 17, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,200 | INFO  | [dispatcher-event-loop-46] | Starting task 23.0 in stage 10.0 (TID 574, dn16, executor 15, partition 23, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,200 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,200 | INFO  | [dispatcher-event-loop-46] | Starting task 13.0 in stage 10.0 (TID 575, dn07, executor 14, partition 13, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,200 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,201 | INFO  | [dispatcher-event-loop-46] | Starting task 58.0 in stage 10.0 (TID 576, dn28, executor 3, partition 58, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,201 | INFO  | [dispatcher-event-loop-46] | Starting task 24.0 in stage 10.0 (TID 577, dn14, executor 17, partition 24, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,201 | INFO  | [dispatcher-event-loop-46] | Starting task 54.0 in stage 10.0 (TID 578, dn29, executor 1, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,202 | INFO  | [dispatcher-event-loop-46] | Starting task 12.0 in stage 10.0 (TID 579, dn36, executor 20, partition 12, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,202 | INFO  | [dispatcher-event-loop-46] | Starting task 33.0 in stage 10.0 (TID 580, dn18, executor 10, partition 33, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,203 | INFO  | [dispatcher-event-loop-46] | Starting task 40.0 in stage 10.0 (TID 581, dn32, executor 4, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,203 | INFO  | [dispatcher-event-loop-46] | Starting task 55.0 in stage 10.0 (TID 582, dn37, executor 8, partition 55, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,203 | INFO  | [dispatcher-event-loop-46] | Starting task 18.0 in stage 10.0 (TID 583, dn22, executor 5, partition 18, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,205 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 14 (MapPartitionsRDD[40] at distinct at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,216 | INFO  | [dag-scheduler-event-loop] | Block broadcast_14 stored as values in memory (estimated size 30.7 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,219 | INFO  | [dag-scheduler-event-loop] | Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.7 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,220 | INFO  | [dispatcher-event-loop-27] | Added broadcast_14_piece0 in memory on dn37:22779 (size: 9.7 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,220 | INFO  | [dag-scheduler-event-loop] | Created broadcast 14 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,221 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[40] at distinct at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,221 | INFO  | [dag-scheduler-event-loop] | Adding task set 14.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,227 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn34:22620 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,227 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn10:22719 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,228 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn16:22668 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,229 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn24:22839 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,230 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn20:22825 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,230 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn27:22790 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,231 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn19:22830 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,232 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn08:22604 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,232 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn28:22784 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,233 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn15:22640 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,233 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn17:22761 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,234 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn32:22787 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,235 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn37:22861 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,235 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn07:22897 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,235 | INFO  | [dispatcher-event-loop-36] | Added broadcast_12_piece0 in memory on dn30:22608 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,237 | INFO  | [dispatcher-event-loop-46] | Added broadcast_12_piece0 in memory on dn29:22705 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,238 | INFO  | [dispatcher-event-loop-63] | Added broadcast_12_piece0 in memory on dn14:22891 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,241 | INFO  | [dispatcher-event-loop-50] | Added broadcast_12_piece0 in memory on dn18:22756 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,246 | INFO  | [dispatcher-event-loop-70] | Added broadcast_12_piece0 in memory on dn22:22834 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:09:57,250 | INFO  | [dispatcher-event-loop-53] | Added broadcast_12_piece0 in memory on dn36:22756 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,219 | INFO  | [dispatcher-event-loop-20] | Starting task 76.0 in stage 10.0 (TID 584, dn07, executor 14, partition 76, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,220 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 10.0 (TID 555) in 7029 ms on dn07 (executor 14) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,343 | INFO  | [dispatcher-event-loop-30] | Starting task 77.0 in stage 10.0 (TID 585, dn07, executor 14, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,344 | INFO  | [task-result-getter-3] | Finished task 13.0 in stage 10.0 (TID 575) in 7144 ms on dn07 (executor 14) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,539 | INFO  | [dispatcher-event-loop-57] | Starting task 78.0 in stage 10.0 (TID 586, dn18, executor 10, partition 78, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,540 | INFO  | [task-result-getter-2] | Finished task 3.0 in stage 10.0 (TID 560) in 7347 ms on dn18 (executor 10) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,612 | INFO  | [dispatcher-event-loop-13] | Starting task 88.0 in stage 10.0 (TID 587, dn24, executor 9, partition 88, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,613 | INFO  | [task-result-getter-1] | Finished task 4.0 in stage 10.0 (TID 545) in 7428 ms on dn24 (executor 9) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,614 | INFO  | [dispatcher-event-loop-13] | Starting task 89.0 in stage 10.0 (TID 588, dn24, executor 9, partition 89, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,614 | INFO  | [task-result-getter-0] | Finished task 48.0 in stage 10.0 (TID 565) in 7419 ms on dn24 (executor 9) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,647 | INFO  | [dispatcher-event-loop-23] | Starting task 20.0 in stage 12.0 (TID 589, dn16, executor 15, partition 20, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,648 | INFO  | [task-result-getter-3] | Finished task 23.0 in stage 10.0 (TID 574) in 7448 ms on dn16 (executor 15) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,659 | INFO  | [dispatcher-event-loop-40] | Starting task 46.0 in stage 10.0 (TID 590, dn15, executor 12, partition 46, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,659 | INFO  | [task-result-getter-2] | Finished task 27.0 in stage 10.0 (TID 568) in 7462 ms on dn15 (executor 12) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,660 | INFO  | [dispatcher-event-loop-38] | Starting task 44.0 in stage 10.0 (TID 591, dn32, executor 4, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,661 | INFO  | [task-result-getter-1] | Finished task 7.0 in stage 10.0 (TID 561) in 7468 ms on dn32 (executor 4) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,663 | INFO  | [dispatcher-event-loop-49] | Added broadcast_13_piece0 in memory on dn16:22668 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,738 | INFO  | [dispatcher-event-loop-34] | Starting task 47.0 in stage 10.0 (TID 592, dn10, executor 19, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,738 | INFO  | [task-result-getter-0] | Finished task 30.0 in stage 10.0 (TID 547) in 7552 ms on dn10 (executor 19) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,764 | INFO  | [dispatcher-event-loop-56] | Starting task 30.0 in stage 12.0 (TID 593, dn10, executor 19, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,765 | INFO  | [task-result-getter-3] | Finished task 31.0 in stage 10.0 (TID 567) in 7569 ms on dn10 (executor 19) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,766 | INFO  | [dispatcher-event-loop-4] | Starting task 64.0 in stage 10.0 (TID 594, dn37, executor 8, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,767 | INFO  | [task-result-getter-2] | Finished task 55.0 in stage 10.0 (TID 582) in 7564 ms on dn37 (executor 8) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,787 | INFO  | [dispatcher-event-loop-51] | Starting task 21.0 in stage 12.0 (TID 595, dn16, executor 15, partition 21, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,788 | INFO  | [task-result-getter-1] | Finished task 20.0 in stage 10.0 (TID 554) in 7598 ms on dn16 (executor 15) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,794 | INFO  | [dispatcher-event-loop-52] | Starting task 82.0 in stage 10.0 (TID 596, dn15, executor 12, partition 82, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,794 | INFO  | [task-result-getter-0] | Finished task 10.0 in stage 10.0 (TID 548) in 7607 ms on dn15 (executor 12) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,797 | INFO  | [dispatcher-event-loop-35] | Starting task 4.0 in stage 12.0 (TID 597, dn37, executor 8, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,798 | INFO  | [task-result-getter-3] | Finished task 43.0 in stage 10.0 (TID 562) in 7604 ms on dn37 (executor 8) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,800 | INFO  | [dispatcher-event-loop-64] | Added broadcast_13_piece0 in memory on dn10:22719 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,805 | INFO  | [dispatcher-event-loop-46] | Added broadcast_13_piece0 in memory on dn37:22861 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,811 | INFO  | [dispatcher-event-loop-63] | Starting task 84.0 in stage 10.0 (TID 598, dn18, executor 10, partition 84, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,812 | INFO  | [task-result-getter-2] | Finished task 33.0 in stage 10.0 (TID 580) in 7610 ms on dn18 (executor 10) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,953 | INFO  | [dispatcher-event-loop-70] | Starting task 7.0 in stage 12.0 (TID 599, dn32, executor 4, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,953 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 10.0 (TID 581) in 7750 ms on dn32 (executor 4) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,966 | INFO  | [dispatcher-event-loop-55] | Added broadcast_13_piece0 in memory on dn32:22787 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,994 | INFO  | [dispatcher-event-loop-45] | Starting task 68.0 in stage 10.0 (TID 600, dn36, executor 20, partition 68, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:04,994 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 10.0 (TID 559) in 7801 ms on dn36 (executor 20) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,017 | INFO  | [dispatcher-event-loop-54] | Starting task 29.0 in stage 10.0 (TID 601, dn17, executor 18, partition 29, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,017 | INFO  | [task-result-getter-3] | Finished task 17.0 in stage 10.0 (TID 573) in 7818 ms on dn17 (executor 18) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,026 | INFO  | [dispatcher-event-loop-60] | Starting task 50.0 in stage 10.0 (TID 602, dn30, executor 2, partition 50, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,026 | INFO  | [task-result-getter-2] | Finished task 16.0 in stage 10.0 (TID 552) in 7838 ms on dn30 (executor 2) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,027 | INFO  | [dispatcher-event-loop-60] | Starting task 45.0 in stage 10.0 (TID 603, dn22, executor 5, partition 45, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,027 | INFO  | [task-result-getter-1] | Finished task 5.0 in stage 10.0 (TID 563) in 7833 ms on dn22 (executor 5) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,046 | INFO  | [dispatcher-event-loop-3] | Starting task 51.0 in stage 10.0 (TID 604, dn30, executor 2, partition 51, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,047 | INFO  | [task-result-getter-0] | Finished task 28.0 in stage 10.0 (TID 572) in 7848 ms on dn30 (executor 2) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,067 | INFO  | [dispatcher-event-loop-8] | Starting task 53.0 in stage 10.0 (TID 605, dn19, executor 11, partition 53, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,068 | INFO  | [task-result-getter-3] | Finished task 21.0 in stage 10.0 (TID 544) in 7884 ms on dn19 (executor 11) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,092 | INFO  | [dispatcher-event-loop-7] | Starting task 0.0 in stage 12.0 (TID 606, dn36, executor 20, partition 0, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,093 | INFO  | [task-result-getter-2] | Finished task 12.0 in stage 10.0 (TID 579) in 7891 ms on dn36 (executor 20) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,096 | INFO  | [dispatcher-event-loop-15] | Starting task 75.0 in stage 10.0 (TID 607, dn28, executor 3, partition 75, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,096 | INFO  | [task-result-getter-1] | Finished task 15.0 in stage 10.0 (TID 556) in 7905 ms on dn28 (executor 3) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,103 | INFO  | [dispatcher-event-loop-16] | Added broadcast_13_piece0 in memory on dn36:22756 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,130 | INFO  | [dispatcher-event-loop-12] | Starting task 79.0 in stage 10.0 (TID 608, dn20, executor 13, partition 79, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,131 | INFO  | [task-result-getter-0] | Finished task 37.0 in stage 10.0 (TID 566) in 7935 ms on dn20 (executor 13) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,132 | INFO  | [dispatcher-event-loop-2] | Starting task 59.0 in stage 10.0 (TID 609, dn19, executor 11, partition 59, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,133 | INFO  | [task-result-getter-3] | Finished task 26.0 in stage 10.0 (TID 564) in 7938 ms on dn19 (executor 11) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,168 | INFO  | [dispatcher-event-loop-18] | Starting task 36.0 in stage 12.0 (TID 610, dn20, executor 13, partition 36, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,169 | INFO  | [task-result-getter-2] | Finished task 36.0 in stage 10.0 (TID 546) in 7983 ms on dn20 (executor 13) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,182 | INFO  | [dispatcher-event-loop-5] | Added broadcast_13_piece0 in memory on dn20:22825 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,219 | INFO  | [dispatcher-event-loop-24] | Starting task 71.0 in stage 10.0 (TID 611, dn22, executor 5, partition 71, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,221 | INFO  | [task-result-getter-1] | Finished task 18.0 in stage 10.0 (TID 583) in 8018 ms on dn22 (executor 5) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,222 | INFO  | [dispatcher-event-loop-6] | Starting task 19.0 in stage 10.0 (TID 612, dn27, executor 7, partition 19, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,223 | INFO  | [task-result-getter-0] | Finished task 14.0 in stage 10.0 (TID 569) in 8025 ms on dn27 (executor 7) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,238 | INFO  | [dispatcher-event-loop-32] | Starting task 2.0 in stage 12.0 (TID 613, dn28, executor 3, partition 2, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,238 | INFO  | [task-result-getter-3] | Finished task 58.0 in stage 10.0 (TID 576) in 8037 ms on dn28 (executor 3) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,249 | INFO  | [dispatcher-event-loop-42] | Added broadcast_13_piece0 in memory on dn28:22784 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,258 | INFO  | [dispatcher-event-loop-13] | Starting task 52.0 in stage 10.0 (TID 614, dn27, executor 7, partition 52, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,258 | INFO  | [task-result-getter-2] | Finished task 0.0 in stage 10.0 (TID 549) in 8071 ms on dn27 (executor 7) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,367 | INFO  | [dispatcher-event-loop-39] | Starting task 65.0 in stage 10.0 (TID 615, dn17, executor 18, partition 65, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,368 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 10.0 (TID 553) in 8179 ms on dn17 (executor 18) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,469 | INFO  | [dispatcher-event-loop-29] | Starting task 42.0 in stage 10.0 (TID 616, dn34, executor 6, partition 42, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,470 | INFO  | [task-result-getter-0] | Finished task 8.0 in stage 10.0 (TID 550) in 8282 ms on dn34 (executor 6) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,536 | INFO  | [dispatcher-event-loop-40] | Starting task 66.0 in stage 10.0 (TID 617, dn34, executor 6, partition 66, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,537 | INFO  | [task-result-getter-3] | Finished task 32.0 in stage 10.0 (TID 570) in 8339 ms on dn34 (executor 6) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,757 | INFO  | [dispatcher-event-loop-11] | Starting task 25.0 in stage 10.0 (TID 618, dn14, executor 17, partition 25, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,758 | INFO  | [task-result-getter-2] | Finished task 24.0 in stage 10.0 (TID 577) in 8557 ms on dn14 (executor 17) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,769 | INFO  | [dispatcher-event-loop-4] | Starting task 62.0 in stage 10.0 (TID 619, dn14, executor 17, partition 62, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:05,769 | INFO  | [task-result-getter-1] | Finished task 22.0 in stage 10.0 (TID 557) in 8577 ms on dn14 (executor 17) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,526 | INFO  | [dispatcher-event-loop-52] | Starting task 80.0 in stage 10.0 (TID 620, dn08, executor 16, partition 80, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,526 | INFO  | [task-result-getter-0] | Finished task 9.0 in stage 10.0 (TID 551) in 9338 ms on dn08 (executor 16) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,623 | INFO  | [dispatcher-event-loop-35] | Starting task 81.0 in stage 10.0 (TID 621, dn08, executor 16, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,624 | INFO  | [task-result-getter-3] | Finished task 38.0 in stage 10.0 (TID 571) in 9426 ms on dn08 (executor 16) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,660 | INFO  | [dispatcher-event-loop-64] | Starting task 56.0 in stage 10.0 (TID 622, dn29, executor 1, partition 56, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,660 | INFO  | [task-result-getter-2] | Finished task 6.0 in stage 10.0 (TID 558) in 9468 ms on dn29 (executor 1) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,714 | INFO  | [dispatcher-event-loop-70] | Starting task 57.0 in stage 10.0 (TID 623, dn29, executor 1, partition 57, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:06,715 | INFO  | [task-result-getter-1] | Finished task 54.0 in stage 10.0 (TID 578) in 9514 ms on dn29 (executor 1) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,403 | INFO  | [dispatcher-event-loop-9] | Starting task 34.0 in stage 10.0 (TID 624, dn07, executor 14, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,404 | INFO  | [task-result-getter-0] | Finished task 76.0 in stage 10.0 (TID 584) in 7186 ms on dn07 (executor 14) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,446 | INFO  | [dispatcher-event-loop-12] | Starting task 35.0 in stage 10.0 (TID 625, dn07, executor 14, partition 35, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,447 | INFO  | [task-result-getter-3] | Finished task 77.0 in stage 10.0 (TID 585) in 7104 ms on dn07 (executor 14) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,732 | INFO  | [dispatcher-event-loop-25] | Starting task 39.0 in stage 10.0 (TID 626, dn10, executor 19, partition 39, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,733 | INFO  | [task-result-getter-2] | Finished task 47.0 in stage 10.0 (TID 592) in 6996 ms on dn10 (executor 19) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,844 | INFO  | [dispatcher-event-loop-5] | Starting task 41.0 in stage 10.0 (TID 627, dn24, executor 9, partition 41, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,845 | INFO  | [task-result-getter-1] | Finished task 88.0 in stage 10.0 (TID 587) in 7233 ms on dn24 (executor 9) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,938 | INFO  | [dispatcher-event-loop-6] | Starting task 83.0 in stage 10.0 (TID 628, dn15, executor 12, partition 83, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,938 | INFO  | [task-result-getter-0] | Finished task 46.0 in stage 10.0 (TID 590) in 7279 ms on dn15 (executor 12) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,989 | INFO  | [dispatcher-event-loop-20] | Starting task 8.0 in stage 12.0 (TID 629, dn24, executor 9, partition 8, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:11,990 | INFO  | [task-result-getter-3] | Finished task 89.0 in stage 10.0 (TID 588) in 7377 ms on dn24 (executor 9) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,023 | INFO  | [dispatcher-event-loop-22] | Starting task 37.0 in stage 12.0 (TID 630, dn20, executor 13, partition 37, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,023 | INFO  | [task-result-getter-2] | Finished task 79.0 in stage 10.0 (TID 608) in 6893 ms on dn20 (executor 13) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,023 | INFO  | [dispatcher-event-loop-57] | Added broadcast_13_piece0 in memory on dn24:22839 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,078 | INFO  | [dispatcher-event-loop-42] | Starting task 86.0 in stage 10.0 (TID 631, dn15, executor 12, partition 86, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,078 | INFO  | [task-result-getter-1] | Finished task 82.0 in stage 10.0 (TID 596) in 7284 ms on dn15 (executor 12) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,080 | INFO  | [dispatcher-event-loop-13] | Starting task 40.0 in stage 12.0 (TID 632, dn32, executor 4, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,081 | INFO  | [task-result-getter-0] | Finished task 44.0 in stage 10.0 (TID 591) in 7421 ms on dn32 (executor 4) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,081 | INFO  | [dispatcher-event-loop-13] | Starting task 85.0 in stage 10.0 (TID 633, dn18, executor 10, partition 85, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,082 | INFO  | [task-result-getter-3] | Finished task 78.0 in stage 10.0 (TID 586) in 7543 ms on dn18 (executor 10) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,313 | INFO  | [dispatcher-event-loop-38] | Starting task 15.0 in stage 12.0 (TID 634, dn28, executor 3, partition 15, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,314 | INFO  | [task-result-getter-2] | Finished task 75.0 in stage 10.0 (TID 607) in 7219 ms on dn28 (executor 3) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,349 | INFO  | [dispatcher-event-loop-37] | Starting task 3.0 in stage 12.0 (TID 635, dn18, executor 10, partition 3, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,350 | INFO  | [task-result-getter-1] | Finished task 84.0 in stage 10.0 (TID 598) in 7539 ms on dn18 (executor 10) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,361 | INFO  | [dispatcher-event-loop-34] | Added broadcast_13_piece0 in memory on dn18:22756 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,385 | INFO  | [dispatcher-event-loop-44] | Starting task 16.0 in stage 12.0 (TID 636, dn30, executor 2, partition 16, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,386 | INFO  | [task-result-getter-0] | Finished task 50.0 in stage 10.0 (TID 602) in 7361 ms on dn30 (executor 2) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,399 | INFO  | [dispatcher-event-loop-43] | Starting task 26.0 in stage 12.0 (TID 637, dn30, executor 2, partition 26, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,400 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 10.0 (TID 604) in 7354 ms on dn30 (executor 2) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,407 | INFO  | [dispatcher-event-loop-41] | Starting task 67.0 in stage 10.0 (TID 638, dn17, executor 18, partition 67, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,408 | INFO  | [task-result-getter-2] | Finished task 29.0 in stage 10.0 (TID 601) in 7391 ms on dn17 (executor 18) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,416 | INFO  | [dispatcher-event-loop-58] | Added broadcast_13_piece0 in memory on dn30:22608 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,486 | INFO  | [dispatcher-event-loop-35] | Starting task 74.0 in stage 10.0 (TID 639, dn22, executor 5, partition 74, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,487 | INFO  | [task-result-getter-1] | Finished task 71.0 in stage 10.0 (TID 611) in 7269 ms on dn22 (executor 5) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,506 | INFO  | [dispatcher-event-loop-64] | Starting task 43.0 in stage 12.0 (TID 640, dn37, executor 8, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,506 | INFO  | [task-result-getter-0] | Finished task 64.0 in stage 10.0 (TID 594) in 7740 ms on dn37 (executor 8) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,507 | INFO  | [dispatcher-event-loop-64] | Starting task 1.0 in stage 12.0 (TID 641, dn22, executor 5, partition 1, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,507 | INFO  | [task-result-getter-3] | Finished task 45.0 in stage 10.0 (TID 603) in 7481 ms on dn22 (executor 5) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,518 | INFO  | [dispatcher-event-loop-70] | Added broadcast_13_piece0 in memory on dn22:22834 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,570 | INFO  | [dispatcher-event-loop-53] | Starting task 70.0 in stage 10.0 (TID 642, dn17, executor 18, partition 70, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,570 | INFO  | [task-result-getter-2] | Finished task 65.0 in stage 10.0 (TID 615) in 7203 ms on dn17 (executor 18) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,575 | INFO  | [dispatcher-event-loop-55] | Starting task 14.0 in stage 12.0 (TID 643, dn27, executor 7, partition 14, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,576 | INFO  | [task-result-getter-1] | Finished task 19.0 in stage 10.0 (TID 612) in 7353 ms on dn27 (executor 7) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,593 | INFO  | [dispatcher-event-loop-54] | Added broadcast_13_piece0 in memory on dn27:22790 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,604 | INFO  | [dispatcher-event-loop-67] | Starting task 19.0 in stage 12.0 (TID 644, dn27, executor 7, partition 19, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,605 | INFO  | [task-result-getter-0] | Finished task 52.0 in stage 10.0 (TID 614) in 7347 ms on dn27 (executor 7) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,635 | INFO  | [dispatcher-event-loop-60] | Starting task 87.0 in stage 10.0 (TID 645, dn19, executor 11, partition 87, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,636 | INFO  | [task-result-getter-3] | Finished task 59.0 in stage 10.0 (TID 609) in 7504 ms on dn19 (executor 11) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,750 | INFO  | [dispatcher-event-loop-0] | Starting task 12.0 in stage 12.0 (TID 646, dn36, executor 20, partition 12, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,750 | INFO  | [task-result-getter-2] | Finished task 68.0 in stage 10.0 (TID 600) in 7756 ms on dn36 (executor 20) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,856 | INFO  | [dispatcher-event-loop-3] | Starting task 27.0 in stage 12.0 (TID 647, dn19, executor 11, partition 27, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,857 | INFO  | [task-result-getter-1] | Finished task 53.0 in stage 10.0 (TID 605) in 7790 ms on dn19 (executor 11) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:12,867 | INFO  | [dispatcher-event-loop-1] | Added broadcast_13_piece0 in memory on dn19:22830 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,030 | INFO  | [dispatcher-event-loop-7] | Starting task 63.0 in stage 10.0 (TID 648, dn14, executor 17, partition 63, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,030 | INFO  | [task-result-getter-0] | Finished task 25.0 in stage 10.0 (TID 618) in 7273 ms on dn14 (executor 17) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,146 | INFO  | [dispatcher-event-loop-15] | Starting task 72.0 in stage 10.0 (TID 649, dn14, executor 17, partition 72, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,147 | INFO  | [task-result-getter-3] | Finished task 62.0 in stage 10.0 (TID 619) in 7379 ms on dn14 (executor 17) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,224 | INFO  | [dispatcher-event-loop-12] | Starting task 32.0 in stage 12.0 (TID 650, dn34, executor 6, partition 32, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,224 | INFO  | [task-result-getter-2] | Finished task 42.0 in stage 10.0 (TID 616) in 7755 ms on dn34 (executor 6) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,247 | INFO  | [dispatcher-event-loop-25] | Added broadcast_13_piece0 in memory on dn34:22620 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,331 | INFO  | [dispatcher-event-loop-18] | Starting task 42.0 in stage 12.0 (TID 651, dn34, executor 6, partition 42, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,331 | INFO  | [task-result-getter-1] | Finished task 66.0 in stage 10.0 (TID 617) in 7795 ms on dn34 (executor 6) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,960 | INFO  | [dispatcher-event-loop-6] | Starting task 9.0 in stage 12.0 (TID 652, dn08, executor 16, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,960 | INFO  | [task-result-getter-0] | Finished task 81.0 in stage 10.0 (TID 621) in 7337 ms on dn08 (executor 16) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:13,987 | INFO  | [dispatcher-event-loop-32] | Added broadcast_13_piece0 in memory on dn08:22604 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,061 | INFO  | [dispatcher-event-loop-30] | Starting task 38.0 in stage 12.0 (TID 653, dn08, executor 16, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,062 | INFO  | [task-result-getter-3] | Finished task 80.0 in stage 10.0 (TID 620) in 7535 ms on dn08 (executor 16) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,230 | INFO  | [dispatcher-event-loop-57] | Starting task 22.0 in stage 12.0 (TID 654, dn16, executor 15, partition 22, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,231 | INFO  | [task-result-getter-2] | Finished task 20.0 in stage 12.0 (TID 589) in 9584 ms on dn16 (executor 15) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,253 | INFO  | [dispatcher-event-loop-42] | Starting task 23.0 in stage 12.0 (TID 655, dn16, executor 15, partition 23, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,254 | INFO  | [task-result-getter-1] | Finished task 21.0 in stage 12.0 (TID 595) in 9467 ms on dn16 (executor 15) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,458 | INFO  | [dispatcher-event-loop-39] | Starting task 31.0 in stage 12.0 (TID 656, dn10, executor 19, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,458 | INFO  | [task-result-getter-0] | Finished task 30.0 in stage 12.0 (TID 593) in 9694 ms on dn10 (executor 19) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,715 | INFO  | [dispatcher-event-loop-29] | Starting task 44.0 in stage 12.0 (TID 657, dn32, executor 4, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,715 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 12.0 (TID 599) in 9763 ms on dn32 (executor 4) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,752 | INFO  | [dispatcher-event-loop-40] | Starting task 79.0 in stage 12.0 (TID 658, dn20, executor 13, partition 79, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,753 | INFO  | [task-result-getter-2] | Finished task 36.0 in stage 12.0 (TID 610) in 9585 ms on dn20 (executor 13) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,850 | INFO  | [dispatcher-event-loop-49] | Starting task 55.0 in stage 12.0 (TID 659, dn37, executor 8, partition 55, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:14,851 | INFO  | [task-result-getter-1] | Finished task 4.0 in stage 12.0 (TID 597) in 10054 ms on dn37 (executor 8) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,049 | INFO  | [dispatcher-event-loop-47] | Starting task 58.0 in stage 12.0 (TID 660, dn28, executor 3, partition 58, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,050 | INFO  | [task-result-getter-0] | Finished task 2.0 in stage 12.0 (TID 613) in 9812 ms on dn28 (executor 3) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,229 | INFO  | [dispatcher-event-loop-56] | Starting task 68.0 in stage 12.0 (TID 661, dn36, executor 20, partition 68, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,229 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 12.0 (TID 606) in 10137 ms on dn36 (executor 20) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,491 | INFO  | [dispatcher-event-loop-41] | Starting task 69.0 in stage 10.0 (TID 662, dn29, executor 1, partition 69, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,492 | INFO  | [task-result-getter-2] | Finished task 56.0 in stage 10.0 (TID 622) in 8832 ms on dn29 (executor 1) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,492 | INFO  | [dispatcher-event-loop-41] | Starting task 73.0 in stage 10.0 (TID 663, dn29, executor 1, partition 73, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:15,493 | INFO  | [task-result-getter-1] | Finished task 57.0 in stage 10.0 (TID 623) in 8779 ms on dn29 (executor 1) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,354 | INFO  | [dispatcher-event-loop-61] | Starting task 11.0 in stage 12.0 (TID 664, dn07, executor 14, partition 11, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,355 | INFO  | [task-result-getter-0] | Finished task 35.0 in stage 10.0 (TID 625) in 6909 ms on dn07 (executor 14) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,386 | INFO  | [dispatcher-event-loop-8] | Added broadcast_13_piece0 in memory on dn07:22897 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,429 | INFO  | [dispatcher-event-loop-1] | Starting task 13.0 in stage 12.0 (TID 665, dn07, executor 14, partition 13, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,429 | INFO  | [task-result-getter-3] | Finished task 34.0 in stage 10.0 (TID 624) in 7026 ms on dn07 (executor 14) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,531 | INFO  | [dispatcher-event-loop-17] | Starting task 49.0 in stage 10.0 (TID 666, dn10, executor 19, partition 49, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,532 | INFO  | [task-result-getter-2] | Finished task 39.0 in stage 10.0 (TID 626) in 6800 ms on dn10 (executor 19) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,831 | INFO  | [dispatcher-event-loop-9] | Starting task 60.0 in stage 10.0 (TID 667, dn15, executor 12, partition 60, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,832 | INFO  | [task-result-getter-1] | Finished task 83.0 in stage 10.0 (TID 628) in 6895 ms on dn15 (executor 12) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,917 | INFO  | [dispatcher-event-loop-12] | Starting task 61.0 in stage 10.0 (TID 668, dn24, executor 9, partition 61, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:18,918 | INFO  | [task-result-getter-0] | Finished task 41.0 in stage 10.0 (TID 627) in 7074 ms on dn24 (executor 9) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,219 | INFO  | [dispatcher-event-loop-19] | Starting task 10.0 in stage 12.0 (TID 669, dn15, executor 12, partition 10, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,220 | INFO  | [task-result-getter-3] | Finished task 86.0 in stage 10.0 (TID 631) in 7142 ms on dn15 (executor 12) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,231 | INFO  | [dispatcher-event-loop-14] | Added broadcast_13_piece0 in memory on dn15:22640 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,250 | INFO  | [dispatcher-event-loop-31] | Starting task 33.0 in stage 12.0 (TID 670, dn18, executor 10, partition 33, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,250 | INFO  | [task-result-getter-2] | Finished task 85.0 in stage 10.0 (TID 633) in 7169 ms on dn18 (executor 10) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,692 | INFO  | [dispatcher-event-loop-6] | Starting task 5.0 in stage 12.0 (TID 671, dn22, executor 5, partition 5, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,693 | INFO  | [task-result-getter-1] | Finished task 74.0 in stage 10.0 (TID 639) in 7207 ms on dn22 (executor 5) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,987 | INFO  | [dispatcher-event-loop-20] | Starting task 53.0 in stage 12.0 (TID 672, dn19, executor 11, partition 53, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:19,987 | INFO  | [task-result-getter-0] | Finished task 87.0 in stage 10.0 (TID 645) in 7352 ms on dn19 (executor 11) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,288 | INFO  | [dispatcher-event-loop-30] | Starting task 17.0 in stage 12.0 (TID 673, dn17, executor 18, partition 17, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,289 | INFO  | [task-result-getter-3] | Finished task 67.0 in stage 10.0 (TID 638) in 7882 ms on dn17 (executor 18) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,321 | INFO  | [dispatcher-event-loop-21] | Added broadcast_13_piece0 in memory on dn17:22761 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,480 | INFO  | [dispatcher-event-loop-23] | Starting task 24.0 in stage 12.0 (TID 674, dn14, executor 17, partition 24, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,480 | INFO  | [task-result-getter-2] | Finished task 63.0 in stage 10.0 (TID 648) in 7451 ms on dn14 (executor 17) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,496 | INFO  | [dispatcher-event-loop-40] | Added broadcast_13_piece0 in memory on dn14:22891 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,563 | INFO  | [dispatcher-event-loop-38] | Starting task 29.0 in stage 12.0 (TID 675, dn17, executor 18, partition 29, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:20,564 | INFO  | [task-result-getter-1] | Finished task 70.0 in stage 10.0 (TID 642) in 7994 ms on dn17 (executor 18) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,153 | INFO  | [dispatcher-event-loop-56] | Starting task 25.0 in stage 12.0 (TID 676, dn14, executor 17, partition 25, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,153 | INFO  | [task-result-getter-0] | Finished task 72.0 in stage 10.0 (TID 649) in 8007 ms on dn14 (executor 17) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,546 | INFO  | [dispatcher-event-loop-43] | Starting task 78.0 in stage 12.0 (TID 677, dn18, executor 10, partition 78, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,546 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 12.0 (TID 635) in 9197 ms on dn18 (executor 10) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,559 | INFO  | [dispatcher-event-loop-51] | Starting task 82.0 in stage 12.0 (TID 678, dn20, executor 13, partition 82, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,559 | INFO  | [task-result-getter-2] | Finished task 37.0 in stage 12.0 (TID 630) in 9537 ms on dn20 (executor 13) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,675 | INFO  | [dispatcher-event-loop-52] | Starting task 48.0 in stage 12.0 (TID 679, dn24, executor 9, partition 48, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,676 | INFO  | [task-result-getter-1] | Finished task 8.0 in stage 12.0 (TID 629) in 9687 ms on dn24 (executor 9) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,854 | INFO  | [dispatcher-event-loop-36] | Starting task 75.0 in stage 12.0 (TID 680, dn28, executor 3, partition 75, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,855 | INFO  | [task-result-getter-0] | Finished task 15.0 in stage 12.0 (TID 634) in 9542 ms on dn28 (executor 3) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,936 | INFO  | [dispatcher-event-loop-46] | Starting task 7.0 in stage 14.0 (TID 681, dn32, executor 4, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,937 | INFO  | [task-result-getter-3] | Finished task 40.0 in stage 12.0 (TID 632) in 9857 ms on dn32 (executor 4) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,948 | INFO  | [dispatcher-event-loop-70] | Added broadcast_14_piece0 in memory on dn32:22787 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,981 | INFO  | [dispatcher-event-loop-53] | Starting task 64.0 in stage 12.0 (TID 682, dn37, executor 8, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:21,982 | INFO  | [task-result-getter-2] | Finished task 43.0 in stage 12.0 (TID 640) in 9476 ms on dn37 (executor 8) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,165 | INFO  | [dispatcher-event-loop-55] | Starting task 28.0 in stage 12.0 (TID 683, dn30, executor 2, partition 28, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,166 | INFO  | [task-result-getter-1] | Finished task 16.0 in stage 12.0 (TID 636) in 9781 ms on dn30 (executor 2) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,263 | INFO  | [dispatcher-event-loop-67] | Starting task 50.0 in stage 12.0 (TID 684, dn30, executor 2, partition 50, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,264 | INFO  | [task-result-getter-0] | Finished task 26.0 in stage 12.0 (TID 637) in 9865 ms on dn30 (executor 2) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,305 | INFO  | [dispatcher-event-loop-60] | Starting task 18.0 in stage 12.0 (TID 685, dn22, executor 5, partition 18, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,306 | INFO  | [task-result-getter-3] | Finished task 1.0 in stage 12.0 (TID 641) in 9799 ms on dn22 (executor 5) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,514 | INFO  | [dispatcher-event-loop-61] | Starting task 46.0 in stage 12.0 (TID 686, dn27, executor 7, partition 46, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,514 | INFO  | [task-result-getter-2] | Finished task 19.0 in stage 12.0 (TID 644) in 9910 ms on dn27 (executor 7) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,820 | INFO  | [dispatcher-event-loop-8] | Starting task 59.0 in stage 12.0 (TID 687, dn19, executor 11, partition 59, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,820 | INFO  | [task-result-getter-1] | Finished task 27.0 in stage 12.0 (TID 647) in 9964 ms on dn19 (executor 11) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,899 | INFO  | [dispatcher-event-loop-7] | Starting task 47.0 in stage 12.0 (TID 688, dn27, executor 7, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:22,900 | INFO  | [task-result-getter-0] | Finished task 14.0 in stage 12.0 (TID 643) in 10325 ms on dn27 (executor 7) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,013 | INFO  | [dispatcher-event-loop-15] | Starting task 84.0 in stage 12.0 (TID 689, dn36, executor 20, partition 84, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,013 | INFO  | [task-result-getter-3] | Finished task 12.0 in stage 12.0 (TID 646) in 10264 ms on dn36 (executor 20) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,325 | INFO  | [dispatcher-event-loop-12] | Starting task 52.0 in stage 12.0 (TID 690, dn34, executor 6, partition 52, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,326 | INFO  | [task-result-getter-2] | Finished task 42.0 in stage 12.0 (TID 651) in 9995 ms on dn34 (executor 6) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,334 | INFO  | [dispatcher-event-loop-19] | Starting task 66.0 in stage 12.0 (TID 691, dn34, executor 6, partition 66, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,334 | INFO  | [task-result-getter-1] | Finished task 32.0 in stage 12.0 (TID 650) in 10111 ms on dn34 (executor 6) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,685 | INFO  | [dispatcher-event-loop-14] | Starting task 20.0 in stage 14.0 (TID 692, dn16, executor 15, partition 20, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,686 | INFO  | [task-result-getter-0] | Finished task 23.0 in stage 12.0 (TID 655) in 9433 ms on dn16 (executor 15) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,702 | INFO  | [dispatcher-event-loop-24] | Added broadcast_14_piece0 in memory on dn16:22668 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,836 | INFO  | [dispatcher-event-loop-6] | Starting task 54.0 in stage 12.0 (TID 693, dn10, executor 19, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,837 | INFO  | [task-result-getter-3] | Finished task 31.0 in stage 12.0 (TID 656) in 9380 ms on dn10 (executor 19) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,943 | INFO  | [dispatcher-event-loop-30] | Starting task 6.0 in stage 12.0 (TID 694, dn29, executor 1, partition 6, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,943 | INFO  | [task-result-getter-2] | Finished task 69.0 in stage 10.0 (TID 662) in 8452 ms on dn29 (executor 1) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,957 | INFO  | [dispatcher-event-loop-21] | Added broadcast_13_piece0 in memory on dn29:22705 (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,958 | INFO  | [dispatcher-event-loop-42] | Starting task 36.0 in stage 14.0 (TID 695, dn20, executor 13, partition 36, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,958 | INFO  | [task-result-getter-1] | Finished task 79.0 in stage 12.0 (TID 658) in 9207 ms on dn20 (executor 13) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:23,966 | INFO  | [dispatcher-event-loop-13] | Added broadcast_14_piece0 in memory on dn20:22825 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,057 | INFO  | [dispatcher-event-loop-23] | Starting task 56.0 in stage 12.0 (TID 696, dn29, executor 1, partition 56, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,058 | INFO  | [task-result-getter-0] | Finished task 73.0 in stage 10.0 (TID 663) in 8566 ms on dn29 (executor 1) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,076 | INFO  | [dispatcher-event-loop-28] | Starting task 21.0 in stage 14.0 (TID 697, dn16, executor 15, partition 21, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,076 | INFO  | [task-result-getter-3] | Finished task 22.0 in stage 12.0 (TID 654) in 9846 ms on dn16 (executor 15) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,153 | INFO  | [dispatcher-event-loop-38] | Starting task 80.0 in stage 12.0 (TID 698, dn08, executor 16, partition 80, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,154 | INFO  | [task-result-getter-2] | Finished task 9.0 in stage 12.0 (TID 652) in 10195 ms on dn08 (executor 16) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,262 | INFO  | [dispatcher-event-loop-37] | Starting task 81.0 in stage 12.0 (TID 699, dn08, executor 16, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,263 | INFO  | [task-result-getter-1] | Finished task 38.0 in stage 12.0 (TID 653) in 10202 ms on dn08 (executor 16) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,375 | INFO  | [dispatcher-event-loop-11] | Starting task 77.0 in stage 12.0 (TID 700, dn37, executor 8, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,376 | INFO  | [task-result-getter-0] | Finished task 55.0 in stage 12.0 (TID 659) in 9526 ms on dn37 (executor 8) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,587 | INFO  | [dispatcher-event-loop-44] | Starting task 40.0 in stage 14.0 (TID 701, dn32, executor 4, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,588 | INFO  | [task-result-getter-3] | Finished task 44.0 in stage 12.0 (TID 657) in 9873 ms on dn32 (executor 4) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,905 | INFO  | [dispatcher-event-loop-43] | Starting task 2.0 in stage 14.0 (TID 702, dn28, executor 3, partition 2, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,906 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 12.0 (TID 660) in 9857 ms on dn28 (executor 3) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:24,916 | INFO  | [dispatcher-event-loop-41] | Added broadcast_14_piece0 in memory on dn28:22784 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:25,876 | INFO  | [dispatcher-event-loop-50] | Starting task 88.0 in stage 12.0 (TID 703, dn24, executor 9, partition 88, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:25,877 | INFO  | [task-result-getter-1] | Finished task 61.0 in stage 10.0 (TID 668) in 6959 ms on dn24 (executor 9) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:25,952 | INFO  | [dispatcher-event-loop-55] | Starting task 0.0 in stage 14.0 (TID 704, dn36, executor 20, partition 0, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:25,953 | INFO  | [task-result-getter-0] | Finished task 68.0 in stage 12.0 (TID 661) in 10724 ms on dn36 (executor 20) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:25,966 | INFO  | [dispatcher-event-loop-54] | Added broadcast_14_piece0 in memory on dn36:22756 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,015 | INFO  | [dispatcher-event-loop-67] | Starting task 83.0 in stage 12.0 (TID 705, dn15, executor 12, partition 83, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,016 | INFO  | [task-result-getter-3] | Finished task 60.0 in stage 10.0 (TID 667) in 7185 ms on dn15 (executor 12) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,135 | INFO  | [dispatcher-event-loop-60] | Starting task 30.0 in stage 14.0 (TID 706, dn10, executor 19, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,136 | INFO  | [task-result-getter-2] | Finished task 49.0 in stage 10.0 (TID 666) in 7605 ms on dn10 (executor 19) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,136 | INFO  | [task-result-getter-2] | Removed TaskSet 10.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,137 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 10 (distinct at GraphWriter.scala:253) finished in 28.975 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,137 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,138 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 12, ShuffleMapStage 14) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,138 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ShuffleMapStage 15, ResultStage 16, ShuffleMapStage 13, ShuffleMapStage 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,138 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,139 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 11 (MapPartitionsRDD[33] at mapPartitions at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,149 | INFO  | [dispatcher-event-loop-0] | Added broadcast_14_piece0 in memory on dn10:22719 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,161 | INFO  | [dag-scheduler-event-loop] | Block broadcast_15 stored as values in memory (estimated size 7.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,165 | INFO  | [dag-scheduler-event-loop] | Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,166 | INFO  | [dispatcher-event-loop-61] | Added broadcast_15_piece0 in memory on dn37:22779 (size: 4.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,166 | INFO  | [dag-scheduler-event-loop] | Created broadcast 15 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,168 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[33] at mapPartitions at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:26,168 | INFO  | [dag-scheduler-event-loop] | Adding task set 11.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,648 | INFO  | [dispatcher-event-loop-12] | Starting task 0.0 in stage 11.0 (TID 707, dn07, executor 14, partition 0, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,649 | INFO  | [task-result-getter-1] | Finished task 11.0 in stage 12.0 (TID 664) in 9295 ms on dn07 (executor 14) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,658 | INFO  | [dispatcher-event-loop-25] | Added broadcast_15_piece0 in memory on dn07:22897 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,668 | INFO  | [dispatcher-event-loop-18] | Asked to send map output locations for shuffle 7 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,715 | INFO  | [dispatcher-event-loop-31] | Starting task 1.0 in stage 11.0 (TID 708, dn07, executor 14, partition 1, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,715 | INFO  | [task-result-getter-0] | Finished task 13.0 in stage 12.0 (TID 665) in 9287 ms on dn07 (executor 14) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,831 | INFO  | [dispatcher-event-loop-24] | Starting task 2.0 in stage 11.0 (TID 709, dn07, executor 14, partition 2, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,832 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 11.0 (TID 707) in 184 ms on dn07 (executor 14) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,832 | INFO  | [dispatcher-event-loop-24] | Starting task 3.0 in stage 11.0 (TID 710, dn07, executor 14, partition 3, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,833 | INFO  | [task-result-getter-2] | Finished task 1.0 in stage 11.0 (TID 708) in 118 ms on dn07 (executor 14) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,868 | INFO  | [dispatcher-event-loop-32] | Starting task 4.0 in stage 11.0 (TID 711, dn07, executor 14, partition 4, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,869 | INFO  | [task-result-getter-1] | Finished task 3.0 in stage 11.0 (TID 710) in 37 ms on dn07 (executor 14) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,871 | INFO  | [dispatcher-event-loop-30] | Starting task 5.0 in stage 11.0 (TID 712, dn07, executor 14, partition 5, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,871 | INFO  | [task-result-getter-0] | Finished task 2.0 in stage 11.0 (TID 709) in 40 ms on dn07 (executor 14) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,906 | INFO  | [dispatcher-event-loop-21] | Starting task 6.0 in stage 11.0 (TID 713, dn07, executor 14, partition 6, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,906 | INFO  | [task-result-getter-3] | Finished task 4.0 in stage 11.0 (TID 711) in 38 ms on dn07 (executor 14) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,908 | INFO  | [dispatcher-event-loop-42] | Starting task 7.0 in stage 11.0 (TID 714, dn07, executor 14, partition 7, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,909 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 11.0 (TID 712) in 39 ms on dn07 (executor 14) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,949 | INFO  | [dispatcher-event-loop-13] | Starting task 8.0 in stage 11.0 (TID 715, dn07, executor 14, partition 8, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,950 | INFO  | [task-result-getter-1] | Finished task 6.0 in stage 11.0 (TID 713) in 44 ms on dn07 (executor 14) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,976 | INFO  | [dispatcher-event-loop-29] | Starting task 9.0 in stage 11.0 (TID 716, dn07, executor 14, partition 9, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,977 | INFO  | [task-result-getter-0] | Finished task 7.0 in stage 11.0 (TID 714) in 69 ms on dn07 (executor 14) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,993 | INFO  | [dispatcher-event-loop-40] | Starting task 10.0 in stage 11.0 (TID 717, dn07, executor 14, partition 10, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:27,993 | INFO  | [task-result-getter-3] | Finished task 8.0 in stage 11.0 (TID 715) in 44 ms on dn07 (executor 14) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,007 | INFO  | [dispatcher-event-loop-49] | Starting task 11.0 in stage 11.0 (TID 718, dn07, executor 14, partition 11, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,008 | INFO  | [task-result-getter-2] | Finished task 9.0 in stage 11.0 (TID 716) in 32 ms on dn07 (executor 14) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,023 | INFO  | [dispatcher-event-loop-47] | Starting task 12.0 in stage 11.0 (TID 719, dn07, executor 14, partition 12, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,024 | INFO  | [task-result-getter-1] | Finished task 10.0 in stage 11.0 (TID 717) in 31 ms on dn07 (executor 14) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,029 | INFO  | [dispatcher-event-loop-44] | Starting task 13.0 in stage 11.0 (TID 720, dn07, executor 14, partition 13, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,029 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 11.0 (TID 718) in 22 ms on dn07 (executor 14) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,046 | INFO  | [dispatcher-event-loop-43] | Starting task 14.0 in stage 11.0 (TID 721, dn07, executor 14, partition 14, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,047 | INFO  | [task-result-getter-3] | Finished task 12.0 in stage 11.0 (TID 719) in 24 ms on dn07 (executor 14) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,050 | INFO  | [dispatcher-event-loop-51] | Starting task 15.0 in stage 11.0 (TID 722, dn07, executor 14, partition 15, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,051 | INFO  | [task-result-getter-2] | Finished task 13.0 in stage 11.0 (TID 720) in 22 ms on dn07 (executor 14) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,053 | INFO  | [dispatcher-event-loop-48] | Starting task 16.0 in stage 11.0 (TID 723, dn07, executor 14, partition 16, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,054 | INFO  | [task-result-getter-1] | Finished task 14.0 in stage 11.0 (TID 721) in 8 ms on dn07 (executor 14) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,093 | INFO  | [dispatcher-event-loop-58] | Starting task 17.0 in stage 11.0 (TID 724, dn07, executor 14, partition 17, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,094 | INFO  | [task-result-getter-0] | Finished task 15.0 in stage 11.0 (TID 722) in 43 ms on dn07 (executor 14) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,094 | INFO  | [dispatcher-event-loop-58] | Starting task 18.0 in stage 11.0 (TID 725, dn07, executor 14, partition 18, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,094 | INFO  | [task-result-getter-3] | Finished task 16.0 in stage 11.0 (TID 723) in 41 ms on dn07 (executor 14) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,130 | INFO  | [dispatcher-event-loop-64] | Starting task 19.0 in stage 11.0 (TID 726, dn07, executor 14, partition 19, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,130 | INFO  | [task-result-getter-2] | Finished task 18.0 in stage 11.0 (TID 725) in 36 ms on dn07 (executor 14) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,133 | INFO  | [dispatcher-event-loop-63] | Starting task 20.0 in stage 11.0 (TID 727, dn07, executor 14, partition 20, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,134 | INFO  | [task-result-getter-1] | Finished task 17.0 in stage 11.0 (TID 724) in 41 ms on dn07 (executor 14) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,164 | INFO  | [dispatcher-event-loop-70] | Starting task 21.0 in stage 11.0 (TID 728, dn07, executor 14, partition 21, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,164 | INFO  | [task-result-getter-0] | Finished task 20.0 in stage 11.0 (TID 727) in 31 ms on dn07 (executor 14) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,170 | INFO  | [dispatcher-event-loop-59] | Starting task 22.0 in stage 11.0 (TID 729, dn07, executor 14, partition 22, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,171 | INFO  | [task-result-getter-3] | Finished task 19.0 in stage 11.0 (TID 726) in 41 ms on dn07 (executor 14) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,190 | INFO  | [dispatcher-event-loop-45] | Starting task 23.0 in stage 11.0 (TID 730, dn07, executor 14, partition 23, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,191 | INFO  | [task-result-getter-2] | Finished task 21.0 in stage 11.0 (TID 728) in 27 ms on dn07 (executor 14) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,212 | INFO  | [dispatcher-event-loop-54] | Starting task 24.0 in stage 11.0 (TID 731, dn07, executor 14, partition 24, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,213 | INFO  | [task-result-getter-1] | Finished task 23.0 in stage 11.0 (TID 730) in 23 ms on dn07 (executor 14) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,213 | INFO  | [dispatcher-event-loop-54] | Starting task 25.0 in stage 11.0 (TID 732, dn07, executor 14, partition 25, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,214 | INFO  | [task-result-getter-0] | Finished task 22.0 in stage 11.0 (TID 729) in 44 ms on dn07 (executor 14) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,268 | INFO  | [dispatcher-event-loop-68] | Starting task 26.0 in stage 11.0 (TID 733, dn07, executor 14, partition 26, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,268 | INFO  | [task-result-getter-3] | Finished task 25.0 in stage 11.0 (TID 732) in 55 ms on dn07 (executor 14) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,269 | INFO  | [dispatcher-event-loop-68] | Starting task 27.0 in stage 11.0 (TID 734, dn07, executor 14, partition 27, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,269 | INFO  | [task-result-getter-2] | Finished task 24.0 in stage 11.0 (TID 731) in 57 ms on dn07 (executor 14) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,308 | INFO  | [dispatcher-event-loop-3] | Starting task 28.0 in stage 11.0 (TID 735, dn07, executor 14, partition 28, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,308 | INFO  | [task-result-getter-1] | Finished task 26.0 in stage 11.0 (TID 733) in 40 ms on dn07 (executor 14) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,309 | INFO  | [dispatcher-event-loop-71] | Starting task 29.0 in stage 11.0 (TID 736, dn07, executor 14, partition 29, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,309 | INFO  | [task-result-getter-0] | Finished task 27.0 in stage 11.0 (TID 734) in 40 ms on dn07 (executor 14) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,356 | INFO  | [dispatcher-event-loop-15] | Starting task 30.0 in stage 11.0 (TID 737, dn07, executor 14, partition 30, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,356 | INFO  | [task-result-getter-3] | Finished task 29.0 in stage 11.0 (TID 736) in 47 ms on dn07 (executor 14) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,357 | INFO  | [dispatcher-event-loop-15] | Starting task 31.0 in stage 11.0 (TID 738, dn07, executor 14, partition 31, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,357 | INFO  | [task-result-getter-2] | Finished task 28.0 in stage 11.0 (TID 735) in 49 ms on dn07 (executor 14) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,379 | INFO  | [dispatcher-event-loop-12] | Starting task 32.0 in stage 11.0 (TID 739, dn07, executor 14, partition 32, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,380 | INFO  | [task-result-getter-1] | Finished task 30.0 in stage 11.0 (TID 737) in 24 ms on dn07 (executor 14) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,381 | INFO  | [dispatcher-event-loop-2] | Starting task 33.0 in stage 11.0 (TID 740, dn07, executor 14, partition 33, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,381 | INFO  | [task-result-getter-0] | Finished task 31.0 in stage 11.0 (TID 738) in 24 ms on dn07 (executor 14) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,399 | INFO  | [dispatcher-event-loop-18] | Starting task 34.0 in stage 11.0 (TID 741, dn07, executor 14, partition 34, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,399 | INFO  | [task-result-getter-3] | Finished task 33.0 in stage 11.0 (TID 740) in 19 ms on dn07 (executor 14) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,401 | INFO  | [dispatcher-event-loop-14] | Starting task 35.0 in stage 11.0 (TID 742, dn07, executor 14, partition 35, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,401 | INFO  | [task-result-getter-2] | Finished task 32.0 in stage 11.0 (TID 739) in 22 ms on dn07 (executor 14) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,419 | INFO  | [dispatcher-event-loop-27] | Starting task 36.0 in stage 11.0 (TID 743, dn07, executor 14, partition 36, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,420 | INFO  | [task-result-getter-1] | Finished task 34.0 in stage 11.0 (TID 741) in 21 ms on dn07 (executor 14) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,420 | INFO  | [dispatcher-event-loop-27] | Starting task 38.0 in stage 11.0 (TID 744, dn07, executor 14, partition 38, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,421 | INFO  | [task-result-getter-0] | Finished task 35.0 in stage 11.0 (TID 742) in 20 ms on dn07 (executor 14) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,439 | INFO  | [dispatcher-event-loop-32] | Starting task 39.0 in stage 11.0 (TID 745, dn07, executor 14, partition 39, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,439 | INFO  | [task-result-getter-3] | Finished task 36.0 in stage 11.0 (TID 743) in 20 ms on dn07 (executor 14) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,440 | INFO  | [dispatcher-event-loop-32] | Starting task 40.0 in stage 11.0 (TID 746, dn07, executor 14, partition 40, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,440 | INFO  | [task-result-getter-2] | Finished task 38.0 in stage 11.0 (TID 744) in 20 ms on dn07 (executor 14) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,460 | INFO  | [dispatcher-event-loop-21] | Starting task 41.0 in stage 11.0 (TID 747, dn07, executor 14, partition 41, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,461 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 11.0 (TID 746) in 21 ms on dn07 (executor 14) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,462 | INFO  | [dispatcher-event-loop-26] | Starting task 42.0 in stage 11.0 (TID 748, dn07, executor 14, partition 42, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,462 | INFO  | [task-result-getter-0] | Finished task 39.0 in stage 11.0 (TID 745) in 23 ms on dn07 (executor 14) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,482 | INFO  | [dispatcher-event-loop-13] | Starting task 43.0 in stage 11.0 (TID 749, dn07, executor 14, partition 43, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,482 | INFO  | [task-result-getter-3] | Finished task 42.0 in stage 11.0 (TID 748) in 20 ms on dn07 (executor 14) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,486 | INFO  | [dispatcher-event-loop-29] | Starting task 44.0 in stage 11.0 (TID 750, dn07, executor 14, partition 44, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,486 | INFO  | [task-result-getter-2] | Finished task 41.0 in stage 11.0 (TID 747) in 26 ms on dn07 (executor 14) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,501 | INFO  | [dispatcher-event-loop-40] | Starting task 45.0 in stage 11.0 (TID 751, dn07, executor 14, partition 45, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,502 | INFO  | [task-result-getter-1] | Finished task 43.0 in stage 11.0 (TID 749) in 20 ms on dn07 (executor 14) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,504 | INFO  | [dispatcher-event-loop-49] | Starting task 46.0 in stage 11.0 (TID 752, dn07, executor 14, partition 46, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,505 | INFO  | [task-result-getter-0] | Finished task 44.0 in stage 11.0 (TID 750) in 20 ms on dn07 (executor 14) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,528 | INFO  | [dispatcher-event-loop-47] | Starting task 47.0 in stage 11.0 (TID 753, dn07, executor 14, partition 47, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,529 | INFO  | [task-result-getter-3] | Finished task 45.0 in stage 11.0 (TID 751) in 27 ms on dn07 (executor 14) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,531 | INFO  | [dispatcher-event-loop-11] | Starting task 48.0 in stage 11.0 (TID 754, dn07, executor 14, partition 48, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,532 | INFO  | [task-result-getter-2] | Finished task 46.0 in stage 11.0 (TID 752) in 28 ms on dn07 (executor 14) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,554 | INFO  | [dispatcher-event-loop-44] | Starting task 49.0 in stage 11.0 (TID 755, dn07, executor 14, partition 49, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,555 | INFO  | [task-result-getter-1] | Finished task 48.0 in stage 11.0 (TID 754) in 24 ms on dn07 (executor 14) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,556 | INFO  | [dispatcher-event-loop-44] | Starting task 50.0 in stage 11.0 (TID 756, dn07, executor 14, partition 50, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,556 | INFO  | [task-result-getter-0] | Finished task 47.0 in stage 11.0 (TID 753) in 28 ms on dn07 (executor 14) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,606 | INFO  | [dispatcher-event-loop-51] | Starting task 51.0 in stage 11.0 (TID 757, dn07, executor 14, partition 51, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,607 | INFO  | [task-result-getter-3] | Finished task 49.0 in stage 11.0 (TID 755) in 53 ms on dn07 (executor 14) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,609 | INFO  | [dispatcher-event-loop-41] | Starting task 52.0 in stage 11.0 (TID 758, dn07, executor 14, partition 52, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,609 | INFO  | [task-result-getter-2] | Finished task 50.0 in stage 11.0 (TID 756) in 54 ms on dn07 (executor 14) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,626 | INFO  | [dispatcher-event-loop-35] | Starting task 53.0 in stage 11.0 (TID 759, dn07, executor 14, partition 53, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,627 | INFO  | [task-result-getter-1] | Finished task 52.0 in stage 11.0 (TID 758) in 18 ms on dn07 (executor 14) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,660 | INFO  | [dispatcher-event-loop-66] | Starting task 54.0 in stage 11.0 (TID 760, dn07, executor 14, partition 54, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,661 | INFO  | [task-result-getter-0] | Finished task 51.0 in stage 11.0 (TID 757) in 55 ms on dn07 (executor 14) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,661 | INFO  | [dispatcher-event-loop-66] | Starting task 55.0 in stage 11.0 (TID 761, dn07, executor 14, partition 55, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,662 | INFO  | [task-result-getter-3] | Finished task 53.0 in stage 11.0 (TID 759) in 36 ms on dn07 (executor 14) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,685 | INFO  | [dispatcher-event-loop-50] | Starting task 56.0 in stage 11.0 (TID 762, dn07, executor 14, partition 56, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,685 | INFO  | [task-result-getter-2] | Finished task 55.0 in stage 11.0 (TID 761) in 24 ms on dn07 (executor 14) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,686 | INFO  | [dispatcher-event-loop-50] | Starting task 57.0 in stage 11.0 (TID 763, dn07, executor 14, partition 57, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,686 | INFO  | [task-result-getter-1] | Finished task 54.0 in stage 11.0 (TID 760) in 26 ms on dn07 (executor 14) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,705 | INFO  | [dispatcher-event-loop-55] | Starting task 58.0 in stage 11.0 (TID 764, dn07, executor 14, partition 58, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,705 | INFO  | [task-result-getter-0] | Finished task 57.0 in stage 11.0 (TID 763) in 19 ms on dn07 (executor 14) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,707 | INFO  | [dispatcher-event-loop-45] | Starting task 59.0 in stage 11.0 (TID 765, dn07, executor 14, partition 59, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,707 | INFO  | [task-result-getter-3] | Finished task 56.0 in stage 11.0 (TID 762) in 22 ms on dn07 (executor 14) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,723 | INFO  | [dispatcher-event-loop-54] | Starting task 60.0 in stage 11.0 (TID 766, dn07, executor 14, partition 60, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,723 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 11.0 (TID 764) in 19 ms on dn07 (executor 14) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,725 | INFO  | [dispatcher-event-loop-69] | Starting task 61.0 in stage 11.0 (TID 767, dn07, executor 14, partition 61, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,725 | INFO  | [task-result-getter-1] | Finished task 59.0 in stage 11.0 (TID 765) in 18 ms on dn07 (executor 14) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,743 | INFO  | [dispatcher-event-loop-68] | Starting task 62.0 in stage 11.0 (TID 768, dn07, executor 14, partition 62, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,744 | INFO  | [task-result-getter-0] | Finished task 60.0 in stage 11.0 (TID 766) in 21 ms on dn07 (executor 14) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,745 | INFO  | [dispatcher-event-loop-68] | Starting task 37.0 in stage 11.0 (TID 769, dn18, executor 10, partition 37, NODE_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,745 | INFO  | [task-result-getter-3] | Finished task 33.0 in stage 12.0 (TID 670) in 9496 ms on dn18 (executor 10) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,745 | INFO  | [dispatcher-event-loop-68] | Starting task 63.0 in stage 11.0 (TID 770, dn07, executor 14, partition 63, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,746 | INFO  | [task-result-getter-2] | Finished task 61.0 in stage 11.0 (TID 767) in 21 ms on dn07 (executor 14) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,751 | INFO  | [dispatcher-event-loop-7] | Starting task 65.0 in stage 11.0 (TID 771, dn07, executor 14, partition 65, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,751 | INFO  | [task-result-getter-1] | Finished task 63.0 in stage 11.0 (TID 770) in 6 ms on dn07 (executor 14) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,753 | INFO  | [dispatcher-event-loop-17] | Added broadcast_15_piece0 in memory on dn18:22756 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,756 | INFO  | [dispatcher-event-loop-15] | Starting task 66.0 in stage 11.0 (TID 772, dn07, executor 14, partition 66, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,757 | INFO  | [task-result-getter-0] | Finished task 62.0 in stage 11.0 (TID 768) in 14 ms on dn07 (executor 14) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,766 | INFO  | [dispatcher-event-loop-16] | Asked to send map output locations for shuffle 7 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,771 | INFO  | [dispatcher-event-loop-12] | Starting task 67.0 in stage 11.0 (TID 773, dn07, executor 14, partition 67, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,772 | INFO  | [task-result-getter-3] | Finished task 65.0 in stage 11.0 (TID 771) in 21 ms on dn07 (executor 14) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,775 | INFO  | [dispatcher-event-loop-19] | Starting task 68.0 in stage 11.0 (TID 774, dn07, executor 14, partition 68, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,776 | INFO  | [task-result-getter-2] | Finished task 66.0 in stage 11.0 (TID 772) in 20 ms on dn07 (executor 14) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,787 | INFO  | [dispatcher-event-loop-18] | Starting task 69.0 in stage 11.0 (TID 775, dn07, executor 14, partition 69, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,788 | INFO  | [task-result-getter-1] | Finished task 67.0 in stage 11.0 (TID 773) in 17 ms on dn07 (executor 14) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,796 | INFO  | [dispatcher-event-loop-14] | Starting task 70.0 in stage 11.0 (TID 776, dn07, executor 14, partition 70, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,797 | INFO  | [task-result-getter-0] | Finished task 68.0 in stage 11.0 (TID 774) in 22 ms on dn07 (executor 14) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,801 | INFO  | [dispatcher-event-loop-24] | Starting task 71.0 in stage 11.0 (TID 777, dn07, executor 14, partition 71, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,801 | INFO  | [task-result-getter-3] | Finished task 69.0 in stage 11.0 (TID 775) in 14 ms on dn07 (executor 14) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,809 | INFO  | [dispatcher-event-loop-20] | Starting task 64.0 in stage 11.0 (TID 778, dn18, executor 10, partition 64, NODE_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,810 | INFO  | [task-result-getter-2] | Finished task 37.0 in stage 11.0 (TID 769) in 66 ms on dn18 (executor 10) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,821 | INFO  | [dispatcher-event-loop-22] | Starting task 72.0 in stage 11.0 (TID 779, dn15, executor 12, partition 72, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,822 | INFO  | [task-result-getter-1] | Finished task 10.0 in stage 12.0 (TID 669) in 9603 ms on dn15 (executor 12) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,829 | INFO  | [dispatcher-event-loop-57] | Starting task 73.0 in stage 11.0 (TID 780, dn18, executor 10, partition 73, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,830 | INFO  | [task-result-getter-0] | Finished task 64.0 in stage 11.0 (TID 778) in 21 ms on dn18 (executor 10) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,831 | INFO  | [dispatcher-event-loop-21] | Starting task 74.0 in stage 11.0 (TID 781, dn07, executor 14, partition 74, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,832 | INFO  | [task-result-getter-3] | Finished task 71.0 in stage 11.0 (TID 777) in 31 ms on dn07 (executor 14) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,834 | INFO  | [dispatcher-event-loop-39] | Starting task 75.0 in stage 11.0 (TID 782, dn07, executor 14, partition 75, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,835 | INFO  | [task-result-getter-2] | Finished task 70.0 in stage 11.0 (TID 776) in 39 ms on dn07 (executor 14) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,839 | INFO  | [dispatcher-event-loop-23] | Added broadcast_15_piece0 in memory on dn15:22640 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,849 | INFO  | [dispatcher-event-loop-29] | Starting task 76.0 in stage 11.0 (TID 783, dn07, executor 14, partition 76, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,850 | INFO  | [task-result-getter-1] | Finished task 74.0 in stage 11.0 (TID 781) in 19 ms on dn07 (executor 14) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,856 | INFO  | [dispatcher-event-loop-40] | Starting task 78.0 in stage 11.0 (TID 784, dn07, executor 14, partition 78, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,856 | INFO  | [task-result-getter-0] | Finished task 75.0 in stage 11.0 (TID 782) in 22 ms on dn07 (executor 14) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,856 | INFO  | [dispatcher-event-loop-38] | Asked to send map output locations for shuffle 7 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,866 | INFO  | [dispatcher-event-loop-37] | Starting task 79.0 in stage 11.0 (TID 785, dn07, executor 14, partition 79, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,866 | INFO  | [task-result-getter-3] | Finished task 76.0 in stage 11.0 (TID 783) in 17 ms on dn07 (executor 14) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,868 | INFO  | [dispatcher-event-loop-47] | Starting task 80.0 in stage 11.0 (TID 786, dn18, executor 10, partition 80, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,869 | INFO  | [task-result-getter-2] | Finished task 73.0 in stage 11.0 (TID 780) in 40 ms on dn18 (executor 10) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,882 | INFO  | [dispatcher-event-loop-56] | Starting task 81.0 in stage 11.0 (TID 787, dn07, executor 14, partition 81, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,882 | INFO  | [task-result-getter-1] | Finished task 79.0 in stage 11.0 (TID 785) in 16 ms on dn07 (executor 14) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,883 | INFO  | [dispatcher-event-loop-56] | Starting task 82.0 in stage 11.0 (TID 788, dn07, executor 14, partition 82, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,883 | INFO  | [task-result-getter-0] | Finished task 78.0 in stage 11.0 (TID 784) in 27 ms on dn07 (executor 14) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,905 | INFO  | [dispatcher-event-loop-33] | Starting task 83.0 in stage 11.0 (TID 789, dn07, executor 14, partition 83, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,905 | INFO  | [task-result-getter-3] | Finished task 81.0 in stage 11.0 (TID 787) in 23 ms on dn07 (executor 14) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,906 | INFO  | [dispatcher-event-loop-51] | Starting task 84.0 in stage 11.0 (TID 790, dn07, executor 14, partition 84, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,906 | INFO  | [task-result-getter-2] | Finished task 82.0 in stage 11.0 (TID 788) in 23 ms on dn07 (executor 14) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,908 | INFO  | [dispatcher-event-loop-41] | Starting task 85.0 in stage 11.0 (TID 791, dn18, executor 10, partition 85, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,908 | INFO  | [task-result-getter-1] | Finished task 80.0 in stage 11.0 (TID 786) in 40 ms on dn18 (executor 10) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,935 | INFO  | [dispatcher-event-loop-58] | Starting task 86.0 in stage 11.0 (TID 792, dn07, executor 14, partition 86, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,935 | INFO  | [task-result-getter-0] | Finished task 83.0 in stage 11.0 (TID 789) in 31 ms on dn07 (executor 14) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,938 | INFO  | [dispatcher-event-loop-66] | Starting task 87.0 in stage 11.0 (TID 793, dn18, executor 10, partition 87, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,939 | INFO  | [task-result-getter-3] | Finished task 85.0 in stage 11.0 (TID 791) in 31 ms on dn18 (executor 10) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,939 | INFO  | [dispatcher-event-loop-64] | Starting task 88.0 in stage 11.0 (TID 794, dn07, executor 14, partition 88, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,940 | INFO  | [task-result-getter-2] | Finished task 84.0 in stage 11.0 (TID 790) in 34 ms on dn07 (executor 14) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,948 | INFO  | [dispatcher-event-loop-70] | Starting task 89.0 in stage 11.0 (TID 795, dn15, executor 12, partition 89, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,948 | INFO  | [task-result-getter-1] | Finished task 72.0 in stage 11.0 (TID 779) in 127 ms on dn15 (executor 12) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,953 | INFO  | [dispatcher-event-loop-53] | Starting task 76.0 in stage 12.0 (TID 796, dn07, executor 14, partition 76, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,954 | INFO  | [task-result-getter-0] | Finished task 86.0 in stage 11.0 (TID 792) in 20 ms on dn07 (executor 14) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,960 | INFO  | [dispatcher-event-loop-55] | Starting task 11.0 in stage 14.0 (TID 797, dn07, executor 14, partition 11, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,961 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 11.0 (TID 794) in 22 ms on dn07 (executor 14) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,974 | INFO  | [dispatcher-event-loop-67] | Starting task 85.0 in stage 12.0 (TID 798, dn18, executor 10, partition 85, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,974 | INFO  | [task-result-getter-2] | Finished task 87.0 in stage 11.0 (TID 793) in 36 ms on dn18 (executor 10) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,980 | INFO  | [dispatcher-event-loop-60] | Starting task 86.0 in stage 12.0 (TID 799, dn15, executor 12, partition 86, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,981 | INFO  | [task-result-getter-1] | Finished task 89.0 in stage 11.0 (TID 795) in 33 ms on dn15 (executor 12) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:28,983 | INFO  | [dispatcher-event-loop-65] | Added broadcast_14_piece0 in memory on dn07:22897 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:29,208 | INFO  | [dispatcher-event-loop-0] | Starting task 44.0 in stage 14.0 (TID 800, dn32, executor 4, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:29,209 | INFO  | [task-result-getter-0] | Finished task 7.0 in stage 14.0 (TID 681) in 7273 ms on dn32 (executor 4) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:29,706 | INFO  | [dispatcher-event-loop-68] | Starting task 45.0 in stage 12.0 (TID 801, dn22, executor 5, partition 45, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:29,707 | INFO  | [task-result-getter-3] | Finished task 5.0 in stage 12.0 (TID 671) in 10015 ms on dn22 (executor 5) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:29,854 | INFO  | [dispatcher-event-loop-8] | Starting task 87.0 in stage 12.0 (TID 802, dn19, executor 11, partition 87, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:29,854 | INFO  | [task-result-getter-2] | Finished task 53.0 in stage 12.0 (TID 672) in 9868 ms on dn19 (executor 11) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,318 | INFO  | [dispatcher-event-loop-25] | Starting task 65.0 in stage 12.0 (TID 803, dn17, executor 18, partition 65, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,319 | INFO  | [task-result-getter-1] | Finished task 17.0 in stage 12.0 (TID 673) in 11031 ms on dn17 (executor 18) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,355 | INFO  | [dispatcher-event-loop-31] | Starting task 3.0 in stage 14.0 (TID 804, dn18, executor 10, partition 3, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,356 | INFO  | [task-result-getter-0] | Finished task 78.0 in stage 12.0 (TID 677) in 9811 ms on dn18 (executor 10) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,368 | INFO  | [dispatcher-event-loop-24] | Added broadcast_14_piece0 in memory on dn18:22756 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,384 | INFO  | [dispatcher-event-loop-27] | Starting task 15.0 in stage 14.0 (TID 805, dn28, executor 3, partition 15, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,385 | INFO  | [task-result-getter-3] | Finished task 75.0 in stage 12.0 (TID 680) in 9531 ms on dn28 (executor 3) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,496 | INFO  | [dispatcher-event-loop-6] | Starting task 89.0 in stage 12.0 (TID 806, dn24, executor 9, partition 89, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,497 | INFO  | [task-result-getter-2] | Finished task 48.0 in stage 12.0 (TID 679) in 9822 ms on dn24 (executor 9) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,510 | INFO  | [dispatcher-event-loop-32] | Starting task 67.0 in stage 12.0 (TID 807, dn17, executor 18, partition 67, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,510 | INFO  | [task-result-getter-1] | Finished task 29.0 in stage 12.0 (TID 675) in 10947 ms on dn17 (executor 18) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,521 | INFO  | [dispatcher-event-loop-57] | Starting task 37.0 in stage 14.0 (TID 808, dn20, executor 13, partition 37, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,521 | INFO  | [task-result-getter-0] | Finished task 82.0 in stage 12.0 (TID 678) in 9962 ms on dn20 (executor 13) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,582 | INFO  | [dispatcher-event-loop-21] | Starting task 22.0 in stage 14.0 (TID 809, dn16, executor 15, partition 22, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,582 | INFO  | [task-result-getter-3] | Finished task 20.0 in stage 14.0 (TID 692) in 7897 ms on dn16 (executor 15) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,789 | INFO  | [dispatcher-event-loop-29] | Starting task 23.0 in stage 14.0 (TID 810, dn16, executor 15, partition 23, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,789 | INFO  | [task-result-getter-2] | Finished task 21.0 in stage 14.0 (TID 697) in 7713 ms on dn16 (executor 15) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,840 | INFO  | [dispatcher-event-loop-40] | Starting task 77.0 in stage 11.0 (TID 811, dn37, executor 8, partition 77, RACK_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,840 | INFO  | [task-result-getter-1] | Finished task 64.0 in stage 12.0 (TID 682) in 9859 ms on dn37 (executor 8) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,849 | INFO  | [dispatcher-event-loop-37] | Added broadcast_15_piece0 in memory on dn37:22861 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,866 | INFO  | [dispatcher-event-loop-34] | Asked to send map output locations for shuffle 7 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,933 | INFO  | [dispatcher-event-loop-47] | Starting task 79.0 in stage 14.0 (TID 812, dn20, executor 13, partition 79, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,933 | INFO  | [task-result-getter-0] | Finished task 36.0 in stage 14.0 (TID 695) in 7975 ms on dn20 (executor 13) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,958 | INFO  | [dispatcher-event-loop-4] | Starting task 4.0 in stage 14.0 (TID 813, dn37, executor 8, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,958 | INFO  | [task-result-getter-3] | Finished task 77.0 in stage 11.0 (TID 811) in 118 ms on dn37 (executor 8) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,959 | INFO  | [task-result-getter-3] | Removed TaskSet 11.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,959 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 11 (mapPartitions at GraphWriter.scala:253) finished in 5.804 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,959 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,960 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 12, ShuffleMapStage 14) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,960 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ShuffleMapStage 15, ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,960 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:31,966 | INFO  | [dispatcher-event-loop-43] | Added broadcast_14_piece0 in memory on dn37:22861 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,052 | INFO  | [dispatcher-event-loop-33] | Starting task 51.0 in stage 12.0 (TID 814, dn30, executor 2, partition 51, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,053 | INFO  | [task-result-getter-2] | Finished task 28.0 in stage 12.0 (TID 683) in 9888 ms on dn30 (executor 2) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,067 | INFO  | [dispatcher-event-loop-48] | Starting task 62.0 in stage 12.0 (TID 815, dn14, executor 17, partition 62, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,067 | INFO  | [task-result-getter-1] | Finished task 24.0 in stage 12.0 (TID 674) in 11588 ms on dn14 (executor 17) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,152 | INFO  | [dispatcher-event-loop-41] | Starting task 16.0 in stage 14.0 (TID 816, dn30, executor 2, partition 16, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,153 | INFO  | [task-result-getter-0] | Finished task 50.0 in stage 12.0 (TID 684) in 9890 ms on dn30 (executor 2) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,199 | INFO  | [dispatcher-event-loop-36] | Added broadcast_14_piece0 in memory on dn30:22608 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,225 | INFO  | [dispatcher-event-loop-46] | Starting task 26.0 in stage 14.0 (TID 817, dn19, executor 11, partition 26, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,226 | INFO  | [task-result-getter-3] | Finished task 59.0 in stage 12.0 (TID 687) in 9407 ms on dn19 (executor 11) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,230 | INFO  | [dispatcher-event-loop-70] | Starting task 57.0 in stage 12.0 (TID 818, dn27, executor 7, partition 57, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,230 | INFO  | [task-result-getter-2] | Finished task 46.0 in stage 12.0 (TID 686) in 9717 ms on dn27 (executor 7) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,234 | INFO  | [dispatcher-event-loop-59] | Added broadcast_14_piece0 in memory on dn19:22830 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,344 | INFO  | [dispatcher-event-loop-55] | Starting task 58.0 in stage 14.0 (TID 819, dn32, executor 4, partition 58, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,344 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 14.0 (TID 701) in 7757 ms on dn32 (executor 4) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,371 | INFO  | [dispatcher-event-loop-45] | Starting task 63.0 in stage 12.0 (TID 820, dn14, executor 17, partition 63, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,371 | INFO  | [task-result-getter-0] | Finished task 25.0 in stage 12.0 (TID 676) in 11219 ms on dn14 (executor 17) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,387 | INFO  | [dispatcher-event-loop-54] | Starting task 71.0 in stage 12.0 (TID 821, dn22, executor 5, partition 71, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,387 | INFO  | [task-result-getter-3] | Finished task 18.0 in stage 12.0 (TID 685) in 10082 ms on dn22 (executor 5) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,592 | INFO  | [dispatcher-event-loop-0] | Starting task 38.0 in stage 14.0 (TID 822, dn28, executor 3, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,593 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 14.0 (TID 702) in 7688 ms on dn28 (executor 3) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,995 | INFO  | [dispatcher-event-loop-68] | Starting task 14.0 in stage 14.0 (TID 823, dn27, executor 7, partition 14, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:32,995 | INFO  | [task-result-getter-1] | Finished task 47.0 in stage 12.0 (TID 688) in 10096 ms on dn27 (executor 7) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,007 | INFO  | [dispatcher-event-loop-1] | Added broadcast_14_piece0 in memory on dn27:22790 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,384 | INFO  | [dispatcher-event-loop-17] | Starting task 31.0 in stage 14.0 (TID 824, dn10, executor 19, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,385 | INFO  | [task-result-getter-0] | Finished task 54.0 in stage 12.0 (TID 693) in 9549 ms on dn10 (executor 19) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,661 | INFO  | [dispatcher-event-loop-9] | Starting task 8.0 in stage 14.0 (TID 825, dn34, executor 6, partition 8, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,662 | INFO  | [task-result-getter-3] | Finished task 52.0 in stage 12.0 (TID 690) in 10337 ms on dn34 (executor 6) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,670 | INFO  | [dispatcher-event-loop-2] | Added broadcast_14_piece0 in memory on dn34:22620 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,723 | INFO  | [dispatcher-event-loop-25] | Starting task 9.0 in stage 14.0 (TID 826, dn08, executor 16, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,723 | INFO  | [task-result-getter-2] | Finished task 81.0 in stage 12.0 (TID 699) in 9461 ms on dn08 (executor 16) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,732 | INFO  | [dispatcher-event-loop-14] | Added broadcast_14_piece0 in memory on dn08:22604 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,736 | INFO  | [dispatcher-event-loop-5] | Starting task 27.0 in stage 14.0 (TID 827, dn34, executor 6, partition 27, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,737 | INFO  | [task-result-getter-1] | Finished task 66.0 in stage 12.0 (TID 691) in 10404 ms on dn34 (executor 6) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,744 | INFO  | [dispatcher-event-loop-27] | Starting task 47.0 in stage 14.0 (TID 828, dn10, executor 19, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,745 | INFO  | [task-result-getter-0] | Finished task 30.0 in stage 14.0 (TID 706) in 7610 ms on dn10 (executor 19) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,756 | INFO  | [dispatcher-event-loop-6] | Starting task 1.0 in stage 14.0 (TID 829, dn36, executor 20, partition 1, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,757 | INFO  | [task-result-getter-3] | Finished task 84.0 in stage 12.0 (TID 689) in 10745 ms on dn36 (executor 20) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,985 | INFO  | [dispatcher-event-loop-57] | Starting task 80.0 in stage 14.0 (TID 830, dn08, executor 16, partition 80, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:33,985 | INFO  | [task-result-getter-2] | Finished task 80.0 in stage 12.0 (TID 698) in 9832 ms on dn08 (executor 16) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:34,831 | INFO  | [dispatcher-event-loop-42] | Starting task 43.0 in stage 14.0 (TID 831, dn37, executor 8, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:34,831 | INFO  | [task-result-getter-1] | Finished task 77.0 in stage 12.0 (TID 700) in 10456 ms on dn37 (executor 8) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,073 | INFO  | [dispatcher-event-loop-29] | Starting task 12.0 in stage 14.0 (TID 832, dn36, executor 20, partition 12, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,073 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 14.0 (TID 704) in 9121 ms on dn36 (executor 20) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,254 | INFO  | [dispatcher-event-loop-49] | Starting task 48.0 in stage 14.0 (TID 833, dn24, executor 9, partition 48, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,255 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 12.0 (TID 703) in 9379 ms on dn24 (executor 9) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,265 | INFO  | [dispatcher-event-loop-47] | Added broadcast_14_piece0 in memory on dn24:22839 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,290 | INFO  | [dispatcher-event-loop-11] | Starting task 69.0 in stage 12.0 (TID 834, dn29, executor 1, partition 69, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,291 | INFO  | [task-result-getter-2] | Finished task 6.0 in stage 12.0 (TID 694) in 11349 ms on dn29 (executor 1) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,291 | INFO  | [dispatcher-event-loop-11] | Starting task 73.0 in stage 12.0 (TID 835, dn29, executor 1, partition 73, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:35,292 | INFO  | [task-result-getter-1] | Finished task 56.0 in stage 12.0 (TID 696) in 11235 ms on dn29 (executor 1) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:36,344 | INFO  | [dispatcher-event-loop-58] | Starting task 10.0 in stage 14.0 (TID 836, dn15, executor 12, partition 10, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:36,345 | INFO  | [task-result-getter-0] | Finished task 83.0 in stage 12.0 (TID 705) in 10330 ms on dn15 (executor 12) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:36,359 | INFO  | [dispatcher-event-loop-64] | Added broadcast_14_piece0 in memory on dn15:22640 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:37,110 | INFO  | [dispatcher-event-loop-59] | Starting task 13.0 in stage 14.0 (TID 837, dn07, executor 14, partition 13, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:37,111 | INFO  | [task-result-getter-3] | Finished task 11.0 in stage 14.0 (TID 797) in 8151 ms on dn07 (executor 14) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:37,218 | INFO  | [task-result-getter-2] | Finished task 44.0 in stage 14.0 (TID 800) in 8010 ms on dn32 (executor 4) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,281 | INFO  | [dispatcher-event-loop-61] | Starting task 33.0 in stage 14.0 (TID 838, dn18, executor 10, partition 33, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,282 | INFO  | [task-result-getter-1] | Finished task 85.0 in stage 12.0 (TID 798) in 9308 ms on dn18 (executor 10) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,673 | INFO  | [dispatcher-event-loop-8] | Starting task 34.0 in stage 12.0 (TID 839, dn32, executor 4, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,676 | INFO  | [dispatcher-event-loop-1] | Starting task 35.0 in stage 12.0 (TID 840, dn18, executor 10, partition 35, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,676 | INFO  | [task-result-getter-0] | Finished task 3.0 in stage 14.0 (TID 804) in 7321 ms on dn18 (executor 10) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,908 | INFO  | [dispatcher-event-loop-17] | Starting task 39.0 in stage 12.0 (TID 841, dn07, executor 14, partition 39, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:38,908 | INFO  | [task-result-getter-3] | Finished task 76.0 in stage 12.0 (TID 796) in 9955 ms on dn07 (executor 14) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,080 | INFO  | [dispatcher-event-loop-9] | Starting task 41.0 in stage 12.0 (TID 842, dn16, executor 15, partition 41, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,080 | INFO  | [task-result-getter-2] | Finished task 22.0 in stage 14.0 (TID 809) in 7498 ms on dn16 (executor 15) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,086 | INFO  | [dispatcher-event-loop-12] | Starting task 49.0 in stage 12.0 (TID 843, dn16, executor 15, partition 49, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,086 | INFO  | [task-result-getter-1] | Finished task 23.0 in stage 14.0 (TID 810) in 7298 ms on dn16 (executor 15) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,169 | INFO  | [dispatcher-event-loop-19] | Starting task 74.0 in stage 12.0 (TID 844, dn22, executor 5, partition 74, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,169 | INFO  | [task-result-getter-0] | Finished task 45.0 in stage 12.0 (TID 801) in 9463 ms on dn22 (executor 5) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,215 | INFO  | [dispatcher-event-loop-18] | Starting task 53.0 in stage 14.0 (TID 845, dn19, executor 11, partition 53, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,215 | INFO  | [task-result-getter-3] | Finished task 87.0 in stage 12.0 (TID 802) in 9361 ms on dn19 (executor 11) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,226 | INFO  | [dispatcher-event-loop-14] | Starting task 75.0 in stage 14.0 (TID 846, dn28, executor 3, partition 75, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,227 | INFO  | [task-result-getter-2] | Finished task 15.0 in stage 14.0 (TID 805) in 7843 ms on dn28 (executor 3) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,403 | INFO  | [dispatcher-event-loop-24] | Starting task 82.0 in stage 14.0 (TID 847, dn20, executor 13, partition 82, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,404 | INFO  | [task-result-getter-1] | Finished task 37.0 in stage 14.0 (TID 808) in 7884 ms on dn20 (executor 13) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,452 | INFO  | [task-result-getter-0] | Finished task 79.0 in stage 14.0 (TID 812) in 7520 ms on dn20 (executor 13) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,675 | INFO  | [dispatcher-event-loop-22] | Starting task 59.0 in stage 14.0 (TID 848, dn19, executor 11, partition 59, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:39,675 | INFO  | [task-result-getter-3] | Finished task 26.0 in stage 14.0 (TID 817) in 7450 ms on dn19 (executor 11) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,050 | INFO  | [dispatcher-event-loop-30] | Starting task 46.0 in stage 14.0 (TID 849, dn15, executor 12, partition 46, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,050 | INFO  | [task-result-getter-2] | Finished task 86.0 in stage 12.0 (TID 799) in 11070 ms on dn15 (executor 12) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,072 | INFO  | [dispatcher-event-loop-26] | Starting task 28.0 in stage 14.0 (TID 850, dn30, executor 2, partition 28, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,072 | INFO  | [task-result-getter-1] | Finished task 16.0 in stage 14.0 (TID 816) in 7920 ms on dn30 (executor 2) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,111 | INFO  | [task-result-getter-0] | Finished task 58.0 in stage 14.0 (TID 819) in 7767 ms on dn32 (executor 4) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,694 | INFO  | [task-result-getter-3] | Finished task 38.0 in stage 14.0 (TID 822) in 8102 ms on dn28 (executor 3) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,839 | INFO  | [dispatcher-event-loop-37] | Starting task 88.0 in stage 14.0 (TID 851, dn24, executor 9, partition 88, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:40,840 | INFO  | [task-result-getter-2] | Finished task 89.0 in stage 12.0 (TID 806) in 9344 ms on dn24 (executor 9) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,087 | INFO  | [dispatcher-event-loop-11] | Starting task 54.0 in stage 14.0 (TID 852, dn10, executor 19, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,087 | INFO  | [task-result-getter-1] | Finished task 31.0 in stage 14.0 (TID 824) in 7703 ms on dn10 (executor 19) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,289 | INFO  | [dispatcher-event-loop-44] | Starting task 81.0 in stage 14.0 (TID 853, dn08, executor 16, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,290 | INFO  | [task-result-getter-0] | Finished task 9.0 in stage 14.0 (TID 826) in 7567 ms on dn08 (executor 16) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,453 | INFO  | [dispatcher-event-loop-33] | Starting task 19.0 in stage 14.0 (TID 854, dn27, executor 7, partition 19, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,454 | INFO  | [task-result-getter-3] | Finished task 14.0 in stage 14.0 (TID 823) in 8459 ms on dn27 (executor 7) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,557 | INFO  | [task-result-getter-2] | Finished task 47.0 in stage 14.0 (TID 828) in 7813 ms on dn10 (executor 19) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,569 | INFO  | [dispatcher-event-loop-52] | Starting task 50.0 in stage 14.0 (TID 855, dn30, executor 2, partition 50, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,570 | INFO  | [task-result-getter-1] | Finished task 51.0 in stage 12.0 (TID 814) in 9518 ms on dn30 (executor 2) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,620 | INFO  | [dispatcher-event-loop-35] | Starting task 55.0 in stage 14.0 (TID 856, dn37, executor 8, partition 55, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,621 | INFO  | [task-result-getter-0] | Finished task 4.0 in stage 14.0 (TID 813) in 9664 ms on dn37 (executor 8) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,761 | INFO  | [dispatcher-event-loop-66] | Starting task 32.0 in stage 14.0 (TID 857, dn34, executor 6, partition 32, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,762 | INFO  | [task-result-getter-3] | Finished task 27.0 in stage 14.0 (TID 827) in 8026 ms on dn34 (executor 6) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,793 | INFO  | [dispatcher-event-loop-50] | Starting task 42.0 in stage 14.0 (TID 858, dn34, executor 6, partition 42, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,794 | INFO  | [task-result-getter-2] | Finished task 8.0 in stage 14.0 (TID 825) in 8133 ms on dn34 (executor 6) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,856 | INFO  | [task-result-getter-1] | Finished task 80.0 in stage 14.0 (TID 830) in 7872 ms on dn08 (executor 16) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,888 | INFO  | [dispatcher-event-loop-59] | Starting task 70.0 in stage 12.0 (TID 859, dn17, executor 18, partition 70, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,889 | INFO  | [task-result-getter-0] | Finished task 65.0 in stage 12.0 (TID 803) in 10571 ms on dn17 (executor 18) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,964 | INFO  | [dispatcher-event-loop-62] | Starting task 5.0 in stage 14.0 (TID 860, dn22, executor 5, partition 5, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,965 | INFO  | [task-result-getter-3] | Finished task 71.0 in stage 12.0 (TID 821) in 9578 ms on dn22 (executor 5) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,979 | INFO  | [dispatcher-event-loop-54] | Starting task 17.0 in stage 14.0 (TID 861, dn17, executor 18, partition 17, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,980 | INFO  | [task-result-getter-2] | Finished task 67.0 in stage 12.0 (TID 807) in 10470 ms on dn17 (executor 18) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,983 | INFO  | [dispatcher-event-loop-60] | Added broadcast_14_piece0 in memory on dn22:22834 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:41,989 | INFO  | [dispatcher-event-loop-0] | Added broadcast_14_piece0 in memory on dn17:22761 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,627 | INFO  | [dispatcher-event-loop-8] | Starting task 52.0 in stage 14.0 (TID 862, dn27, executor 7, partition 52, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,627 | INFO  | [task-result-getter-1] | Finished task 57.0 in stage 12.0 (TID 818) in 10397 ms on dn27 (executor 7) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,634 | INFO  | [dispatcher-event-loop-7] | Starting task 68.0 in stage 14.0 (TID 863, dn36, executor 20, partition 68, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,634 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 14.0 (TID 829) in 8878 ms on dn36 (executor 20) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,661 | INFO  | [dispatcher-event-loop-17] | Starting task 89.0 in stage 14.0 (TID 864, dn24, executor 9, partition 89, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,662 | INFO  | [task-result-getter-3] | Finished task 48.0 in stage 14.0 (TID 833) in 7408 ms on dn24 (executor 9) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,891 | INFO  | [dispatcher-event-loop-16] | Starting task 72.0 in stage 12.0 (TID 865, dn14, executor 17, partition 72, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:42,892 | INFO  | [task-result-getter-2] | Finished task 63.0 in stage 12.0 (TID 820) in 10522 ms on dn14 (executor 17) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,161 | INFO  | [dispatcher-event-loop-25] | Starting task 24.0 in stage 14.0 (TID 866, dn14, executor 17, partition 24, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,162 | INFO  | [task-result-getter-1] | Finished task 62.0 in stage 12.0 (TID 815) in 11096 ms on dn14 (executor 17) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,185 | INFO  | [dispatcher-event-loop-14] | Added broadcast_14_piece0 in memory on dn14:22891 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,802 | INFO  | [dispatcher-event-loop-24] | Starting task 84.0 in stage 14.0 (TID 867, dn36, executor 20, partition 84, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,803 | INFO  | [task-result-getter-0] | Finished task 12.0 in stage 14.0 (TID 832) in 8730 ms on dn36 (executor 20) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,976 | INFO  | [dispatcher-event-loop-22] | Starting task 64.0 in stage 14.0 (TID 868, dn37, executor 8, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:43,976 | INFO  | [task-result-getter-3] | Finished task 43.0 in stage 14.0 (TID 831) in 9145 ms on dn37 (executor 8) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:44,692 | INFO  | [dispatcher-event-loop-57] | Starting task 76.0 in stage 14.0 (TID 869, dn07, executor 14, partition 76, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:44,692 | INFO  | [task-result-getter-2] | Finished task 13.0 in stage 14.0 (TID 837) in 7582 ms on dn07 (executor 14) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:45,792 | INFO  | [dispatcher-event-loop-49] | Starting task 77.0 in stage 14.0 (TID 870, dn15, executor 12, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:45,792 | INFO  | [task-result-getter-1] | Finished task 10.0 in stage 14.0 (TID 836) in 9448 ms on dn15 (executor 12) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,066 | INFO  | [dispatcher-event-loop-4] | Starting task 60.0 in stage 12.0 (TID 871, dn18, executor 10, partition 60, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,067 | INFO  | [task-result-getter-0] | Finished task 33.0 in stage 14.0 (TID 838) in 7786 ms on dn18 (executor 10) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,362 | INFO  | [dispatcher-event-loop-56] | Starting task 61.0 in stage 12.0 (TID 872, dn29, executor 1, partition 61, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,362 | INFO  | [task-result-getter-3] | Finished task 69.0 in stage 12.0 (TID 834) in 11072 ms on dn29 (executor 1) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,560 | INFO  | [dispatcher-event-loop-51] | Starting task 6.0 in stage 14.0 (TID 873, dn29, executor 1, partition 6, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,560 | INFO  | [task-result-getter-2] | Finished task 73.0 in stage 12.0 (TID 835) in 11269 ms on dn29 (executor 1) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:46,569 | INFO  | [dispatcher-event-loop-41] | Added broadcast_14_piece0 in memory on dn29:22705 (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,292 | INFO  | [dispatcher-event-loop-66] | Starting task 86.0 in stage 14.0 (TID 874, dn19, executor 11, partition 86, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,293 | INFO  | [task-result-getter-1] | Finished task 53.0 in stage 14.0 (TID 845) in 8078 ms on dn19 (executor 11) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,376 | INFO  | [task-result-getter-0] | Finished task 75.0 in stage 14.0 (TID 846) in 8150 ms on dn28 (executor 3) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,377 | INFO  | [dispatcher-event-loop-59] | Starting task 87.0 in stage 14.0 (TID 875, dn19, executor 11, partition 87, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,378 | INFO  | [task-result-getter-3] | Finished task 59.0 in stage 14.0 (TID 848) in 7703 ms on dn19 (executor 11) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,560 | INFO  | [task-result-getter-2] | Finished task 82.0 in stage 14.0 (TID 847) in 8157 ms on dn20 (executor 13) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,914 | INFO  | [dispatcher-event-loop-67] | Starting task 51.0 in stage 14.0 (TID 876, dn30, executor 2, partition 51, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:47,914 | INFO  | [task-result-getter-1] | Finished task 28.0 in stage 14.0 (TID 850) in 7842 ms on dn30 (executor 2) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,272 | INFO  | [dispatcher-event-loop-60] | Starting task 78.0 in stage 14.0 (TID 877, dn18, executor 10, partition 78, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,272 | INFO  | [task-result-getter-0] | Finished task 35.0 in stage 12.0 (TID 840) in 9596 ms on dn18 (executor 10) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,341 | INFO  | [task-result-getter-3] | Finished task 54.0 in stage 14.0 (TID 852) in 7254 ms on dn10 (executor 19) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,480 | INFO  | [task-result-getter-2] | Finished task 41.0 in stage 12.0 (TID 842) in 9400 ms on dn16 (executor 15) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,584 | INFO  | [task-result-getter-1] | Finished task 39.0 in stage 12.0 (TID 841) in 9675 ms on dn07 (executor 14) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,612 | INFO  | [task-result-getter-0] | Finished task 88.0 in stage 14.0 (TID 851) in 7773 ms on dn24 (executor 9) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,824 | INFO  | [dispatcher-event-loop-10] | Starting task 18.0 in stage 14.0 (TID 878, dn22, executor 5, partition 18, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,825 | INFO  | [task-result-getter-3] | Finished task 74.0 in stage 12.0 (TID 844) in 9656 ms on dn22 (executor 5) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:48,928 | INFO  | [task-result-getter-2] | Finished task 49.0 in stage 12.0 (TID 843) in 9842 ms on dn16 (executor 15) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,025 | INFO  | [task-result-getter-1] | Finished task 81.0 in stage 14.0 (TID 853) in 7736 ms on dn08 (executor 16) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,383 | INFO  | [dispatcher-event-loop-16] | Starting task 62.0 in stage 14.0 (TID 879, dn30, executor 2, partition 62, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,383 | INFO  | [task-result-getter-0] | Finished task 50.0 in stage 14.0 (TID 855) in 7814 ms on dn30 (executor 2) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,577 | INFO  | [dispatcher-event-loop-2] | Starting task 83.0 in stage 14.0 (TID 880, dn15, executor 12, partition 83, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,577 | INFO  | [task-result-getter-3] | Finished task 46.0 in stage 14.0 (TID 849) in 9528 ms on dn15 (executor 12) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,611 | INFO  | [dispatcher-event-loop-25] | Starting task 45.0 in stage 14.0 (TID 881, dn22, executor 5, partition 45, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:49,611 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 14.0 (TID 860) in 7647 ms on dn22 (executor 5) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,373 | INFO  | [dispatcher-event-loop-14] | Starting task 66.0 in stage 14.0 (TID 882, dn34, executor 6, partition 66, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,374 | INFO  | [task-result-getter-1] | Finished task 32.0 in stage 14.0 (TID 857) in 8613 ms on dn34 (executor 6) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,395 | INFO  | [task-result-getter-0] | Finished task 89.0 in stage 14.0 (TID 864) in 7734 ms on dn24 (executor 9) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,532 | INFO  | [dispatcher-event-loop-30] | Starting task 71.0 in stage 14.0 (TID 883, dn34, executor 6, partition 71, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,532 | INFO  | [task-result-getter-3] | Finished task 42.0 in stage 14.0 (TID 858) in 8739 ms on dn34 (executor 6) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,596 | INFO  | [dispatcher-event-loop-26] | Starting task 29.0 in stage 14.0 (TID 884, dn17, executor 18, partition 29, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,597 | INFO  | [task-result-getter-2] | Finished task 17.0 in stage 14.0 (TID 861) in 8618 ms on dn17 (executor 18) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,623 | INFO  | [dispatcher-event-loop-42] | Starting task 57.0 in stage 14.0 (TID 885, dn27, executor 7, partition 57, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,624 | INFO  | [task-result-getter-1] | Finished task 19.0 in stage 14.0 (TID 854) in 9171 ms on dn27 (executor 7) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,889 | INFO  | [task-result-getter-0] | Finished task 55.0 in stage 14.0 (TID 856) in 9269 ms on dn37 (executor 8) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:50,942 | INFO  | [task-result-getter-3] | Finished task 34.0 in stage 12.0 (TID 839) in 12270 ms on dn32 (executor 4) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:51,573 | INFO  | [task-result-getter-2] | Finished task 68.0 in stage 14.0 (TID 863) in 8940 ms on dn36 (executor 20) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:51,715 | INFO  | [task-result-getter-1] | Finished task 52.0 in stage 14.0 (TID 862) in 9088 ms on dn27 (executor 7) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:52,091 | INFO  | [task-result-getter-0] | Finished task 76.0 in stage 14.0 (TID 869) in 7399 ms on dn07 (executor 14) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:52,437 | INFO  | [dispatcher-event-loop-48] | Starting task 65.0 in stage 14.0 (TID 886, dn17, executor 18, partition 65, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:52,437 | INFO  | [task-result-getter-3] | Finished task 70.0 in stage 12.0 (TID 859) in 10549 ms on dn17 (executor 18) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:52,543 | INFO  | [dispatcher-event-loop-41] | Starting task 25.0 in stage 14.0 (TID 887, dn14, executor 17, partition 25, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:52,543 | INFO  | [task-result-getter-2] | Finished task 24.0 in stage 14.0 (TID 866) in 9382 ms on dn14 (executor 17) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:52,814 | INFO  | [task-result-getter-1] | Finished task 84.0 in stage 14.0 (TID 867) in 9012 ms on dn36 (executor 20) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:53,511 | INFO  | [task-result-getter-0] | Finished task 64.0 in stage 14.0 (TID 868) in 9536 ms on dn37 (executor 8) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:54,319 | INFO  | [dispatcher-event-loop-53] | Starting task 63.0 in stage 14.0 (TID 888, dn14, executor 17, partition 63, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:54,319 | INFO  | [task-result-getter-3] | Finished task 72.0 in stage 12.0 (TID 865) in 11428 ms on dn14 (executor 17) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:54,875 | INFO  | [task-result-getter-2] | Finished task 77.0 in stage 14.0 (TID 870) in 9084 ms on dn15 (executor 12) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:55,263 | INFO  | [task-result-getter-1] | Finished task 51.0 in stage 14.0 (TID 876) in 7350 ms on dn30 (executor 2) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:55,338 | INFO  | [task-result-getter-0] | Finished task 87.0 in stage 14.0 (TID 875) in 7961 ms on dn19 (executor 11) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:55,419 | INFO  | [task-result-getter-3] | Finished task 86.0 in stage 14.0 (TID 874) in 8127 ms on dn19 (executor 11) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:55,533 | INFO  | [dispatcher-event-loop-61] | Starting task 85.0 in stage 14.0 (TID 889, dn18, executor 10, partition 85, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:55,534 | INFO  | [task-result-getter-2] | Finished task 60.0 in stage 12.0 (TID 871) in 9468 ms on dn18 (executor 10) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:55,685 | INFO  | [task-result-getter-1] | Finished task 78.0 in stage 14.0 (TID 877) in 7414 ms on dn18 (executor 10) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:56,138 | INFO  | [dispatcher-event-loop-9] | Starting task 56.0 in stage 14.0 (TID 890, dn29, executor 1, partition 56, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:56,139 | INFO  | [task-result-getter-0] | Finished task 6.0 in stage 14.0 (TID 873) in 9580 ms on dn29 (executor 1) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:56,478 | INFO  | [dispatcher-event-loop-19] | Starting task 74.0 in stage 14.0 (TID 891, dn22, executor 5, partition 74, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:56,479 | INFO  | [task-result-getter-3] | Finished task 18.0 in stage 14.0 (TID 878) in 7655 ms on dn22 (executor 5) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:56,699 | INFO  | [task-result-getter-2] | Finished task 62.0 in stage 14.0 (TID 879) in 7317 ms on dn30 (executor 2) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,245 | INFO  | [dispatcher-event-loop-24] | Starting task 69.0 in stage 14.0 (TID 892, dn29, executor 1, partition 69, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,245 | INFO  | [task-result-getter-1] | Finished task 61.0 in stage 12.0 (TID 872) in 10884 ms on dn29 (executor 1) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,246 | INFO  | [task-result-getter-1] | Removed TaskSet 12.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,247 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 60.058 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,248 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,248 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 14) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,248 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ShuffleMapStage 15, ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,248 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,251 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,274 | INFO  | [dag-scheduler-event-loop] | Block broadcast_16 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,278 | INFO  | [dag-scheduler-event-loop] | Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,278 | INFO  | [dispatcher-event-loop-20] | Added broadcast_16_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,279 | INFO  | [dag-scheduler-event-loop] | Created broadcast 16 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,280 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,280 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,282 | INFO  | [dispatcher-event-loop-6] | Starting task 0.0 in stage 13.0 (TID 893, dn24, executor 9, partition 0, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,282 | INFO  | [dispatcher-event-loop-6] | Starting task 1.0 in stage 13.0 (TID 894, dn32, executor 4, partition 1, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,283 | INFO  | [dispatcher-event-loop-6] | Starting task 2.0 in stage 13.0 (TID 895, dn27, executor 7, partition 2, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,283 | INFO  | [dispatcher-event-loop-6] | Starting task 3.0 in stage 13.0 (TID 896, dn16, executor 15, partition 3, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,283 | INFO  | [dispatcher-event-loop-6] | Starting task 4.0 in stage 13.0 (TID 897, dn20, executor 13, partition 4, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,283 | INFO  | [dispatcher-event-loop-6] | Starting task 5.0 in stage 13.0 (TID 898, dn28, executor 3, partition 5, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,283 | INFO  | [dispatcher-event-loop-6] | Starting task 6.0 in stage 13.0 (TID 899, dn08, executor 16, partition 6, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,284 | INFO  | [dispatcher-event-loop-6] | Starting task 7.0 in stage 13.0 (TID 900, dn19, executor 11, partition 7, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,284 | INFO  | [dispatcher-event-loop-6] | Starting task 8.0 in stage 13.0 (TID 901, dn36, executor 20, partition 8, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,284 | INFO  | [dispatcher-event-loop-6] | Starting task 9.0 in stage 13.0 (TID 902, dn07, executor 14, partition 9, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,284 | INFO  | [dispatcher-event-loop-6] | Starting task 10.0 in stage 13.0 (TID 903, dn37, executor 8, partition 10, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,284 | INFO  | [dispatcher-event-loop-6] | Starting task 11.0 in stage 13.0 (TID 904, dn10, executor 19, partition 11, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,284 | INFO  | [dispatcher-event-loop-6] | Starting task 12.0 in stage 13.0 (TID 905, dn15, executor 12, partition 12, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 13.0 in stage 13.0 (TID 906, dn30, executor 2, partition 13, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 14.0 in stage 13.0 (TID 907, dn18, executor 10, partition 14, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 15.0 in stage 13.0 (TID 908, dn24, executor 9, partition 15, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 16.0 in stage 13.0 (TID 909, dn32, executor 4, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 17.0 in stage 13.0 (TID 910, dn16, executor 15, partition 17, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 18.0 in stage 13.0 (TID 911, dn20, executor 13, partition 18, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 19.0 in stage 13.0 (TID 912, dn28, executor 3, partition 19, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,285 | INFO  | [dispatcher-event-loop-6] | Starting task 20.0 in stage 13.0 (TID 913, dn08, executor 16, partition 20, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,286 | INFO  | [dispatcher-event-loop-6] | Starting task 21.0 in stage 13.0 (TID 914, dn19, executor 11, partition 21, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,286 | INFO  | [dispatcher-event-loop-6] | Starting task 22.0 in stage 13.0 (TID 915, dn36, executor 20, partition 22, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,286 | INFO  | [dispatcher-event-loop-6] | Starting task 23.0 in stage 13.0 (TID 916, dn07, executor 14, partition 23, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,286 | INFO  | [dispatcher-event-loop-6] | Starting task 24.0 in stage 13.0 (TID 917, dn37, executor 8, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,286 | INFO  | [dispatcher-event-loop-6] | Starting task 25.0 in stage 13.0 (TID 918, dn10, executor 19, partition 25, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,286 | INFO  | [dispatcher-event-loop-6] | Starting task 26.0 in stage 13.0 (TID 919, dn30, executor 2, partition 26, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,301 | INFO  | [dispatcher-event-loop-50] | Added broadcast_16_piece0 in memory on dn32:22787 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,302 | INFO  | [dispatcher-event-loop-53] | Added broadcast_16_piece0 in memory on dn10:22719 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,303 | INFO  | [dispatcher-event-loop-62] | Added broadcast_16_piece0 in memory on dn37:22861 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,304 | INFO  | [dispatcher-event-loop-54] | Added broadcast_16_piece0 in memory on dn19:22830 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,304 | INFO  | [dispatcher-event-loop-69] | Added broadcast_16_piece0 in memory on dn07:22897 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,308 | INFO  | [dispatcher-event-loop-60] | Added broadcast_16_piece0 in memory on dn16:22668 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,309 | INFO  | [dispatcher-event-loop-0] | Added broadcast_16_piece0 in memory on dn30:22608 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,310 | INFO  | [dispatcher-event-loop-61] | Added broadcast_16_piece0 in memory on dn15:22640 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,310 | INFO  | [dispatcher-event-loop-61] | Added broadcast_16_piece0 in memory on dn18:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,310 | INFO  | [dispatcher-event-loop-61] | Added broadcast_16_piece0 in memory on dn28:22784 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,311 | INFO  | [dispatcher-event-loop-71] | Added broadcast_16_piece0 in memory on dn24:22839 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,311 | INFO  | [dispatcher-event-loop-71] | Added broadcast_16_piece0 in memory on dn08:22604 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,312 | INFO  | [dispatcher-event-loop-7] | Added broadcast_16_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,313 | INFO  | [dispatcher-event-loop-10] | Added broadcast_16_piece0 in memory on dn20:22825 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,316 | INFO  | [dispatcher-event-loop-17] | Asked to send map output locations for shuffle 3 to *.*.132.15:57922 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,321 | INFO  | [dispatcher-event-loop-15] | Asked to send map output locations for shuffle 3 to *.*.132.40:54846 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,321 | INFO  | [dispatcher-event-loop-15] | Asked to send map output locations for shuffle 3 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,321 | INFO  | [dispatcher-event-loop-15] | Added broadcast_16_piece0 in memory on dn27:22790 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,322 | INFO  | [dispatcher-event-loop-12] | Asked to send map output locations for shuffle 3 to *.*.132.21:46253 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,323 | INFO  | [dispatcher-event-loop-2] | Asked to send map output locations for shuffle 3 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,325 | INFO  | [dispatcher-event-loop-19] | Asked to send map output locations for shuffle 3 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,326 | INFO  | [dispatcher-event-loop-25] | Asked to send map output locations for shuffle 3 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,327 | INFO  | [dispatcher-event-loop-18] | Asked to send map output locations for shuffle 4 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,328 | INFO  | [dispatcher-event-loop-31] | Asked to send map output locations for shuffle 3 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,328 | INFO  | [dispatcher-event-loop-14] | Asked to send map output locations for shuffle 4 to *.*.132.15:57922 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,331 | INFO  | [dispatcher-event-loop-24] | Asked to send map output locations for shuffle 4 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,331 | INFO  | [dispatcher-event-loop-5] | Asked to send map output locations for shuffle 3 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,332 | INFO  | [dispatcher-event-loop-27] | Asked to send map output locations for shuffle 4 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,332 | INFO  | [dispatcher-event-loop-27] | Asked to send map output locations for shuffle 3 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,332 | INFO  | [dispatcher-event-loop-27] | Asked to send map output locations for shuffle 4 to *.*.132.40:54846 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,333 | INFO  | [dispatcher-event-loop-22] | Asked to send map output locations for shuffle 4 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,340 | INFO  | [dispatcher-event-loop-32] | Asked to send map output locations for shuffle 4 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,341 | INFO  | [dispatcher-event-loop-57] | Asked to send map output locations for shuffle 4 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,341 | INFO  | [dispatcher-event-loop-30] | Asked to send map output locations for shuffle 3 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,344 | INFO  | [dispatcher-event-loop-42] | Asked to send map output locations for shuffle 3 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,345 | INFO  | [dispatcher-event-loop-39] | Starting task 27.0 in stage 13.0 (TID 920, dn18, executor 10, partition 27, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,346 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,346 | INFO  | [task-result-getter-0] | Finished task 14.0 in stage 13.0 (TID 907) in 61 ms on dn18 (executor 10) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,346 | INFO  | [dispatcher-event-loop-23] | Asked to send map output locations for shuffle 4 to *.*.132.21:46253 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,346 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 3 to *.*.132.38:54888 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,347 | INFO  | [dispatcher-event-loop-40] | Asked to send map output locations for shuffle 4 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,351 | INFO  | [dispatcher-event-loop-38] | Asked to send map output locations for shuffle 4 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,352 | INFO  | [dispatcher-event-loop-49] | Asked to send map output locations for shuffle 4 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,355 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,357 | INFO  | [dispatcher-event-loop-34] | Asked to send map output locations for shuffle 3 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,359 | INFO  | [dispatcher-event-loop-47] | Asked to send map output locations for shuffle 4 to *.*.132.38:54888 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,378 | INFO  | [dispatcher-event-loop-56] | Asked to send map output locations for shuffle 4 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,386 | INFO  | [dispatcher-event-loop-44] | Starting task 28.0 in stage 13.0 (TID 921, dn24, executor 9, partition 28, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,387 | INFO  | [task-result-getter-3] | Finished task 15.0 in stage 13.0 (TID 908) in 102 ms on dn24 (executor 9) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,397 | INFO  | [dispatcher-event-loop-33] | Starting task 29.0 in stage 13.0 (TID 922, dn22, executor 5, partition 29, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,398 | INFO  | [task-result-getter-2] | Finished task 45.0 in stage 14.0 (TID 881) in 7788 ms on dn22 (executor 5) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,408 | INFO  | [dispatcher-event-loop-52] | Added broadcast_16_piece0 in memory on dn22:22834 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,414 | INFO  | [dispatcher-event-loop-41] | Starting task 30.0 in stage 13.0 (TID 923, dn24, executor 9, partition 30, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,415 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 13.0 (TID 893) in 134 ms on dn24 (executor 9) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,416 | INFO  | [dispatcher-event-loop-35] | Starting task 31.0 in stage 13.0 (TID 924, dn30, executor 2, partition 31, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,416 | INFO  | [task-result-getter-0] | Finished task 13.0 in stage 13.0 (TID 906) in 131 ms on dn30 (executor 2) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,422 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 3 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,441 | INFO  | [dispatcher-event-loop-64] | Asked to send map output locations for shuffle 4 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,444 | INFO  | [dispatcher-event-loop-46] | Starting task 32.0 in stage 13.0 (TID 925, dn30, executor 2, partition 32, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,445 | INFO  | [task-result-getter-3] | Finished task 31.0 in stage 13.0 (TID 924) in 29 ms on dn30 (executor 2) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,449 | INFO  | [dispatcher-event-loop-70] | Starting task 33.0 in stage 13.0 (TID 926, dn32, executor 4, partition 33, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,449 | INFO  | [task-result-getter-2] | Finished task 1.0 in stage 13.0 (TID 894) in 167 ms on dn32 (executor 4) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,453 | INFO  | [dispatcher-event-loop-53] | Starting task 34.0 in stage 13.0 (TID 927, dn10, executor 19, partition 34, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,454 | INFO  | [task-result-getter-1] | Finished task 11.0 in stage 13.0 (TID 904) in 170 ms on dn10 (executor 19) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,461 | INFO  | [dispatcher-event-loop-55] | Starting task 35.0 in stage 13.0 (TID 928, dn16, executor 15, partition 35, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,462 | INFO  | [task-result-getter-0] | Finished task 17.0 in stage 13.0 (TID 910) in 177 ms on dn16 (executor 15) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,470 | INFO  | [dispatcher-event-loop-62] | Starting task 36.0 in stage 13.0 (TID 929, dn08, executor 16, partition 36, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,471 | INFO  | [task-result-getter-3] | Finished task 6.0 in stage 13.0 (TID 899) in 188 ms on dn08 (executor 16) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,471 | INFO  | [dispatcher-event-loop-67] | Starting task 37.0 in stage 13.0 (TID 930, dn18, executor 10, partition 37, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,472 | INFO  | [task-result-getter-2] | Finished task 27.0 in stage 13.0 (TID 920) in 127 ms on dn18 (executor 10) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,473 | INFO  | [dispatcher-event-loop-54] | Starting task 38.0 in stage 13.0 (TID 931, dn20, executor 13, partition 38, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,474 | INFO  | [task-result-getter-1] | Finished task 4.0 in stage 13.0 (TID 897) in 190 ms on dn20 (executor 13) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,481 | INFO  | [dispatcher-event-loop-0] | Starting task 39.0 in stage 13.0 (TID 932, dn36, executor 20, partition 39, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,482 | INFO  | [task-result-getter-0] | Finished task 22.0 in stage 13.0 (TID 915) in 196 ms on dn36 (executor 20) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,485 | INFO  | [dispatcher-event-loop-68] | Starting task 40.0 in stage 13.0 (TID 933, dn18, executor 10, partition 40, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,485 | INFO  | [task-result-getter-3] | Finished task 37.0 in stage 13.0 (TID 930) in 14 ms on dn18 (executor 10) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,500 | INFO  | [dispatcher-event-loop-8] | Starting task 41.0 in stage 13.0 (TID 934, dn20, executor 13, partition 41, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,501 | INFO  | [task-result-getter-2] | Finished task 18.0 in stage 13.0 (TID 911) in 216 ms on dn20 (executor 13) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,502 | INFO  | [dispatcher-event-loop-71] | Starting task 42.0 in stage 13.0 (TID 935, dn30, executor 2, partition 42, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,503 | INFO  | [task-result-getter-1] | Finished task 32.0 in stage 13.0 (TID 925) in 59 ms on dn30 (executor 2) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,523 | INFO  | [dispatcher-event-loop-10] | Starting task 43.0 in stage 13.0 (TID 936, dn07, executor 14, partition 43, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,524 | INFO  | [task-result-getter-0] | Finished task 9.0 in stage 13.0 (TID 902) in 240 ms on dn07 (executor 14) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,525 | INFO  | [dispatcher-event-loop-17] | Starting task 44.0 in stage 13.0 (TID 937, dn10, executor 19, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,525 | INFO  | [task-result-getter-3] | Finished task 25.0 in stage 13.0 (TID 918) in 239 ms on dn10 (executor 19) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,575 | INFO  | [dispatcher-event-loop-16] | Starting task 45.0 in stage 13.0 (TID 938, dn19, executor 11, partition 45, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,576 | INFO  | [task-result-getter-2] | Finished task 21.0 in stage 13.0 (TID 914) in 289 ms on dn19 (executor 11) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,585 | INFO  | [dispatcher-event-loop-2] | Starting task 46.0 in stage 13.0 (TID 939, dn30, executor 2, partition 46, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,586 | INFO  | [task-result-getter-1] | Finished task 42.0 in stage 13.0 (TID 935) in 84 ms on dn30 (executor 2) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,597 | INFO  | [dispatcher-event-loop-25] | Starting task 47.0 in stage 13.0 (TID 940, dn20, executor 13, partition 47, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,598 | INFO  | [task-result-getter-0] | Finished task 41.0 in stage 13.0 (TID 934) in 98 ms on dn20 (executor 13) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,598 | INFO  | [dispatcher-event-loop-25] | Starting task 48.0 in stage 13.0 (TID 941, dn16, executor 15, partition 48, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,598 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 13.0 (TID 896) in 315 ms on dn16 (executor 15) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,605 | INFO  | [dispatcher-event-loop-24] | Starting task 49.0 in stage 13.0 (TID 942, dn28, executor 3, partition 49, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,605 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 13.0 (TID 898) in 322 ms on dn28 (executor 3) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,616 | INFO  | [dispatcher-event-loop-27] | Starting task 50.0 in stage 13.0 (TID 943, dn36, executor 20, partition 50, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,616 | INFO  | [task-result-getter-1] | Finished task 39.0 in stage 13.0 (TID 932) in 135 ms on dn36 (executor 20) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,620 | INFO  | [dispatcher-event-loop-6] | Starting task 51.0 in stage 13.0 (TID 944, dn18, executor 10, partition 51, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,620 | INFO  | [task-result-getter-0] | Finished task 40.0 in stage 13.0 (TID 933) in 136 ms on dn18 (executor 10) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,638 | INFO  | [dispatcher-event-loop-26] | Starting task 52.0 in stage 13.0 (TID 945, dn22, executor 5, partition 52, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,639 | INFO  | [task-result-getter-3] | Finished task 29.0 in stage 13.0 (TID 922) in 242 ms on dn22 (executor 5) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,640 | INFO  | [dispatcher-event-loop-32] | Starting task 53.0 in stage 13.0 (TID 946, dn08, executor 16, partition 53, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,641 | INFO  | [task-result-getter-2] | Finished task 36.0 in stage 13.0 (TID 929) in 171 ms on dn08 (executor 16) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,648 | INFO  | [dispatcher-event-loop-57] | Starting task 54.0 in stage 13.0 (TID 947, dn20, executor 13, partition 54, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,648 | INFO  | [task-result-getter-1] | Finished task 38.0 in stage 13.0 (TID 931) in 175 ms on dn20 (executor 13) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,667 | INFO  | [dispatcher-event-loop-13] | Starting task 55.0 in stage 13.0 (TID 948, dn22, executor 5, partition 55, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,668 | INFO  | [task-result-getter-0] | Finished task 52.0 in stage 13.0 (TID 945) in 29 ms on dn22 (executor 5) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,681 | INFO  | [dispatcher-event-loop-29] | Starting task 56.0 in stage 13.0 (TID 949, dn18, executor 10, partition 56, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,682 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 13.0 (TID 944) in 62 ms on dn18 (executor 10) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,695 | INFO  | [dispatcher-event-loop-40] | Starting task 57.0 in stage 13.0 (TID 950, dn08, executor 16, partition 57, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,695 | INFO  | [task-result-getter-2] | Finished task 53.0 in stage 13.0 (TID 946) in 55 ms on dn08 (executor 16) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,701 | INFO  | [dispatcher-event-loop-49] | Starting task 58.0 in stage 13.0 (TID 951, dn16, executor 15, partition 58, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,701 | INFO  | [task-result-getter-1] | Finished task 48.0 in stage 13.0 (TID 941) in 103 ms on dn16 (executor 15) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,703 | INFO  | [dispatcher-event-loop-37] | Starting task 59.0 in stage 13.0 (TID 952, dn19, executor 11, partition 59, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,704 | INFO  | [task-result-getter-0] | Finished task 45.0 in stage 13.0 (TID 938) in 129 ms on dn19 (executor 11) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,717 | INFO  | [dispatcher-event-loop-4] | Starting task 60.0 in stage 13.0 (TID 953, dn30, executor 2, partition 60, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,718 | INFO  | [task-result-getter-3] | Finished task 46.0 in stage 13.0 (TID 939) in 133 ms on dn30 (executor 2) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,727 | INFO  | [dispatcher-event-loop-56] | Starting task 61.0 in stage 13.0 (TID 954, dn20, executor 13, partition 61, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,727 | INFO  | [task-result-getter-2] | Finished task 54.0 in stage 13.0 (TID 947) in 80 ms on dn20 (executor 13) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,816 | INFO  | [dispatcher-event-loop-43] | Starting task 62.0 in stage 13.0 (TID 955, dn08, executor 16, partition 62, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,817 | INFO  | [task-result-getter-1] | Finished task 57.0 in stage 13.0 (TID 950) in 122 ms on dn08 (executor 16) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,834 | INFO  | [dispatcher-event-loop-51] | Starting task 63.0 in stage 13.0 (TID 956, dn20, executor 13, partition 63, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,835 | INFO  | [task-result-getter-0] | Finished task 61.0 in stage 13.0 (TID 954) in 109 ms on dn20 (executor 13) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,840 | INFO  | [dispatcher-event-loop-52] | Starting task 64.0 in stage 13.0 (TID 957, dn08, executor 16, partition 64, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,840 | INFO  | [task-result-getter-3] | Finished task 62.0 in stage 13.0 (TID 955) in 24 ms on dn08 (executor 16) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,841 | INFO  | [dispatcher-event-loop-52] | Starting task 65.0 in stage 13.0 (TID 958, dn20, executor 13, partition 65, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,841 | INFO  | [task-result-getter-2] | Finished task 63.0 in stage 13.0 (TID 956) in 7 ms on dn20 (executor 13) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,849 | INFO  | [dispatcher-event-loop-66] | Starting task 66.0 in stage 13.0 (TID 959, dn30, executor 2, partition 66, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,850 | INFO  | [task-result-getter-1] | Finished task 60.0 in stage 13.0 (TID 953) in 133 ms on dn30 (executor 2) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,853 | INFO  | [dispatcher-event-loop-64] | Starting task 67.0 in stage 13.0 (TID 960, dn30, executor 2, partition 67, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,853 | INFO  | [task-result-getter-0] | Finished task 26.0 in stage 13.0 (TID 919) in 567 ms on dn30 (executor 2) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,855 | INFO  | [dispatcher-event-loop-46] | Starting task 68.0 in stage 13.0 (TID 961, dn18, executor 10, partition 68, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,855 | INFO  | [task-result-getter-3] | Finished task 56.0 in stage 13.0 (TID 949) in 174 ms on dn18 (executor 10) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,856 | INFO  | [dispatcher-event-loop-46] | Starting task 69.0 in stage 13.0 (TID 962, dn19, executor 11, partition 69, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,856 | INFO  | [task-result-getter-2] | Finished task 59.0 in stage 13.0 (TID 952) in 153 ms on dn19 (executor 11) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,857 | INFO  | [dispatcher-event-loop-50] | Starting task 70.0 in stage 13.0 (TID 963, dn08, executor 16, partition 70, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,857 | INFO  | [task-result-getter-1] | Finished task 64.0 in stage 13.0 (TID 957) in 17 ms on dn08 (executor 16) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,873 | INFO  | [dispatcher-event-loop-45] | Starting task 71.0 in stage 13.0 (TID 964, dn08, executor 16, partition 71, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,874 | INFO  | [task-result-getter-0] | Finished task 20.0 in stage 13.0 (TID 913) in 589 ms on dn08 (executor 16) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,894 | INFO  | [dispatcher-event-loop-67] | Starting task 72.0 in stage 13.0 (TID 965, dn36, executor 20, partition 72, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,895 | INFO  | [task-result-getter-3] | Finished task 8.0 in stage 13.0 (TID 901) in 611 ms on dn36 (executor 20) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,896 | INFO  | [dispatcher-event-loop-69] | Starting task 73.0 in stage 13.0 (TID 966, dn08, executor 16, partition 73, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,897 | INFO  | [task-result-getter-2] | Finished task 71.0 in stage 13.0 (TID 964) in 24 ms on dn08 (executor 16) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,929 | INFO  | [dispatcher-event-loop-60] | Starting task 74.0 in stage 13.0 (TID 967, dn30, executor 2, partition 74, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,929 | INFO  | [task-result-getter-1] | Finished task 67.0 in stage 13.0 (TID 960) in 77 ms on dn30 (executor 2) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,935 | INFO  | [dispatcher-event-loop-3] | Starting task 75.0 in stage 13.0 (TID 968, dn18, executor 10, partition 75, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,935 | INFO  | [task-result-getter-0] | Finished task 68.0 in stage 13.0 (TID 961) in 80 ms on dn18 (executor 10) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,942 | INFO  | [dispatcher-event-loop-61] | Starting task 76.0 in stage 13.0 (TID 969, dn30, executor 2, partition 76, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,943 | INFO  | [task-result-getter-3] | Finished task 66.0 in stage 13.0 (TID 959) in 94 ms on dn30 (executor 2) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,947 | INFO  | [dispatcher-event-loop-1] | Starting task 77.0 in stage 13.0 (TID 970, dn36, executor 20, partition 77, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,947 | INFO  | [task-result-getter-2] | Finished task 50.0 in stage 13.0 (TID 943) in 331 ms on dn36 (executor 20) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,963 | INFO  | [dispatcher-event-loop-7] | Starting task 78.0 in stage 13.0 (TID 971, dn19, executor 11, partition 78, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,963 | INFO  | [task-result-getter-1] | Finished task 69.0 in stage 13.0 (TID 962) in 108 ms on dn19 (executor 11) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,969 | INFO  | [dispatcher-event-loop-17] | Starting task 79.0 in stage 13.0 (TID 972, dn36, executor 20, partition 79, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,970 | INFO  | [task-result-getter-0] | Finished task 77.0 in stage 13.0 (TID 970) in 24 ms on dn36 (executor 20) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,986 | INFO  | [dispatcher-event-loop-9] | Starting task 80.0 in stage 13.0 (TID 973, dn15, executor 12, partition 80, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,986 | INFO  | [task-result-getter-3] | Finished task 12.0 in stage 13.0 (TID 905) in 702 ms on dn15 (executor 12) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,988 | INFO  | [dispatcher-event-loop-16] | Starting task 81.0 in stage 13.0 (TID 974, dn30, executor 2, partition 81, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:57,988 | INFO  | [task-result-getter-2] | Finished task 74.0 in stage 13.0 (TID 967) in 59 ms on dn30 (executor 2) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,042 | INFO  | [dispatcher-event-loop-25] | Starting task 82.0 in stage 13.0 (TID 975, dn36, executor 20, partition 82, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,043 | INFO  | [task-result-getter-1] | Finished task 79.0 in stage 13.0 (TID 972) in 74 ms on dn36 (executor 20) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,091 | INFO  | [dispatcher-event-loop-14] | Starting task 83.0 in stage 13.0 (TID 976, dn30, executor 2, partition 83, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,092 | INFO  | [task-result-getter-0] | Finished task 76.0 in stage 13.0 (TID 969) in 150 ms on dn30 (executor 2) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,102 | INFO  | [dispatcher-event-loop-5] | Starting task 84.0 in stage 13.0 (TID 977, dn19, executor 11, partition 84, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,103 | INFO  | [task-result-getter-3] | Finished task 78.0 in stage 13.0 (TID 971) in 140 ms on dn19 (executor 11) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,159 | INFO  | [dispatcher-event-loop-20] | Starting task 85.0 in stage 13.0 (TID 978, dn30, executor 2, partition 85, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,160 | INFO  | [task-result-getter-2] | Finished task 81.0 in stage 13.0 (TID 974) in 173 ms on dn30 (executor 2) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,160 | INFO  | [dispatcher-event-loop-6] | Starting task 86.0 in stage 13.0 (TID 979, dn15, executor 12, partition 86, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,161 | INFO  | [task-result-getter-1] | Finished task 80.0 in stage 13.0 (TID 973) in 175 ms on dn15 (executor 12) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,191 | INFO  | [dispatcher-event-loop-32] | Starting task 87.0 in stage 13.0 (TID 980, dn15, executor 12, partition 87, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,192 | INFO  | [task-result-getter-0] | Finished task 83.0 in stage 14.0 (TID 880) in 8616 ms on dn15 (executor 12) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,237 | INFO  | [dispatcher-event-loop-57] | Starting task 88.0 in stage 13.0 (TID 981, dn15, executor 12, partition 88, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,237 | INFO  | [task-result-getter-3] | Finished task 86.0 in stage 13.0 (TID 979) in 77 ms on dn15 (executor 12) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,267 | INFO  | [dispatcher-event-loop-42] | Starting task 89.0 in stage 13.0 (TID 982, dn15, executor 12, partition 89, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,267 | INFO  | [task-result-getter-2] | Finished task 87.0 in stage 13.0 (TID 980) in 76 ms on dn15 (executor 12) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,306 | INFO  | [task-result-getter-1] | Finished task 89.0 in stage 13.0 (TID 982) in 40 ms on dn15 (executor 12) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,349 | INFO  | [task-result-getter-0] | Finished task 70.0 in stage 13.0 (TID 963) in 492 ms on dn08 (executor 16) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,399 | INFO  | [task-result-getter-3] | Finished task 65.0 in stage 13.0 (TID 958) in 558 ms on dn20 (executor 13) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,431 | INFO  | [task-result-getter-2] | Finished task 66.0 in stage 14.0 (TID 882) in 8058 ms on dn34 (executor 6) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,453 | INFO  | [task-result-getter-1] | Finished task 88.0 in stage 13.0 (TID 981) in 217 ms on dn15 (executor 12) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,485 | INFO  | [task-result-getter-0] | Finished task 71.0 in stage 14.0 (TID 883) in 7954 ms on dn34 (executor 6) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,531 | INFO  | [task-result-getter-3] | Finished task 55.0 in stage 13.0 (TID 948) in 864 ms on dn22 (executor 5) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,552 | INFO  | [task-result-getter-2] | Finished task 75.0 in stage 13.0 (TID 968) in 618 ms on dn18 (executor 10) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,623 | INFO  | [dispatcher-event-loop-4] | Starting task 67.0 in stage 14.0 (TID 983, dn17, executor 18, partition 67, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,624 | INFO  | [task-result-getter-1] | Finished task 29.0 in stage 14.0 (TID 884) in 8028 ms on dn17 (executor 18) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,635 | INFO  | [task-result-getter-0] | Finished task 84.0 in stage 13.0 (TID 977) in 533 ms on dn19 (executor 11) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,714 | INFO  | [task-result-getter-3] | Finished task 28.0 in stage 13.0 (TID 921) in 1328 ms on dn24 (executor 9) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,831 | INFO  | [task-result-getter-2] | Finished task 33.0 in stage 13.0 (TID 926) in 1383 ms on dn32 (executor 4) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,881 | INFO  | [task-result-getter-1] | Finished task 30.0 in stage 13.0 (TID 923) in 1467 ms on dn24 (executor 9) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:58,995 | INFO  | [task-result-getter-0] | Finished task 35.0 in stage 13.0 (TID 928) in 1534 ms on dn16 (executor 15) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:59,057 | INFO  | [task-result-getter-3] | Finished task 83.0 in stage 13.0 (TID 976) in 966 ms on dn30 (executor 2) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:59,074 | INFO  | [task-result-getter-2] | Finished task 49.0 in stage 13.0 (TID 942) in 1469 ms on dn28 (executor 3) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:59,354 | INFO  | [task-result-getter-1] | Finished task 23.0 in stage 13.0 (TID 916) in 2068 ms on dn07 (executor 14) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:59,584 | INFO  | [task-result-getter-0] | Finished task 57.0 in stage 14.0 (TID 885) in 8961 ms on dn27 (executor 7) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:10:59,703 | INFO  | [task-result-getter-3] | Finished task 34.0 in stage 13.0 (TID 927) in 2250 ms on dn10 (executor 19) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:00,251 | INFO  | [task-result-getter-2] | Finished task 85.0 in stage 13.0 (TID 978) in 2092 ms on dn30 (executor 2) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:00,350 | INFO  | [task-result-getter-1] | Finished task 72.0 in stage 13.0 (TID 965) in 2456 ms on dn36 (executor 20) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:00,456 | INFO  | [task-result-getter-0] | Finished task 82.0 in stage 13.0 (TID 975) in 2414 ms on dn36 (executor 20) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:00,725 | INFO  | [dispatcher-event-loop-45] | Starting task 70.0 in stage 14.0 (TID 984, dn17, executor 18, partition 70, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:00,726 | INFO  | [task-result-getter-3] | Finished task 65.0 in stage 14.0 (TID 886) in 8289 ms on dn17 (executor 18) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:01,165 | INFO  | [task-result-getter-2] | Finished task 7.0 in stage 13.0 (TID 900) in 3882 ms on dn19 (executor 11) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:01,957 | INFO  | [dispatcher-event-loop-61] | Starting task 72.0 in stage 14.0 (TID 985, dn14, executor 17, partition 72, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:01,957 | INFO  | [task-result-getter-1] | Finished task 25.0 in stage 14.0 (TID 887) in 9414 ms on dn14 (executor 17) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:02,892 | INFO  | [task-result-getter-0] | Finished task 85.0 in stage 14.0 (TID 889) in 7359 ms on dn18 (executor 10) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:03,001 | INFO  | [task-result-getter-3] | Finished task 63.0 in stage 14.0 (TID 888) in 8683 ms on dn14 (executor 17) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:03,502 | INFO  | [task-result-getter-2] | Finished task 47.0 in stage 13.0 (TID 940) in 5905 ms on dn20 (executor 13) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:03,606 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 13.0 (TID 895) in 6323 ms on dn27 (executor 7) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:04,246 | INFO  | [task-result-getter-0] | Finished task 74.0 in stage 14.0 (TID 891) in 7768 ms on dn22 (executor 5) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:05,610 | INFO  | [dispatcher-event-loop-32] | Starting task 73.0 in stage 14.0 (TID 986, dn29, executor 1, partition 73, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:05,610 | INFO  | [task-result-getter-3] | Finished task 56.0 in stage 14.0 (TID 890) in 9472 ms on dn29 (executor 1) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:05,875 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 13.0 (TID 951) in 8174 ms on dn16 (executor 15) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:06,539 | INFO  | [task-result-getter-1] | Finished task 69.0 in stage 14.0 (TID 892) in 9295 ms on dn29 (executor 1) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:06,955 | INFO  | [task-result-getter-0] | Finished task 67.0 in stage 14.0 (TID 983) in 8332 ms on dn17 (executor 18) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:07,943 | INFO  | [task-result-getter-3] | Finished task 73.0 in stage 13.0 (TID 966) in 10047 ms on dn08 (executor 16) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,204 | INFO  | [task-result-getter-2] | Finished task 10.0 in stage 13.0 (TID 903) in 10920 ms on dn37 (executor 8) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,673 | INFO  | [dispatcher-event-loop-35] | Starting task 34.0 in stage 14.0 (TID 987, dn17, executor 18, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,674 | INFO  | [dispatcher-event-loop-35] | Starting task 35.0 in stage 14.0 (TID 988, dn08, executor 16, partition 35, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,674 | INFO  | [dispatcher-event-loop-35] | Starting task 39.0 in stage 14.0 (TID 989, dn10, executor 19, partition 39, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,675 | INFO  | [dispatcher-event-loop-35] | Starting task 41.0 in stage 14.0 (TID 990, dn24, executor 9, partition 41, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,675 | INFO  | [dispatcher-event-loop-35] | Starting task 49.0 in stage 14.0 (TID 991, dn27, executor 7, partition 49, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,676 | INFO  | [dispatcher-event-loop-35] | Starting task 60.0 in stage 14.0 (TID 992, dn28, executor 3, partition 60, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:08,676 | INFO  | [dispatcher-event-loop-35] | Starting task 61.0 in stage 14.0 (TID 993, dn14, executor 17, partition 61, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:09,319 | INFO  | [task-result-getter-1] | Finished task 70.0 in stage 14.0 (TID 984) in 8594 ms on dn17 (executor 18) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:11,205 | INFO  | [task-result-getter-0] | Finished task 72.0 in stage 14.0 (TID 985) in 9249 ms on dn14 (executor 17) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:14,137 | INFO  | [task-result-getter-3] | Finished task 73.0 in stage 14.0 (TID 986) in 8528 ms on dn29 (executor 1) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:16,067 | INFO  | [task-result-getter-2] | Finished task 41.0 in stage 14.0 (TID 990) in 7392 ms on dn24 (executor 9) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:16,899 | INFO  | [task-result-getter-1] | Finished task 35.0 in stage 14.0 (TID 988) in 8224 ms on dn08 (executor 16) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:17,046 | INFO  | [task-result-getter-0] | Finished task 61.0 in stage 14.0 (TID 993) in 8370 ms on dn14 (executor 17) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:17,073 | INFO  | [task-result-getter-3] | Finished task 39.0 in stage 14.0 (TID 989) in 8398 ms on dn10 (executor 19) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:17,836 | INFO  | [task-result-getter-2] | Finished task 49.0 in stage 14.0 (TID 991) in 9161 ms on dn27 (executor 7) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:18,073 | INFO  | [task-result-getter-1] | Finished task 34.0 in stage 14.0 (TID 987) in 9400 ms on dn17 (executor 18) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:30,330 | INFO  | [task-result-getter-0] | Finished task 19.0 in stage 13.0 (TID 912) in 33045 ms on dn28 (executor 3) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,464 | INFO  | [task-result-getter-3] | Finished task 60.0 in stage 14.0 (TID 992) in 28788 ms on dn28 (executor 3) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,465 | INFO  | [task-result-getter-3] | Removed TaskSet 14.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,466 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 14 (distinct at GraphWriter.scala:253) finished in 100.253 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,466 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,466 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,466 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ShuffleMapStage 15, ResultStage 16) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,466 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,467 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 15 (MapPartitionsRDD[43] at mapPartitions at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,477 | INFO  | [dag-scheduler-event-loop] | Block broadcast_17 stored as values in memory (estimated size 7.4 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,482 | INFO  | [dag-scheduler-event-loop] | Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,483 | INFO  | [dispatcher-event-loop-69] | Added broadcast_17_piece0 in memory on dn37:22779 (size: 4.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,483 | INFO  | [dag-scheduler-event-loop] | Created broadcast 17 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,486 | INFO  | [dag-scheduler-event-loop] | Submitting 90 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[43] at mapPartitions at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,486 | INFO  | [dag-scheduler-event-loop] | Adding task set 15.0 with 90 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,487 | INFO  | [dispatcher-event-loop-65] | Starting task 0.0 in stage 15.0 (TID 994, dn20, executor 13, partition 0, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,487 | INFO  | [dispatcher-event-loop-65] | Starting task 1.0 in stage 15.0 (TID 995, dn17, executor 18, partition 1, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,487 | INFO  | [dispatcher-event-loop-65] | Starting task 2.0 in stage 15.0 (TID 996, dn22, executor 5, partition 2, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,487 | INFO  | [dispatcher-event-loop-65] | Starting task 3.0 in stage 15.0 (TID 997, dn08, executor 16, partition 3, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 4.0 in stage 15.0 (TID 998, dn29, executor 1, partition 4, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 5.0 in stage 15.0 (TID 999, dn10, executor 19, partition 5, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 6.0 in stage 15.0 (TID 1000, dn18, executor 10, partition 6, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 7.0 in stage 15.0 (TID 1001, dn28, executor 3, partition 7, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 8.0 in stage 15.0 (TID 1002, dn30, executor 2, partition 8, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 9.0 in stage 15.0 (TID 1003, dn19, executor 11, partition 9, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 10.0 in stage 15.0 (TID 1004, dn14, executor 17, partition 10, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,488 | INFO  | [dispatcher-event-loop-65] | Starting task 11.0 in stage 15.0 (TID 1005, dn07, executor 14, partition 11, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 12.0 in stage 15.0 (TID 1006, dn36, executor 20, partition 12, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 13.0 in stage 15.0 (TID 1007, dn32, executor 4, partition 13, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 14.0 in stage 15.0 (TID 1008, dn34, executor 6, partition 14, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 15.0 in stage 15.0 (TID 1009, dn37, executor 8, partition 15, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 16.0 in stage 15.0 (TID 1010, dn24, executor 9, partition 16, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 17.0 in stage 15.0 (TID 1011, dn27, executor 7, partition 17, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 18.0 in stage 15.0 (TID 1012, dn16, executor 15, partition 18, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,489 | INFO  | [dispatcher-event-loop-65] | Starting task 19.0 in stage 15.0 (TID 1013, dn15, executor 12, partition 19, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 20.0 in stage 15.0 (TID 1014, dn20, executor 13, partition 20, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 21.0 in stage 15.0 (TID 1015, dn17, executor 18, partition 21, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 22.0 in stage 15.0 (TID 1016, dn22, executor 5, partition 22, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 23.0 in stage 15.0 (TID 1017, dn08, executor 16, partition 23, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 24.0 in stage 15.0 (TID 1018, dn29, executor 1, partition 24, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 25.0 in stage 15.0 (TID 1019, dn18, executor 10, partition 25, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 26.0 in stage 15.0 (TID 1020, dn28, executor 3, partition 26, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,490 | INFO  | [dispatcher-event-loop-65] | Starting task 27.0 in stage 15.0 (TID 1021, dn30, executor 2, partition 27, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 28.0 in stage 15.0 (TID 1022, dn19, executor 11, partition 28, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 29.0 in stage 15.0 (TID 1023, dn14, executor 17, partition 29, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 30.0 in stage 15.0 (TID 1024, dn36, executor 20, partition 30, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 31.0 in stage 15.0 (TID 1025, dn34, executor 6, partition 31, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 32.0 in stage 15.0 (TID 1026, dn24, executor 9, partition 32, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 33.0 in stage 15.0 (TID 1027, dn27, executor 7, partition 33, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,491 | INFO  | [dispatcher-event-loop-65] | Starting task 34.0 in stage 15.0 (TID 1028, dn16, executor 15, partition 34, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,492 | INFO  | [dispatcher-event-loop-65] | Starting task 35.0 in stage 15.0 (TID 1029, dn15, executor 12, partition 35, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,506 | INFO  | [dispatcher-event-loop-42] | Added broadcast_17_piece0 in memory on dn30:22608 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,507 | INFO  | [dispatcher-event-loop-42] | Added broadcast_17_piece0 in memory on dn10:22719 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,507 | INFO  | [dispatcher-event-loop-42] | Added broadcast_17_piece0 in memory on dn17:22761 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,507 | INFO  | [dispatcher-event-loop-42] | Added broadcast_17_piece0 in memory on dn18:22756 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,507 | INFO  | [dispatcher-event-loop-42] | Added broadcast_17_piece0 in memory on dn15:22640 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,508 | INFO  | [dispatcher-event-loop-33] | Added broadcast_17_piece0 in memory on dn08:22604 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,508 | INFO  | [dispatcher-event-loop-33] | Added broadcast_17_piece0 in memory on dn14:22891 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,509 | INFO  | [dispatcher-event-loop-33] | Added broadcast_17_piece0 in memory on dn19:22830 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,509 | INFO  | [dispatcher-event-loop-33] | Added broadcast_17_piece0 in memory on dn27:22790 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,509 | INFO  | [dispatcher-event-loop-33] | Added broadcast_17_piece0 in memory on dn29:22705 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,510 | INFO  | [dispatcher-event-loop-66] | Added broadcast_17_piece0 in memory on dn24:22839 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,511 | INFO  | [dispatcher-event-loop-66] | Added broadcast_17_piece0 in memory on dn16:22668 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,511 | INFO  | [dispatcher-event-loop-66] | Added broadcast_17_piece0 in memory on dn28:22784 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,513 | INFO  | [dispatcher-event-loop-66] | Added broadcast_17_piece0 in memory on dn22:22834 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,513 | INFO  | [dispatcher-event-loop-66] | Added broadcast_17_piece0 in memory on dn36:22756 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,517 | INFO  | [dispatcher-event-loop-55] | Asked to send map output locations for shuffle 8 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,517 | INFO  | [dispatcher-event-loop-55] | Asked to send map output locations for shuffle 8 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,522 | INFO  | [dispatcher-event-loop-55] | Added broadcast_17_piece0 in memory on dn20:22825 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,523 | INFO  | [dispatcher-event-loop-55] | Added broadcast_17_piece0 in memory on dn07:22897 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,523 | INFO  | [dispatcher-event-loop-55] | Added broadcast_17_piece0 in memory on dn34:22620 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,523 | INFO  | [dispatcher-event-loop-55] | Asked to send map output locations for shuffle 8 to *.*.132.38:54888 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,524 | INFO  | [dispatcher-event-loop-45] | Asked to send map output locations for shuffle 8 to *.*.132.15:57922 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,526 | INFO  | [dispatcher-event-loop-62] | Asked to send map output locations for shuffle 8 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,530 | INFO  | [dispatcher-event-loop-54] | Asked to send map output locations for shuffle 8 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,530 | INFO  | [dispatcher-event-loop-68] | Asked to send map output locations for shuffle 8 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,530 | INFO  | [dispatcher-event-loop-61] | Asked to send map output locations for shuffle 8 to *.*.132.12:51724 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,531 | INFO  | [dispatcher-event-loop-8] | Asked to send map output locations for shuffle 8 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,531 | INFO  | [dispatcher-event-loop-1] | Asked to send map output locations for shuffle 8 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,532 | INFO  | [dispatcher-event-loop-71] | Asked to send map output locations for shuffle 8 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,532 | INFO  | [dispatcher-event-loop-7] | Asked to send map output locations for shuffle 8 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,532 | INFO  | [dispatcher-event-loop-10] | Asked to send map output locations for shuffle 8 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,532 | INFO  | [dispatcher-event-loop-17] | Asked to send map output locations for shuffle 8 to *.*.132.21:46253 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,533 | INFO  | [dispatcher-event-loop-15] | Asked to send map output locations for shuffle 8 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,538 | INFO  | [dispatcher-event-loop-19] | Asked to send map output locations for shuffle 8 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,540 | INFO  | [dispatcher-event-loop-18] | Asked to send map output locations for shuffle 8 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,547 | INFO  | [dispatcher-event-loop-25] | Asked to send map output locations for shuffle 8 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,554 | INFO  | [dispatcher-event-loop-31] | Updated broadcast_6_piece0 on disk on dn37:22861 (current size: 10.2 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,556 | INFO  | [dispatcher-event-loop-14] | Added broadcast_17_piece0 in memory on dn37:22861 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,606 | INFO  | [dispatcher-event-loop-24] | Updated broadcast_3_piece0 on disk on dn37:22861 (current size: 58.5 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,608 | INFO  | [dispatcher-event-loop-5] | Updated broadcast_7_piece0 on disk on dn37:22861 (current size: 2.5 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,614 | INFO  | [dispatcher-event-loop-27] | Updated broadcast_8_piece0 on disk on dn37:22861 (current size: 9.6 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,620 | INFO  | [dispatcher-event-loop-20] | Updated broadcast_9_piece0 on disk on dn37:22861 (current size: 4.1 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,625 | INFO  | [dispatcher-event-loop-6] | Updated broadcast_10_piece0 on disk on dn37:22861 (current size: 9.6 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,630 | INFO  | [dispatcher-event-loop-22] | Updated broadcast_11_piece0 on disk on dn37:22861 (current size: 4.1 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,635 | INFO  | [dispatcher-event-loop-26] | Updated broadcast_12_piece0 on disk on dn37:22861 (current size: 9.7 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:37,640 | INFO  | [dispatcher-event-loop-32] | Asked to send map output locations for shuffle 8 to *.*.132.45:47294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:38,896 | INFO  | [dispatcher-event-loop-49] | Updated broadcast_6_piece0 on disk on dn32:22787 (current size: 10.2 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:38,901 | INFO  | [dispatcher-event-loop-34] | Added broadcast_17_piece0 in memory on dn32:22787 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:38,970 | INFO  | [dispatcher-event-loop-37] | Updated broadcast_3_piece0 on disk on dn32:22787 (current size: 58.5 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:38,973 | INFO  | [dispatcher-event-loop-47] | Updated broadcast_7_piece0 on disk on dn32:22787 (current size: 2.5 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:38,982 | INFO  | [dispatcher-event-loop-4] | Updated broadcast_8_piece0 on disk on dn32:22787 (current size: 9.6 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:38,991 | INFO  | [dispatcher-event-loop-11] | Updated broadcast_9_piece0 on disk on dn32:22787 (current size: 4.1 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:39,000 | INFO  | [dispatcher-event-loop-56] | Updated broadcast_10_piece0 on disk on dn32:22787 (current size: 9.6 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:39,008 | INFO  | [dispatcher-event-loop-42] | Updated broadcast_11_piece0 on disk on dn32:22787 (current size: 4.1 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:39,017 | INFO  | [dispatcher-event-loop-44] | Updated broadcast_12_piece0 on disk on dn32:22787 (current size: 9.7 KB, original size: 0.0 B) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:39,037 | INFO  | [dispatcher-event-loop-43] | Asked to send map output locations for shuffle 8 to *.*.132.40:54846 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,952 | INFO  | [dispatcher-event-loop-26] | Starting task 36.0 in stage 15.0 (TID 1030, dn15, executor 12, partition 36, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,953 | INFO  | [task-result-getter-2] | Finished task 19.0 in stage 15.0 (TID 1013) in 11464 ms on dn15 (executor 12) (1/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,971 | INFO  | [dispatcher-event-loop-21] | Starting task 37.0 in stage 15.0 (TID 1031, dn20, executor 13, partition 37, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,972 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 15.0 (TID 994) in 11485 ms on dn20 (executor 13) (2/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,988 | INFO  | [dispatcher-event-loop-57] | Starting task 38.0 in stage 15.0 (TID 1032, dn24, executor 9, partition 38, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,989 | INFO  | [task-result-getter-0] | Finished task 32.0 in stage 15.0 (TID 1026) in 11498 ms on dn24 (executor 9) (3/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,995 | INFO  | [dispatcher-event-loop-39] | Starting task 39.0 in stage 15.0 (TID 1033, dn15, executor 12, partition 39, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:48,995 | INFO  | [task-result-getter-3] | Finished task 35.0 in stage 15.0 (TID 1029) in 11504 ms on dn15 (executor 12) (4/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,011 | INFO  | [dispatcher-event-loop-29] | Starting task 40.0 in stage 15.0 (TID 1034, dn24, executor 9, partition 40, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,012 | INFO  | [task-result-getter-2] | Finished task 16.0 in stage 15.0 (TID 1010) in 11523 ms on dn24 (executor 9) (5/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,019 | INFO  | [dispatcher-event-loop-40] | Starting task 41.0 in stage 15.0 (TID 1035, dn22, executor 5, partition 41, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,019 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 15.0 (TID 996) in 11532 ms on dn22 (executor 5) (6/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,046 | INFO  | [dispatcher-event-loop-49] | Starting task 42.0 in stage 15.0 (TID 1036, dn08, executor 16, partition 42, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,046 | INFO  | [task-result-getter-0] | Finished task 23.0 in stage 15.0 (TID 1017) in 11556 ms on dn08 (executor 16) (7/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,047 | INFO  | [dispatcher-event-loop-49] | Starting task 43.0 in stage 15.0 (TID 1037, dn08, executor 16, partition 43, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,047 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 15.0 (TID 997) in 11560 ms on dn08 (executor 16) (8/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,186 | INFO  | [dispatcher-event-loop-4] | Starting task 44.0 in stage 15.0 (TID 1038, dn07, executor 14, partition 44, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,186 | INFO  | [task-result-getter-2] | Finished task 11.0 in stage 15.0 (TID 1005) in 11698 ms on dn07 (executor 14) (9/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,222 | INFO  | [dispatcher-event-loop-56] | Starting task 45.0 in stage 15.0 (TID 1039, dn20, executor 13, partition 45, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,223 | INFO  | [task-result-getter-1] | Finished task 20.0 in stage 15.0 (TID 1014) in 11733 ms on dn20 (executor 13) (10/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,239 | INFO  | [dispatcher-event-loop-44] | Starting task 46.0 in stage 15.0 (TID 1040, dn10, executor 19, partition 46, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,239 | INFO  | [task-result-getter-0] | Finished task 5.0 in stage 15.0 (TID 999) in 11751 ms on dn10 (executor 19) (11/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,261 | INFO  | [dispatcher-event-loop-51] | Starting task 47.0 in stage 15.0 (TID 1041, dn16, executor 15, partition 47, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,262 | INFO  | [task-result-getter-3] | Finished task 34.0 in stage 15.0 (TID 1028) in 11771 ms on dn16 (executor 15) (12/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,275 | INFO  | [dispatcher-event-loop-41] | Starting task 48.0 in stage 15.0 (TID 1042, dn22, executor 5, partition 48, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,275 | INFO  | [task-result-getter-2] | Finished task 22.0 in stage 15.0 (TID 1016) in 11785 ms on dn22 (executor 5) (13/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,284 | INFO  | [dispatcher-event-loop-35] | Starting task 49.0 in stage 15.0 (TID 1043, dn16, executor 15, partition 49, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,284 | INFO  | [task-result-getter-1] | Finished task 18.0 in stage 15.0 (TID 1012) in 11795 ms on dn16 (executor 15) (14/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,286 | INFO  | [dispatcher-event-loop-58] | Starting task 50.0 in stage 15.0 (TID 1044, dn29, executor 1, partition 50, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,286 | INFO  | [task-result-getter-0] | Finished task 24.0 in stage 15.0 (TID 1018) in 11796 ms on dn29 (executor 1) (15/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,287 | INFO  | [dispatcher-event-loop-58] | Starting task 51.0 in stage 15.0 (TID 1045, dn17, executor 18, partition 51, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,287 | INFO  | [task-result-getter-3] | Finished task 21.0 in stage 15.0 (TID 1015) in 11797 ms on dn17 (executor 18) (16/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,288 | INFO  | [dispatcher-event-loop-58] | Starting task 52.0 in stage 15.0 (TID 1046, dn17, executor 18, partition 52, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,288 | INFO  | [task-result-getter-2] | Finished task 1.0 in stage 15.0 (TID 995) in 11801 ms on dn17 (executor 18) (17/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,294 | INFO  | [dispatcher-event-loop-53] | Starting task 53.0 in stage 15.0 (TID 1047, dn29, executor 1, partition 53, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,294 | INFO  | [task-result-getter-1] | Finished task 4.0 in stage 15.0 (TID 998) in 11807 ms on dn29 (executor 1) (18/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,305 | INFO  | [dispatcher-event-loop-59] | Starting task 54.0 in stage 15.0 (TID 1048, dn30, executor 2, partition 54, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,305 | INFO  | [task-result-getter-0] | Finished task 8.0 in stage 15.0 (TID 1002) in 11817 ms on dn30 (executor 2) (19/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,352 | INFO  | [dispatcher-event-loop-55] | Starting task 55.0 in stage 15.0 (TID 1049, dn19, executor 11, partition 55, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,352 | INFO  | [task-result-getter-3] | Finished task 28.0 in stage 15.0 (TID 1022) in 11861 ms on dn19 (executor 11) (20/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,369 | INFO  | [dispatcher-event-loop-67] | Starting task 56.0 in stage 15.0 (TID 1050, dn19, executor 11, partition 56, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,370 | INFO  | [task-result-getter-2] | Finished task 9.0 in stage 15.0 (TID 1003) in 11882 ms on dn19 (executor 11) (21/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,384 | INFO  | [dispatcher-event-loop-65] | Starting task 57.0 in stage 15.0 (TID 1051, dn18, executor 10, partition 57, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,385 | INFO  | [task-result-getter-1] | Finished task 25.0 in stage 15.0 (TID 1019) in 11895 ms on dn18 (executor 10) (22/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,391 | INFO  | [dispatcher-event-loop-60] | Starting task 58.0 in stage 15.0 (TID 1052, dn27, executor 7, partition 58, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,392 | INFO  | [task-result-getter-0] | Finished task 33.0 in stage 15.0 (TID 1027) in 11901 ms on dn27 (executor 7) (23/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,411 | INFO  | [dispatcher-event-loop-54] | Starting task 59.0 in stage 15.0 (TID 1053, dn28, executor 3, partition 59, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,411 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 15.0 (TID 1001) in 11923 ms on dn28 (executor 3) (24/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,431 | INFO  | [dispatcher-event-loop-68] | Starting task 60.0 in stage 15.0 (TID 1054, dn18, executor 10, partition 60, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,431 | INFO  | [task-result-getter-2] | Finished task 6.0 in stage 15.0 (TID 1000) in 11943 ms on dn18 (executor 10) (25/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,463 | INFO  | [dispatcher-event-loop-8] | Starting task 61.0 in stage 15.0 (TID 1055, dn28, executor 3, partition 61, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,464 | INFO  | [task-result-getter-1] | Finished task 26.0 in stage 15.0 (TID 1020) in 11974 ms on dn28 (executor 3) (26/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,516 | INFO  | [dispatcher-event-loop-71] | Starting task 62.0 in stage 15.0 (TID 1056, dn14, executor 17, partition 62, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,516 | INFO  | [task-result-getter-0] | Finished task 29.0 in stage 15.0 (TID 1023) in 12025 ms on dn14 (executor 17) (27/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,517 | INFO  | [dispatcher-event-loop-71] | Starting task 63.0 in stage 15.0 (TID 1057, dn14, executor 17, partition 63, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,517 | INFO  | [task-result-getter-3] | Finished task 10.0 in stage 15.0 (TID 1004) in 12029 ms on dn14 (executor 17) (28/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,535 | INFO  | [dispatcher-event-loop-15] | Starting task 64.0 in stage 15.0 (TID 1058, dn34, executor 6, partition 64, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,535 | INFO  | [task-result-getter-2] | Finished task 31.0 in stage 15.0 (TID 1025) in 12044 ms on dn34 (executor 6) (29/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,544 | INFO  | [dispatcher-event-loop-16] | Starting task 65.0 in stage 15.0 (TID 1059, dn30, executor 2, partition 65, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,545 | INFO  | [task-result-getter-1] | Finished task 27.0 in stage 15.0 (TID 1021) in 12055 ms on dn30 (executor 2) (30/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,545 | INFO  | [dispatcher-event-loop-12] | Starting task 66.0 in stage 15.0 (TID 1060, dn34, executor 6, partition 66, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,546 | INFO  | [task-result-getter-0] | Finished task 14.0 in stage 15.0 (TID 1008) in 12057 ms on dn34 (executor 6) (31/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,552 | INFO  | [dispatcher-event-loop-18] | Starting task 67.0 in stage 15.0 (TID 1061, dn27, executor 7, partition 67, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:49,553 | INFO  | [task-result-getter-3] | Finished task 17.0 in stage 15.0 (TID 1011) in 12064 ms on dn27 (executor 7) (32/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:50,042 | INFO  | [dispatcher-event-loop-14] | Starting task 68.0 in stage 15.0 (TID 1062, dn36, executor 20, partition 68, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:50,043 | INFO  | [task-result-getter-2] | Finished task 12.0 in stage 15.0 (TID 1006) in 12554 ms on dn36 (executor 20) (33/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:50,066 | INFO  | [dispatcher-event-loop-5] | Starting task 69.0 in stage 15.0 (TID 1063, dn36, executor 20, partition 69, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:50,066 | INFO  | [task-result-getter-1] | Finished task 30.0 in stage 15.0 (TID 1024) in 12575 ms on dn36 (executor 20) (34/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,550 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 115 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,550 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 179 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,552 | INFO  | [dispatcher-event-loop-28] | Removed broadcast_6_piece0 on dn37:22779 in memory (size: 10.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,555 | INFO  | [dispatcher-event-loop-40] | Removed broadcast_6_piece0 on dn27:22790 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,556 | INFO  | [dispatcher-event-loop-38] | Removed broadcast_6_piece0 on dn22:22834 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,564 | INFO  | [dispatcher-event-loop-34] | Removed broadcast_6_piece0 on dn08:22604 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,566 | INFO  | [dispatcher-event-loop-49] | Removed broadcast_6_piece0 on dn15:22640 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,567 | INFO  | [dispatcher-event-loop-37] | Removed broadcast_6_piece0 on dn20:22825 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,568 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn29:22705 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,569 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn16:22668 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,571 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn37:22861 on disk (size: 10.2 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,572 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn34:22620 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,572 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn28:22784 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,572 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn07:22897 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,572 | INFO  | [dispatcher-event-loop-47] | Removed broadcast_6_piece0 on dn10:22719 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,573 | INFO  | [dispatcher-event-loop-51] | Removed broadcast_6_piece0 on dn14:22891 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,573 | INFO  | [dispatcher-event-loop-51] | Removed broadcast_6_piece0 on dn24:22839 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,576 | INFO  | [dispatcher-event-loop-41] | Removed broadcast_6_piece0 on dn17:22761 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,576 | INFO  | [dispatcher-event-loop-41] | Removed broadcast_6_piece0 on dn18:22756 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,579 | INFO  | [dispatcher-event-loop-35] | Removed broadcast_6_piece0 on dn36:22756 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,580 | INFO  | [dispatcher-event-loop-33] | Removed broadcast_6_piece0 on dn19:22830 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,582 | INFO  | [dispatcher-event-loop-36] | Removed broadcast_6_piece0 on dn30:22608 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,741 | INFO  | [dispatcher-event-loop-58] | Removed broadcast_6_piece0 on dn32:22787 on disk (size: 10.2 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,762 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 184 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,762 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 222 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,762 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 117 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,762 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 166 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,762 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 136 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,762 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 133 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 156 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 154 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 200 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 247 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 122 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 131 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,763 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 240 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,764 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 173 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,764 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 218 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,764 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 207 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,764 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 109 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,764 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 197 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,764 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 167 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,765 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 121 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,765 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 120 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,765 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 168 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,765 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 233 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,765 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 142 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,765 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 203 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,766 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 126 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,768 | INFO  | [dispatcher-event-loop-50] | Removed broadcast_15_piece0 on dn37:22779 in memory (size: 4.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,769 | INFO  | [dispatcher-event-loop-59] | Removed broadcast_15_piece0 on dn07:22897 in memory (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,770 | INFO  | [dispatcher-event-loop-59] | Removed broadcast_15_piece0 on dn15:22640 in memory (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,770 | INFO  | [dispatcher-event-loop-59] | Removed broadcast_15_piece0 on dn18:22756 in memory (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,771 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_15_piece0 on dn37:22861 in memory (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,779 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 183 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,781 | INFO  | [dispatcher-event-loop-65] | Removed broadcast_14_piece0 on dn37:22779 in memory (size: 9.7 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,782 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn20:22825 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,782 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn32:22787 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,783 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn07:22897 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,783 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn10:22719 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,783 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn27:22790 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,784 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn15:22640 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,784 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn16:22668 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,785 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn08:22604 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,785 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn28:22784 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,785 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn18:22756 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,786 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn19:22830 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,786 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn17:22761 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,787 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn14:22891 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,787 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn37:22861 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,787 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn22:22834 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,788 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn29:22705 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,788 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn24:22839 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,788 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn30:22608 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,789 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn36:22756 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,789 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_14_piece0 on dn34:22620 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,792 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 227 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,792 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 238 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,792 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 174 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,792 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,792 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 110 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,793 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 139 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,793 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 157 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,793 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 199 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,793 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 103 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,793 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 224 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,793 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 141 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 242 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 163 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 190 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 196 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 229 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 189 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,794 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 201 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,795 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 102 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,797 | INFO  | [dispatcher-event-loop-14] | Removed broadcast_7_piece0 on dn37:22779 in memory (size: 2.5 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,798 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn20:22825 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,798 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn16:22668 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,799 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn27:22790 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,799 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn07:22897 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,800 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn08:22604 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,801 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn19:22830 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,801 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn10:22719 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,801 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn14:22891 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,802 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn28:22784 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,802 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn34:22620 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,803 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn15:22640 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,803 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn29:22705 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,803 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn17:22761 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,804 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn30:22608 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,804 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn24:22839 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,805 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn18:22756 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,805 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn22:22834 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,805 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn37:22861 on disk (size: 2.5 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,806 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_7_piece0 on dn36:22756 in memory (size: 2.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,816 | INFO  | [dispatcher-event-loop-49] | Removed broadcast_7_piece0 on dn32:22787 on disk (size: 2.5 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,819 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 140 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,819 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 250 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,819 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 118 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,820 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 170 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,821 | INFO  | [dispatcher-event-loop-11] | Removed broadcast_9_piece0 on dn37:22779 in memory (size: 4.1 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,822 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn27:22790 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,823 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn32:22787 on disk (size: 4.1 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,823 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn07:22897 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,823 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn19:22830 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,824 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn14:22891 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,824 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn20:22825 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,825 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn28:22784 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,825 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn10:22719 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,825 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn08:22604 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,826 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn16:22668 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,826 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn30:22608 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,827 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn18:22756 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,827 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn22:22834 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,827 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn17:22761 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,828 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn24:22839 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,828 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn15:22640 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,828 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn34:22620 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,829 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn29:22705 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,829 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn37:22861 on disk (size: 4.1 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,829 | INFO  | [dispatcher-event-loop-56] | Removed broadcast_9_piece0 on dn36:22756 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,832 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 147 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,832 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 214 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,832 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 241 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,832 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 209 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,832 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 108 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,845 | INFO  | [Spark Context Cleaner] | Cleaned shuffle 2 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,846 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 165 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,846 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 228 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,846 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 116 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,846 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 239 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,846 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 243 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,846 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 220 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 206 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 235 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 155 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 177 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 225 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 134 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,847 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 210 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 132 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 135 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 251 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 245 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 130 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 105 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,848 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 113 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 160 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 182 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 161 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 186 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 211 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 180 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,849 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 127 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,852 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn37:22779 in memory (size: 9.6 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,852 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn27:22790 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,853 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn32:22787 on disk (size: 9.6 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,853 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn20:22825 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,854 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn07:22897 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,854 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn16:22668 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,854 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn19:22830 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,855 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn34:22620 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,855 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn10:22719 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,855 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn14:22891 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,856 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn18:22756 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,856 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn08:22604 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,857 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn36:22756 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,857 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn17:22761 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,857 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn29:22705 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,858 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn30:22608 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,858 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn22:22834 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,858 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn24:22839 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,859 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn37:22861 on disk (size: 9.6 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,859 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn28:22784 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,859 | INFO  | [dispatcher-event-loop-67] | Removed broadcast_10_piece0 on dn15:22640 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,861 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 153 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,862 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 151 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,862 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 188 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,862 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 204 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,862 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 248 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,862 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 232 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,862 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 249 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,863 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 205 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,863 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 143 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,863 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 164 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,865 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn37:22779 in memory (size: 9.5 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,865 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn28:22784 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,866 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn20:22825 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,866 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn19:22830 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,867 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn07:22897 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,867 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn16:22668 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,868 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn18:22756 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,868 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn27:22790 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,868 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn15:22640 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,869 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn14:22891 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,869 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn10:22719 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,870 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn34:22620 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,870 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn22:22834 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,870 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn24:22839 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,871 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn29:22705 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,871 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn36:22756 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,871 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn30:22608 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,872 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn17:22761 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,872 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn08:22604 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,873 | INFO  | [dispatcher-event-loop-25] | Removed broadcast_13_piece0 on dn37:22861 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,874 | INFO  | [dispatcher-event-loop-24] | Removed broadcast_13_piece0 on dn32:22787 in memory (size: 9.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,877 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 194 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,877 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 125 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,877 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 217 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,877 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 236 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,877 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 171 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 169 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 149 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 124 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 128 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 181 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 215 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,878 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 178 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 213 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 123 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 237 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 221 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 106 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 198 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,879 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 112 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 212 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 158 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 111 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 231 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 192 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 244 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,880 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 150 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 138 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 230 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 219 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 104 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 185 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,881 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 107 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,882 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 148 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,883 | INFO  | [Spark Context Cleaner] | Cleaned shuffle 0 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,883 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 187 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,883 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 191 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,884 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 216 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,884 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 114 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,884 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 137 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,886 | INFO  | [dispatcher-event-loop-42] | Removed broadcast_8_piece0 on dn37:22779 in memory (size: 9.6 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,886 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn08:22604 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,887 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn20:22825 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,887 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn19:22830 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,887 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn16:22668 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,888 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn07:22897 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,888 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn32:22787 on disk (size: 9.6 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,888 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn30:22608 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,888 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn28:22784 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,888 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn17:22761 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,889 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn18:22756 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,889 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn29:22705 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,889 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn15:22640 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,889 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn14:22891 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,889 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn10:22719 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,890 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn24:22839 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,890 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn36:22756 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,890 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn37:22861 on disk (size: 9.6 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,890 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn34:22620 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,890 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn22:22834 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,891 | INFO  | [dispatcher-event-loop-44] | Removed broadcast_8_piece0 on dn27:22790 in memory (size: 9.6 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,896 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 234 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,896 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 152 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,896 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 208 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,897 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 246 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,897 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 119 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,897 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 129 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,897 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 162 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,897 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 146 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,897 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 172 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 159 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 223 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 226 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 193 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 145 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 144 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,898 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 195 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,900 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn37:22779 in memory (size: 9.7 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,901 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn32:22787 on disk (size: 9.7 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,901 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn28:22784 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,902 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn27:22790 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,902 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn20:22825 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,903 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn19:22830 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,903 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn16:22668 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,904 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn07:22897 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,904 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn08:22604 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,904 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn22:22834 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,905 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn10:22719 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,905 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn34:22620 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,905 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn24:22839 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,906 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn30:22608 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,906 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn15:22640 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,907 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn36:22756 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,907 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn17:22761 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,907 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn29:22705 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,908 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn14:22891 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,908 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn18:22756 in memory (size: 9.7 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,908 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_12_piece0 on dn37:22861 on disk (size: 9.7 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,911 | INFO  | [Spark Context Cleaner] | Cleaned shuffle 1 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,913 | INFO  | [dispatcher-event-loop-5] | Removed broadcast_11_piece0 on dn37:22779 in memory (size: 4.1 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,914 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn32:22787 on disk (size: 4.1 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,914 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn22:22834 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,915 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn28:22784 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,915 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn27:22790 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,915 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn16:22668 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,916 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn15:22640 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,916 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn37:22861 on disk (size: 4.1 KB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,917 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn08:22604 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,917 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn20:22825 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,917 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn10:22719 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,918 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn30:22608 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,918 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn24:22839 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,918 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn19:22830 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,919 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn18:22756 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,919 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn17:22761 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,919 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn07:22897 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,920 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn14:22891 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,920 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn29:22705 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,921 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn36:22756 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,921 | INFO  | [dispatcher-event-loop-27] | Removed broadcast_11_piece0 on dn34:22620 in memory (size: 4.1 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:51,923 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 175 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:54,484 | INFO  | [dispatcher-event-loop-35] | Starting task 70.0 in stage 15.0 (TID 1064, dn32, executor 4, partition 70, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:54,484 | INFO  | [task-result-getter-0] | Finished task 13.0 in stage 15.0 (TID 1007) in 16995 ms on dn32 (executor 4) (35/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,283 | INFO  | [dispatcher-event-loop-69] | Starting task 71.0 in stage 15.0 (TID 1065, dn08, executor 16, partition 71, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,284 | INFO  | [task-result-getter-3] | Finished task 42.0 in stage 15.0 (TID 1036) in 7238 ms on dn08 (executor 16) (36/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,295 | INFO  | [dispatcher-event-loop-65] | Starting task 72.0 in stage 15.0 (TID 1066, dn08, executor 16, partition 72, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,295 | INFO  | [task-result-getter-2] | Finished task 43.0 in stage 15.0 (TID 1037) in 7248 ms on dn08 (executor 16) (37/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,372 | INFO  | [dispatcher-event-loop-3] | Starting task 73.0 in stage 15.0 (TID 1067, dn24, executor 9, partition 73, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,372 | INFO  | [task-result-getter-1] | Finished task 40.0 in stage 15.0 (TID 1034) in 7361 ms on dn24 (executor 9) (38/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,425 | INFO  | [dispatcher-event-loop-61] | Starting task 74.0 in stage 15.0 (TID 1068, dn22, executor 5, partition 74, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,426 | INFO  | [task-result-getter-0] | Finished task 41.0 in stage 15.0 (TID 1035) in 7407 ms on dn22 (executor 5) (39/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,473 | INFO  | [dispatcher-event-loop-7] | Starting task 75.0 in stage 15.0 (TID 1069, dn16, executor 15, partition 75, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,474 | INFO  | [task-result-getter-3] | Finished task 47.0 in stage 15.0 (TID 1041) in 7213 ms on dn16 (executor 15) (40/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,587 | INFO  | [dispatcher-event-loop-71] | Starting task 76.0 in stage 15.0 (TID 1070, dn16, executor 15, partition 76, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,588 | INFO  | [task-result-getter-2] | Finished task 49.0 in stage 15.0 (TID 1043) in 7304 ms on dn16 (executor 15) (41/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,711 | INFO  | [dispatcher-event-loop-15] | Starting task 77.0 in stage 15.0 (TID 1071, dn20, executor 13, partition 77, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,712 | INFO  | [task-result-getter-1] | Finished task 45.0 in stage 15.0 (TID 1039) in 7490 ms on dn20 (executor 13) (42/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,742 | INFO  | [dispatcher-event-loop-2] | Starting task 78.0 in stage 15.0 (TID 1072, dn30, executor 2, partition 78, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,742 | INFO  | [task-result-getter-0] | Finished task 54.0 in stage 15.0 (TID 1048) in 7438 ms on dn30 (executor 2) (43/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,751 | INFO  | [dispatcher-event-loop-18] | Starting task 79.0 in stage 15.0 (TID 1073, dn22, executor 5, partition 79, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,751 | INFO  | [task-result-getter-3] | Finished task 48.0 in stage 15.0 (TID 1042) in 7476 ms on dn22 (executor 5) (44/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,798 | INFO  | [dispatcher-event-loop-31] | Starting task 80.0 in stage 15.0 (TID 1074, dn07, executor 14, partition 80, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,798 | INFO  | [task-result-getter-2] | Finished task 44.0 in stage 15.0 (TID 1038) in 7612 ms on dn07 (executor 14) (45/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,819 | INFO  | [dispatcher-event-loop-14] | Starting task 81.0 in stage 15.0 (TID 1075, dn29, executor 1, partition 81, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,819 | INFO  | [task-result-getter-1] | Finished task 53.0 in stage 15.0 (TID 1047) in 7525 ms on dn29 (executor 1) (46/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,826 | INFO  | [dispatcher-event-loop-5] | Starting task 82.0 in stage 15.0 (TID 1076, dn34, executor 6, partition 82, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,826 | INFO  | [task-result-getter-0] | Finished task 64.0 in stage 15.0 (TID 1058) in 7292 ms on dn34 (executor 6) (47/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,842 | INFO  | [dispatcher-event-loop-20] | Starting task 83.0 in stage 15.0 (TID 1077, dn15, executor 12, partition 83, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,843 | INFO  | [task-result-getter-3] | Finished task 39.0 in stage 15.0 (TID 1033) in 7848 ms on dn15 (executor 12) (48/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,852 | INFO  | [dispatcher-event-loop-26] | Starting task 84.0 in stage 15.0 (TID 1078, dn34, executor 6, partition 84, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,852 | INFO  | [task-result-getter-2] | Finished task 66.0 in stage 15.0 (TID 1060) in 7307 ms on dn34 (executor 6) (49/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,880 | INFO  | [dispatcher-event-loop-6] | Starting task 85.0 in stage 15.0 (TID 1079, dn15, executor 12, partition 85, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,880 | INFO  | [task-result-getter-1] | Finished task 36.0 in stage 15.0 (TID 1030) in 7928 ms on dn15 (executor 12) (50/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,881 | INFO  | [dispatcher-event-loop-30] | Starting task 86.0 in stage 15.0 (TID 1080, dn30, executor 2, partition 86, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,882 | INFO  | [task-result-getter-0] | Finished task 65.0 in stage 15.0 (TID 1059) in 7338 ms on dn30 (executor 2) (51/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,918 | INFO  | [dispatcher-event-loop-13] | Starting task 87.0 in stage 15.0 (TID 1081, dn10, executor 19, partition 87, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,919 | INFO  | [task-result-getter-3] | Finished task 46.0 in stage 15.0 (TID 1040) in 7680 ms on dn10 (executor 19) (52/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,956 | INFO  | [dispatcher-event-loop-23] | Starting task 88.0 in stage 15.0 (TID 1082, dn29, executor 1, partition 88, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,957 | INFO  | [task-result-getter-2] | Finished task 50.0 in stage 15.0 (TID 1044) in 7671 ms on dn29 (executor 1) (53/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:56,999 | INFO  | [dispatcher-event-loop-40] | Starting task 89.0 in stage 15.0 (TID 1083, dn19, executor 11, partition 89, PROCESS_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,000 | INFO  | [task-result-getter-1] | Finished task 56.0 in stage 15.0 (TID 1050) in 7631 ms on dn19 (executor 11) (54/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,030 | INFO  | [task-result-getter-0] | Finished task 62.0 in stage 15.0 (TID 1056) in 7514 ms on dn14 (executor 17) (55/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,033 | INFO  | [task-result-getter-3] | Finished task 55.0 in stage 15.0 (TID 1049) in 7681 ms on dn19 (executor 11) (56/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,047 | INFO  | [task-result-getter-2] | Finished task 38.0 in stage 15.0 (TID 1032) in 8059 ms on dn24 (executor 9) (57/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,061 | INFO  | [task-result-getter-1] | Finished task 63.0 in stage 15.0 (TID 1057) in 7545 ms on dn14 (executor 17) (58/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,064 | INFO  | [task-result-getter-0] | Finished task 52.0 in stage 15.0 (TID 1046) in 7776 ms on dn17 (executor 18) (59/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,103 | INFO  | [task-result-getter-3] | Finished task 51.0 in stage 15.0 (TID 1045) in 7816 ms on dn17 (executor 18) (60/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,225 | INFO  | [task-result-getter-2] | Finished task 59.0 in stage 15.0 (TID 1053) in 7814 ms on dn28 (executor 3) (61/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,226 | INFO  | [task-result-getter-1] | Finished task 61.0 in stage 15.0 (TID 1055) in 7763 ms on dn28 (executor 3) (62/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,234 | INFO  | [task-result-getter-0] | Finished task 60.0 in stage 15.0 (TID 1054) in 7803 ms on dn18 (executor 10) (63/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,242 | INFO  | [task-result-getter-3] | Finished task 57.0 in stage 15.0 (TID 1051) in 7858 ms on dn18 (executor 10) (64/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,256 | INFO  | [task-result-getter-2] | Finished task 58.0 in stage 15.0 (TID 1052) in 7865 ms on dn27 (executor 7) (65/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,275 | INFO  | [task-result-getter-1] | Finished task 67.0 in stage 15.0 (TID 1061) in 7723 ms on dn27 (executor 7) (66/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:57,315 | INFO  | [task-result-getter-0] | Finished task 37.0 in stage 15.0 (TID 1031) in 8344 ms on dn20 (executor 13) (67/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:58,150 | INFO  | [task-result-getter-3] | Finished task 69.0 in stage 15.0 (TID 1063) in 8084 ms on dn36 (executor 20) (68/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:11:58,150 | INFO  | [task-result-getter-2] | Finished task 68.0 in stage 15.0 (TID 1062) in 8108 ms on dn36 (executor 20) (69/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:02,584 | INFO  | [task-result-getter-1] | Finished task 83.0 in stage 15.0 (TID 1077) in 5742 ms on dn15 (executor 12) (70/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:02,649 | INFO  | [task-result-getter-0] | Finished task 85.0 in stage 15.0 (TID 1079) in 5769 ms on dn15 (executor 12) (71/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:02,936 | INFO  | [task-result-getter-3] | Finished task 70.0 in stage 15.0 (TID 1064) in 8452 ms on dn32 (executor 4) (72/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,273 | INFO  | [task-result-getter-2] | Finished task 89.0 in stage 15.0 (TID 1083) in 6274 ms on dn19 (executor 11) (73/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,338 | INFO  | [task-result-getter-1] | Finished task 84.0 in stage 15.0 (TID 1078) in 6486 ms on dn34 (executor 6) (74/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,345 | INFO  | [task-result-getter-0] | Finished task 82.0 in stage 15.0 (TID 1076) in 6519 ms on dn34 (executor 6) (75/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,363 | INFO  | [task-result-getter-3] | Finished task 88.0 in stage 15.0 (TID 1082) in 6407 ms on dn29 (executor 1) (76/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,363 | INFO  | [task-result-getter-2] | Finished task 81.0 in stage 15.0 (TID 1075) in 6544 ms on dn29 (executor 1) (77/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,385 | INFO  | [task-result-getter-1] | Finished task 86.0 in stage 15.0 (TID 1080) in 6504 ms on dn30 (executor 2) (78/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,468 | INFO  | [task-result-getter-0] | Finished task 80.0 in stage 15.0 (TID 1074) in 6670 ms on dn07 (executor 14) (79/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,741 | INFO  | [task-result-getter-3] | Finished task 87.0 in stage 15.0 (TID 1081) in 6823 ms on dn10 (executor 19) (80/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,896 | INFO  | [task-result-getter-2] | Finished task 75.0 in stage 15.0 (TID 1069) in 7423 ms on dn16 (executor 15) (81/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,964 | INFO  | [task-result-getter-1] | Finished task 71.0 in stage 15.0 (TID 1065) in 7681 ms on dn08 (executor 16) (82/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:03,999 | INFO  | [task-result-getter-0] | Finished task 73.0 in stage 15.0 (TID 1067) in 7628 ms on dn24 (executor 9) (83/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:04,072 | INFO  | [task-result-getter-3] | Finished task 76.0 in stage 15.0 (TID 1070) in 7484 ms on dn16 (executor 15) (84/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:04,197 | INFO  | [task-result-getter-2] | Finished task 72.0 in stage 15.0 (TID 1066) in 7902 ms on dn08 (executor 16) (85/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:04,288 | INFO  | [task-result-getter-1] | Finished task 77.0 in stage 15.0 (TID 1071) in 7577 ms on dn20 (executor 13) (86/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:04,295 | INFO  | [task-result-getter-0] | Finished task 74.0 in stage 15.0 (TID 1068) in 7870 ms on dn22 (executor 5) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:04,439 | INFO  | [task-result-getter-3] | Finished task 78.0 in stage 15.0 (TID 1072) in 7697 ms on dn30 (executor 2) (88/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:04,508 | INFO  | [task-result-getter-2] | Finished task 79.0 in stage 15.0 (TID 1073) in 7757 ms on dn22 (executor 5) (89/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,420 | INFO  | [task-result-getter-1] | Finished task 15.0 in stage 15.0 (TID 1009) in 32931 ms on dn37 (executor 8) (90/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,421 | INFO  | [task-result-getter-1] | Removed TaskSet 15.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,422 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 15 (mapPartitions at GraphWriter.scala:253) finished in 32.946 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,422 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,422 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,423 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:10,423 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:12:48,181 | INFO  | [task-result-getter-0] | Finished task 43.0 in stage 13.0 (TID 936) in 110658 ms on dn07 (executor 14) (87/90) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,335 | INFO  | [dispatcher-event-loop-16] | Disabling executor 4. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,345 | INFO  | [dag-scheduler-event-loop] | Executor lost: 4 (epoch 8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,347 | INFO  | [dispatcher-event-loop-22] | Trying to remove executor 4 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,351 | INFO  | [dispatcher-event-loop-22] | Removing block manager BlockManagerId(4, dn32, 22787, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,352 | INFO  | [dag-scheduler-event-loop] | Removed 4 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,355 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 4 (epoch 8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,577 | INFO  | [Reporter] | Completed container container_e06_1595920838912_178438_01_000006 on host: dn32 (state: COMPLETE, exit status: 143) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,580 | WARN  | [Reporter] | Container marked as failed: container_e06_1595920838912_178438_01_000006 on host: dn32. Exit status: 143. Diagnostics: [2020-08-03 18:18:50.336]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:18:50.337]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:18:50.344]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,596 | WARN  | [dispatcher-event-loop-57] | Requesting driver to remove executor 4 for reason Container marked as failed: container_e06_1595920838912_178438_01_000006 on host: dn32. Exit status: 143. Diagnostics: [2020-08-03 18:18:50.336]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:18:50.337]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:18:50.344]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,615 | ERROR | [dispatcher-event-loop-39] | Lost executor 4 on dn32: Container marked as failed: container_e06_1595920838912_178438_01_000006 on host: dn32. Exit status: 143. Diagnostics: [2020-08-03 18:18:50.336]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:18:50.337]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:18:50.344]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:18:50,627 | INFO  | [dag-scheduler-event-loop] | Resubmitted ShuffleMapTask(13, 33), so marking it as still running | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,627 | INFO  | [dag-scheduler-event-loop] | Resubmitted ShuffleMapTask(13, 1), so marking it as still running | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,628 | WARN  | [dispatcher-event-loop-39] | Lost task 16.0 in stage 13.0 (TID 909, dn32, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container marked as failed: container_e06_1595920838912_178438_01_000006 on host: dn32. Exit status: 143. Diagnostics: [2020-08-03 18:18:50.336]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:18:50.337]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:18:50.344]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,637 | INFO  | [dispatcher-event-loop-29] | Trying to remove executor 4 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,637 | INFO  | [dispatcher-event-loop-39] | Removal of executor 4 requested | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,641 | INFO  | [dispatcher-event-loop-39] | Asked to remove non-existent executor 4 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,673 | INFO  | [dispatcher-event-loop-28] | Starting task 16.1 in stage 13.0 (TID 1084, dn20, executor 13, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,673 | INFO  | [dispatcher-event-loop-28] | Starting task 1.1 in stage 13.0 (TID 1085, dn36, executor 20, partition 1, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,674 | INFO  | [dispatcher-event-loop-28] | Starting task 33.1 in stage 13.0 (TID 1086, dn08, executor 16, partition 33, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,687 | INFO  | [dispatcher-event-loop-25] | Asked to send map output locations for shuffle 3 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,687 | INFO  | [dispatcher-event-loop-24] | Asked to send map output locations for shuffle 3 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,690 | INFO  | [dispatcher-event-loop-4] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,719 | WARN  | [task-result-getter-3] | Lost task 16.1 in stage 13.0 (TID 1084, dn20, executor 13): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=16, message=																																																																		
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,723 | INFO  | [task-result-getter-3] | Task 16.1 in stage 13.0 (TID 1084) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,724 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,727 | WARN  | [task-result-getter-1] | Lost task 1.1 in stage 13.0 (TID 1085, dn36, executor 20): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=1, message=																																																																		
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,727 | INFO  | [task-result-getter-1] | Task 1.1 in stage 13.0 (TID 1085) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,730 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 473.471 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,733 | WARN  | [task-result-getter-2] | Lost task 33.1 in stage 13.0 (TID 1086, dn08, executor 16): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=33, message=																																																																		
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,733 | INFO  | [task-result-getter-2] | Task 33.1 in stage 13.0 (TID 1086) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,739 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,946 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,949 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,956 | INFO  | [dag-scheduler-event-loop] | Block broadcast_18 stored as values in memory (estimated size 31.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,965 | INFO  | [dag-scheduler-event-loop] | Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,965 | INFO  | [dispatcher-event-loop-43] | Added broadcast_18_piece0 in memory on dn37:22779 (size: 9.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,966 | INFO  | [dag-scheduler-event-loop] | Created broadcast 18 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,967 | INFO  | [dag-scheduler-event-loop] | Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(7, 34, 40, 44)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,967 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.1 with 4 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,971 | INFO  | [dispatcher-event-loop-47] | Starting task 0.0 in stage 12.1 (TID 1087, dn22, executor 5, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,971 | INFO  | [dispatcher-event-loop-47] | Starting task 3.0 in stage 12.1 (TID 1088, dn22, executor 5, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,994 | INFO  | [dispatcher-event-loop-41] | Added broadcast_18_piece0 in memory on dn22:22834 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,596 | INFO  | [Reporter] | Will request 1 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,597 | INFO  | [Reporter] | Submitted 1 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,805 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000022 on host dn32 for executor with ID 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,806 | INFO  | [Reporter] | Received 1 containers from YARN, launching executors on 1 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,674 | INFO  | [dispatcher-event-loop-44] | Starting task 1.0 in stage 12.1 (TID 1089, dn34, executor 6, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,675 | INFO  | [dispatcher-event-loop-44] | Starting task 2.0 in stage 12.1 (TID 1090, dn27, executor 7, partition 40, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,693 | INFO  | [dispatcher-event-loop-60] | Added broadcast_18_piece0 in memory on dn34:22620 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,708 | INFO  | [dispatcher-event-loop-54] | Added broadcast_18_piece0 in memory on dn27:22790 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:57,338 | INFO  | [dispatcher-event-loop-52] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.40:42962 with ID 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:57,485 | INFO  | [dispatcher-event-loop-36] | Registering block manager dn32:22662 with 5.2 GB RAM, 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:02,898 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 12.1 (TID 1087) in 11927 ms on dn22 (executor 5) (1/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:03,489 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 12.1 (TID 1088) in 12518 ms on dn22 (executor 5) (2/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,196 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 12.1 (TID 1089) in 12522 ms on dn34 (executor 6) (3/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 12.1 (TID 1090) in 12596 ms on dn27 (executor 7) (4/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [task-result-getter-2] | Removed TaskSet 12.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 16.319 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,273 | INFO  | [dag-scheduler-event-loop] | Reusing state from previous attempt of stage 13. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,274 | INFO  | [dag-scheduler-event-loop] | Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,276 | INFO  | [dag-scheduler-event-loop] | Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,277 | INFO  | [dispatcher-event-loop-13] | Added broadcast_19_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,278 | INFO  | [dag-scheduler-event-loop] | Created broadcast 19 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,278 | INFO  | [dag-scheduler-event-loop] | Submitting 5 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(1, 16, 24, 33, 44)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,278 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.1 with 5 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,280 | INFO  | [dispatcher-event-loop-29] | Starting task 0.0 in stage 13.1 (TID 1091, dn36, executor 20, partition 1, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,280 | INFO  | [dispatcher-event-loop-29] | Starting task 1.0 in stage 13.1 (TID 1092, dn22, executor 5, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,281 | INFO  | [dispatcher-event-loop-29] | Starting task 2.0 in stage 13.1 (TID 1093, dn08, executor 16, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,281 | INFO  | [dispatcher-event-loop-29] | Starting task 3.0 in stage 13.1 (TID 1094, dn28, executor 3, partition 33, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,281 | INFO  | [dispatcher-event-loop-29] | Starting task 4.0 in stage 13.1 (TID 1095, dn29, executor 1, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,295 | INFO  | [dispatcher-event-loop-49] | Added broadcast_19_piece0 in memory on dn08:22604 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,297 | INFO  | [dispatcher-event-loop-27] | Added broadcast_19_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,298 | INFO  | [dispatcher-event-loop-11] | Added broadcast_19_piece0 in memory on dn28:22784 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,300 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 3 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,302 | INFO  | [dispatcher-event-loop-43] | Added broadcast_19_piece0 in memory on dn22:22834 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,305 | INFO  | [dispatcher-event-loop-47] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,305 | INFO  | [dispatcher-event-loop-48] | Asked to send map output locations for shuffle 3 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,308 | INFO  | [dispatcher-event-loop-51] | Added broadcast_19_piece0 in memory on dn29:22705 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,310 | INFO  | [dispatcher-event-loop-41] | Asked to send map output locations for shuffle 3 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,313 | INFO  | [dispatcher-event-loop-35] | Asked to send map output locations for shuffle 4 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,318 | INFO  | [dispatcher-event-loop-33] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,320 | INFO  | [dispatcher-event-loop-52] | Asked to send map output locations for shuffle 4 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,324 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 4 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,340 | INFO  | [dispatcher-event-loop-63] | Asked to send map output locations for shuffle 3 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,349 | INFO  | [dispatcher-event-loop-70] | Asked to send map output locations for shuffle 4 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,396 | WARN  | [dispatcher-event-loop-43] | Removing executor 8 with no recent heartbeats: 372233 ms exceeds timeout 360000 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,400 | ERROR | [dispatcher-event-loop-43] | Lost executor 8 on dn37: Executor heartbeat timed out after 372233 ms | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:50,401 | WARN  | [dispatcher-event-loop-43] | Lost task 24.0 in stage 13.0 (TID 917, dn37, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 372233 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,404 | INFO  | [dag-scheduler-event-loop] | Executor lost: 8 (epoch 10) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,405 | INFO  | [dispatcher-event-loop-48] | Trying to remove executor 8 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,405 | WARN  | [dispatcher-event-loop-43] | Removing executor 19 with no recent heartbeats: 378363 ms exceeds timeout 360000 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,405 | ERROR | [dispatcher-event-loop-43] | Lost executor 19 on dn10: Executor heartbeat timed out after 378363 ms | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:50,406 | INFO  | [dispatcher-event-loop-48] | Removing block manager BlockManagerId(8, dn37, 22861, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,406 | WARN  | [dispatcher-event-loop-43] | Lost task 44.0 in stage 13.0 (TID 937, dn10, executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 378363 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,406 | INFO  | [dag-scheduler-event-loop] | Removed 8 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,406 | INFO  | [dispatcher-event-loop-43] | Removed TaskSet 13.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,407 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 8 (epoch 10) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,410 | INFO  | [dag-scheduler-event-loop] | Host added was in lost list earlier: dn37 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,411 | INFO  | [dag-scheduler-event-loop] | Executor lost: 19 (epoch 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,411 | INFO  | [dispatcher-event-loop-41] | Trying to remove executor 19 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,411 | INFO  | [kill-executor-thread] | Requesting to kill executor(s) 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,412 | INFO  | [dispatcher-event-loop-41] | Removing block manager BlockManagerId(19, dn10, 22719, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,412 | INFO  | [dag-scheduler-event-loop] | Removed 19 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,412 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 19 (epoch 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,413 | INFO  | [dag-scheduler-event-loop] | Host added was in lost list earlier: dn10 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,425 | INFO  | [kill-executor-thread] | Actual list of executor(s) to be killed is 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,429 | INFO  | [dispatcher-event-loop-36] | Driver requested to kill executor(s) 8. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,431 | INFO  | [kill-executor-thread] | Requesting to kill executor(s) 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,431 | INFO  | [kill-executor-thread] | Actual list of executor(s) to be killed is 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,432 | INFO  | [dispatcher-event-loop-64] | Driver requested to kill executor(s) 19. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,289 | INFO  | [Reporter] | Will request 2 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,290 | INFO  | [Reporter] | Submitted 2 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,501 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000024 on host dn01 for executor with ID 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,501 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000023 on host dn35 for executor with ID 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,502 | INFO  | [Reporter] | Received 2 containers from YARN, launching executors on 2 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,991 | INFO  | [dispatcher-event-loop-17] | Disabling executor 8. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,991 | INFO  | [dag-scheduler-event-loop] | Executor lost: 8 (epoch 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,992 | INFO  | [dispatcher-event-loop-14] | Trying to remove executor 8 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,992 | INFO  | [dag-scheduler-event-loop] | Removed 8 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,993 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 8 (epoch 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,993 | ERROR | [dispatcher-event-loop-62] | Lost executor 8 on dn37: Container container_e06_1595920838912_178438_01_000010 exited from explicit termination request. | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:54,152 | INFO  | [dispatcher-event-loop-18] | Disabling executor 19. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,153 | INFO  | [dag-scheduler-event-loop] | Executor lost: 19 (epoch 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,154 | ERROR | [dispatcher-event-loop-13] | Lost executor 19 on dn10: Container container_e06_1595920838912_178438_01_000019 exited from explicit termination request. | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:54,154 | INFO  | [dispatcher-event-loop-29] | Trying to remove executor 19 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,154 | INFO  | [dag-scheduler-event-loop] | Removed 19 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,155 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 19 (epoch 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,032 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@650e578d) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,034 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@56ead7c1) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,035 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2f6acf53) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,035 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@406e3f19) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1413038c) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@54d842bd) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1917e31c) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3cb28504) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,159 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2f19a16c) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,162 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4e07503f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,165 | ERROR | [dispatcher-event-loop-59] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@21d45cd) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,167 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3953d0b) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,168 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2e508000) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,169 | ERROR | [dispatcher-event-loop-60] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6b70610b) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,193 | INFO  | [dispatcher-event-loop-56] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.6:40176 with ID 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,318 | INFO  | [dispatcher-event-loop-3] | Registering block manager dn01:22647 with 5.2 GB RAM, 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,394 | INFO  | [dispatcher-event-loop-61] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.43:54148 with ID 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,527 | INFO  | [dispatcher-event-loop-8] | Registering block manager dn35:22898 with 5.2 GB RAM, 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:04,060 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@36f576dd) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,062 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@16a210a2) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,062 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@725018f8) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,066 | ERROR | [dispatcher-event-loop-39] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@506cf608) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,067 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49fbaf21) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,079 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1e38dd8d) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,080 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@acb95e5) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,080 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1499437e) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,172 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3986e960) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,173 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@30764d00) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,177 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6bf71a14) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,179 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49c90278) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,180 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@582ca5d5) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,191 | ERROR | [dispatcher-event-loop-11] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@63fe8dd0) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,075 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@67576937) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,076 | ERROR | [dispatcher-event-loop-60] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@496ee4dc) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,080 | ERROR | [dispatcher-event-loop-44] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@58437a31) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,081 | ERROR | [dispatcher-event-loop-56] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@96fa71d) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,087 | ERROR | [dispatcher-event-loop-3] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@77e2ec7f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,090 | ERROR | [dispatcher-event-loop-54] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c60384b) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,093 | ERROR | [dispatcher-event-loop-0] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3b7f4a9b) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,093 | ERROR | [dispatcher-event-loop-0] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6f1be856) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,183 | ERROR | [dispatcher-event-loop-71] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3815c388) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,184 | ERROR | [dispatcher-event-loop-71] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4d92721f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,188 | ERROR | [dispatcher-event-loop-8] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4b9dd228) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,197 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3b9b6ebd) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,197 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@50bc73c3) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,205 | ERROR | [dispatcher-event-loop-2] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@65bb5bf3) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,088 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6d47dc69) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,089 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3a20875c) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,093 | ERROR | [dispatcher-event-loop-38] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4a9ac5e2) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,095 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@75504f31) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,100 | ERROR | [dispatcher-event-loop-25] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@52d4a895) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,103 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6b395491) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,105 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@e2f017a) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,112 | ERROR | [dispatcher-event-loop-27] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4745c0ca) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,195 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@79996e57) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,195 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@757f0697) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,201 | ERROR | [dispatcher-event-loop-37] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4bee670c) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,207 | ERROR | [dispatcher-event-loop-42] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5326769c) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,210 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@50e92d91) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,220 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@539c5927) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,101 | ERROR | [dispatcher-event-loop-68] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@239e1f7a) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,103 | ERROR | [dispatcher-event-loop-0] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@24733115) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,105 | ERROR | [dispatcher-event-loop-61] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@153f2df1) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,107 | ERROR | [dispatcher-event-loop-71] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@31a3af99) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,114 | ERROR | [dispatcher-event-loop-8] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49ecea25) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,116 | ERROR | [dispatcher-event-loop-45] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1e82934b) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,119 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2d9f708c) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,124 | ERROR | [dispatcher-event-loop-2] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6f885ef1) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,206 | ERROR | [dispatcher-event-loop-1] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2a54ca24) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,207 | ERROR | [dispatcher-event-loop-1] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4e419e4c) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,211 | ERROR | [dispatcher-event-loop-15] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@246b9cd) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,218 | ERROR | [dispatcher-event-loop-17] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6ee39e8) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,224 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@39b85f10) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,242 | ERROR | [dispatcher-event-loop-7] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7f455ee7) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,114 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1b0f358) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,117 | ERROR | [dispatcher-event-loop-27] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@451ef3d6) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,118 | ERROR | [dispatcher-event-loop-11] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@47c045da) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,119 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@d02d41f) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,126 | ERROR | [dispatcher-event-loop-37] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@790debd6) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,128 | ERROR | [dispatcher-event-loop-42] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@795932cd) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,134 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@57a63e94) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,138 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@44fb2a03) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,217 | ERROR | [dispatcher-event-loop-49] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6155769c) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,226 | ERROR | [dispatcher-event-loop-51] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@248fe95) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,229 | ERROR | [dispatcher-event-loop-43] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@530271bb) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,230 | ERROR | [dispatcher-event-loop-43] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@84bbfcf) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,235 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5d837820) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,257 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7ae2e4ce) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,127 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@301b048e) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,130 | ERROR | [dispatcher-event-loop-2] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@46e73de) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,131 | ERROR | [dispatcher-event-loop-67] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@45a40b65) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,132 | ERROR | [dispatcher-event-loop-1] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1c144c12) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,141 | ERROR | [dispatcher-event-loop-15] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8af1988) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,145 | ERROR | [dispatcher-event-loop-17] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@23208c6e) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,146 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@76fedb38) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,159 | ERROR | [dispatcher-event-loop-7] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@39f766c) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,233 | ERROR | [dispatcher-event-loop-10] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@35e2f618) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,240 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2243fcaa) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,241 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@567008ff) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,241 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6e644e91) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,246 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@131cd195) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,267 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@40f8e127) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,139 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@480fdf32) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,143 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7dad4df5) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,143 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@558c5e69) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,145 | ERROR | [dispatcher-event-loop-51] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@259b3d86) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,156 | ERROR | [dispatcher-event-loop-41] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6ae409a0) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,159 | ERROR | [dispatcher-event-loop-43] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5bf852a1) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,160 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7b12087a) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,173 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2b6f4572) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,243 | ERROR | [dispatcher-event-loop-36] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@50b238a7) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,251 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6a453450) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,252 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@16c8c169) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,252 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@219d18f1) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,258 | ERROR | [dispatcher-event-loop-70] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@69b07f99) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,277 | ERROR | [dispatcher-event-loop-53] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4cee61a8) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,154 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@386a4b39) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,155 | ERROR | [dispatcher-event-loop-7] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@c5f258e) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,156 | ERROR | [dispatcher-event-loop-10] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@558e0558) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,157 | ERROR | [dispatcher-event-loop-10] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7a2c95b6) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,168 | ERROR | [dispatcher-event-loop-5] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6b591d15) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,169 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5d236b0d) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,171 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@59171d98) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,183 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6ae14d21) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,253 | ERROR | [dispatcher-event-loop-20] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1fe6070b) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,262 | ERROR | [dispatcher-event-loop-12] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@201ed922) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,267 | ERROR | [dispatcher-event-loop-21] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3f4cfd98) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,269 | ERROR | [dispatcher-event-loop-22] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2d6b4c96) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,270 | ERROR | [dispatcher-event-loop-22] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c881581) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,285 | ERROR | [dispatcher-event-loop-26] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6fd063e6) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,166 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@63bf3f54) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,169 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c3242ca) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,170 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@37995f70) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,174 | ERROR | [dispatcher-event-loop-64] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@484e26c9) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,179 | ERROR | [dispatcher-event-loop-63] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@76f3b3b6) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,180 | ERROR | [dispatcher-event-loop-63] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1db9bf35) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,182 | ERROR | [dispatcher-event-loop-70] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@29351abf) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,192 | ERROR | [dispatcher-event-loop-53] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2791f263) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,263 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@21154942) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,272 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@b7d1593) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,277 | ERROR | [dispatcher-event-loop-66] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@63b49459) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,284 | ERROR | [dispatcher-event-loop-55] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8c5b9e3) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,286 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7f363a77) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,294 | ERROR | [dispatcher-event-loop-59] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@35451f4d) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,179 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3bc550ae) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,180 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@aff1f96) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,182 | ERROR | [dispatcher-event-loop-20] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@470ca473) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,185 | ERROR | [dispatcher-event-loop-12] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@75802016) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,190 | ERROR | [dispatcher-event-loop-21] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@612c2759) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,192 | ERROR | [dispatcher-event-loop-32] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8d323f6) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,194 | ERROR | [dispatcher-event-loop-22] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@64c38080) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,199 | WARN  | [task-result-getter-0] | Lost task 0.0 in stage 13.1 (TID 1091, dn36, executor 20): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=4, reduceId=1, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:49,203 | ERROR | [dispatcher-event-loop-6] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7a9fc38d) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,204 | INFO  | [task-result-getter-0] | Task 0.0 in stage 13.1 (TID 1091) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,207 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,207 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 461.934 s due to org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,208 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,223 | WARN  | [task-result-getter-3] | Lost task 3.0 in stage 13.1 (TID 1094, dn28, executor 3): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=4, reduceId=33, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:49,225 | INFO  | [task-result-getter-3] | Task 3.0 in stage 13.1 (TID 1094) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,273 | ERROR | [dispatcher-event-loop-18] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7ff6aa06) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,283 | ERROR | [dispatcher-event-loop-13] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8c5a519) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,289 | ERROR | [dispatcher-event-loop-23] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@445c3f69) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,301 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@784df754) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,302 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@782c40ab) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,305 | ERROR | [dispatcher-event-loop-40] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@15f09f19) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,408 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,410 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,418 | INFO  | [dag-scheduler-event-loop] | Block broadcast_20 stored as values in memory (estimated size 31.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,422 | INFO  | [dag-scheduler-event-loop] | Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,423 | INFO  | [dispatcher-event-loop-28] | Added broadcast_20_piece0 in memory on dn37:22779 (size: 9.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,424 | INFO  | [dag-scheduler-event-loop] | Created broadcast 20 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,425 | INFO  | [dag-scheduler-event-loop] | Submitting 8 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(4, 30, 31, 43, 54, 55, 64, 77)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,425 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.2 with 8 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,428 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 10 (MapPartitionsRDD[30] at distinct at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,428 | INFO  | [dispatcher-event-loop-38] | Starting task 7.0 in stage 12.2 (TID 1096, dn15, executor 12, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,429 | INFO  | [dispatcher-event-loop-38] | Starting task 2.0 in stage 12.2 (TID 1097, dn22, executor 5, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,429 | INFO  | [dispatcher-event-loop-38] | Starting task 4.0 in stage 12.2 (TID 1098, dn14, executor 17, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,430 | INFO  | [dispatcher-event-loop-38] | Starting task 1.0 in stage 12.2 (TID 1099, dn29, executor 1, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,430 | INFO  | [dispatcher-event-loop-38] | Starting task 3.0 in stage 12.2 (TID 1100, dn34, executor 6, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,431 | INFO  | [dispatcher-event-loop-38] | Starting task 6.0 in stage 12.2 (TID 1101, dn17, executor 18, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,431 | INFO  | [dag-scheduler-event-loop] | Block broadcast_21 stored as values in memory (estimated size 31.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,431 | INFO  | [dispatcher-event-loop-38] | Starting task 0.0 in stage 12.2 (TID 1102, dn24, executor 9, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,434 | INFO  | [dag-scheduler-event-loop] | Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,435 | INFO  | [dispatcher-event-loop-30] | Added broadcast_21_piece0 in memory on dn37:22779 (size: 10.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,435 | INFO  | [dag-scheduler-event-loop] | Created broadcast 21 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,446 | INFO  | [dag-scheduler-event-loop] | Submitting 11 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[30] at distinct at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(7, 30, 31, 39, 40, 43, 44, 47, 49, 55, 64)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,446 | INFO  | [dag-scheduler-event-loop] | Adding task set 10.1 with 11 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,449 | INFO  | [dispatcher-event-loop-25] | Starting task 8.0 in stage 10.1 (TID 1103, dn35, executor 23, partition 49, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,449 | INFO  | [dispatcher-event-loop-25] | Starting task 7.0 in stage 10.1 (TID 1104, dn27, executor 7, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,450 | INFO  | [dispatcher-event-loop-25] | Starting task 3.0 in stage 10.1 (TID 1105, dn01, executor 22, partition 39, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,450 | INFO  | [dispatcher-event-loop-25] | Starting task 5.0 in stage 10.1 (TID 1106, dn34, executor 6, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,451 | INFO  | [dispatcher-event-loop-25] | Starting task 10.0 in stage 10.1 (TID 1107, dn17, executor 18, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,451 | INFO  | [dispatcher-event-loop-25] | Starting task 0.0 in stage 10.1 (TID 1108, dn32, executor 21, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,451 | INFO  | [dispatcher-event-loop-25] | Starting task 4.0 in stage 10.1 (TID 1109, dn32, executor 21, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,454 | INFO  | [dispatcher-event-loop-35] | Added broadcast_20_piece0 in memory on dn24:22839 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,454 | INFO  | [dispatcher-event-loop-35] | Added broadcast_20_piece0 in memory on dn29:22705 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,459 | INFO  | [dispatcher-event-loop-64] | Added broadcast_20_piece0 in memory on dn17:22761 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,460 | INFO  | [dispatcher-event-loop-64] | Added broadcast_20_piece0 in memory on dn14:22891 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,460 | INFO  | [dispatcher-event-loop-64] | Added broadcast_20_piece0 in memory on dn34:22620 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,468 | INFO  | [dispatcher-event-loop-66] | Added broadcast_20_piece0 in memory on dn15:22640 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,468 | INFO  | [dispatcher-event-loop-66] | Added broadcast_21_piece0 in memory on dn34:22620 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,469 | INFO  | [dispatcher-event-loop-66] | Added broadcast_21_piece0 in memory on dn17:22761 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,495 | INFO  | [dispatcher-event-loop-65] | Added broadcast_21_piece0 in memory on dn27:22790 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,546 | INFO  | [dispatcher-event-loop-54] | Added broadcast_20_piece0 in memory on dn22:22834 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,729 | INFO  | [dispatcher-event-loop-8] | Added broadcast_21_piece0 in memory on dn01:22647 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,786 | INFO  | [dispatcher-event-loop-45] | Added broadcast_21_piece0 in memory on dn35:22898 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,794 | INFO  | [dispatcher-event-loop-9] | Added broadcast_21_piece0 in memory on dn32:22662 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:50,124 | INFO  | [dispatcher-event-loop-1] | Added broadcast_3_piece0 in memory on dn01:22647 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:50,181 | INFO  | [dispatcher-event-loop-17] | Added broadcast_3_piece0 in memory on dn35:22898 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:50,195 | INFO  | [dispatcher-event-loop-31] | Added broadcast_3_piece0 in memory on dn32:22662 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,673 | INFO  | [dispatcher-event-loop-23] | Starting task 1.0 in stage 10.1 (TID 1110, dn01, executor 22, partition 30, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,674 | INFO  | [dispatcher-event-loop-23] | Starting task 2.0 in stage 10.1 (TID 1111, dn18, executor 10, partition 31, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,674 | INFO  | [dispatcher-event-loop-23] | Starting task 6.0 in stage 10.1 (TID 1112, dn19, executor 11, partition 44, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,674 | INFO  | [dispatcher-event-loop-23] | Starting task 9.0 in stage 10.1 (TID 1113, dn28, executor 3, partition 55, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,675 | INFO  | [dispatcher-event-loop-23] | Starting task 5.0 in stage 12.2 (TID 1114, dn18, executor 10, partition 55, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,693 | INFO  | [dispatcher-event-loop-27] | Added broadcast_21_piece0 in memory on dn28:22784 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,701 | INFO  | [dispatcher-event-loop-11] | Added broadcast_21_piece0 in memory on dn19:22830 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,771 | INFO  | [dispatcher-event-loop-37] | Added broadcast_21_piece0 in memory on dn18:22756 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,784 | INFO  | [dispatcher-event-loop-47] | Added broadcast_20_piece0 in memory on dn18:22756 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,195 | ERROR | [dispatcher-event-loop-36] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@61d8632e) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,205 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@503743fa) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,208 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c36ea73) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,211 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4e9fe16e) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,215 | ERROR | [dispatcher-event-loop-63] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2203ea9f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,218 | ERROR | [dispatcher-event-loop-70] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3620df54) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,277 | WARN  | [task-result-getter-1] | Lost task 2.0 in stage 13.1 (TID 1093, dn08, executor 16): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=55, reduceId=24, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:54,278 | INFO  | [task-result-getter-1] | Task 2.0 in stage 13.1 (TID 1093) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,278 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,294 | ERROR | [dispatcher-event-loop-53] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@42351890) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,297 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7616a5c8) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,301 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5dcbedf) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,308 | WARN  | [task-result-getter-2] | Lost task 4.0 in stage 13.1 (TID 1095, dn29, executor 1): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=4, reduceId=44, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:54,309 | INFO  | [task-result-getter-2] | Task 4.0 in stage 13.1 (TID 1095) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,315 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3e1fb1d2) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,317 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@73c171ec) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,378 | WARN  | [task-result-getter-0] | Lost task 1.0 in stage 13.1 (TID 1092, dn22, executor 5): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=55, reduceId=16, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:54,378 | INFO  | [task-result-getter-0] | Task 1.0 in stage 13.1 (TID 1092) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,378 | INFO  | [task-result-getter-0] | Removed TaskSet 13.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,480 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:59,341 | INFO  | [task-result-getter-3] | Finished task 10.0 in stage 10.1 (TID 1107) in 9890 ms on dn17 (executor 18) (1/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:59,401 | INFO  | [task-result-getter-1] | Finished task 7.0 in stage 10.1 (TID 1104) in 9952 ms on dn27 (executor 7) (2/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:59,558 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 10.1 (TID 1106) in 10108 ms on dn34 (executor 6) (3/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:00,477 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 12.2 (TID 1102) in 11046 ms on dn24 (executor 9) (1/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:00,832 | INFO  | [task-result-getter-3] | Finished task 1.0 in stage 12.2 (TID 1099) in 11402 ms on dn29 (executor 1) (2/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,272 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 10.1 (TID 1111) in 8599 ms on dn18 (executor 10) (4/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,334 | INFO  | [task-result-getter-2] | Finished task 3.0 in stage 10.1 (TID 1105) in 11884 ms on dn01 (executor 22) (5/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,358 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 10.1 (TID 1110) in 8685 ms on dn01 (executor 22) (6/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,360 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 12.2 (TID 1096) in 11933 ms on dn15 (executor 12) (3/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,493 | INFO  | [task-result-getter-1] | Finished task 8.0 in stage 10.1 (TID 1103) in 12045 ms on dn35 (executor 23) (7/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,563 | INFO  | [task-result-getter-2] | Finished task 6.0 in stage 12.2 (TID 1101) in 12132 ms on dn17 (executor 18) (4/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,574 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 10.1 (TID 1108) in 12123 ms on dn32 (executor 21) (8/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,636 | INFO  | [task-result-getter-3] | Finished task 4.0 in stage 12.2 (TID 1098) in 12207 ms on dn14 (executor 17) (5/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,696 | INFO  | [task-result-getter-1] | Finished task 3.0 in stage 12.2 (TID 1100) in 12266 ms on dn34 (executor 6) (6/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,842 | INFO  | [task-result-getter-2] | Finished task 4.0 in stage 10.1 (TID 1109) in 12391 ms on dn32 (executor 21) (9/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,870 | INFO  | [task-result-getter-0] | Finished task 2.0 in stage 12.2 (TID 1097) in 12441 ms on dn22 (executor 5) (7/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,568 | INFO  | [task-result-getter-3] | Finished task 9.0 in stage 10.1 (TID 1113) in 9893 ms on dn28 (executor 3) (10/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,723 | INFO  | [task-result-getter-1] | Finished task 6.0 in stage 10.1 (TID 1112) in 10049 ms on dn19 (executor 11) (11/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,724 | INFO  | [task-result-getter-1] | Removed TaskSet 10.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,724 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 10 (distinct at GraphWriter.scala:253) finished in 13.295 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13, ShuffleMapStage 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,726 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 11 (MapPartitionsRDD[33] at mapPartitions at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,729 | INFO  | [dag-scheduler-event-loop] | Block broadcast_22 stored as values in memory (estimated size 7.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,735 | INFO  | [dag-scheduler-event-loop] | Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,735 | INFO  | [dispatcher-event-loop-58] | Added broadcast_22_piece0 in memory on dn37:22779 (size: 4.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,736 | INFO  | [dag-scheduler-event-loop] | Created broadcast 22 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,737 | INFO  | [dag-scheduler-event-loop] | Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[33] at mapPartitions at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(77)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,737 | INFO  | [dag-scheduler-event-loop] | Adding task set 11.1 with 1 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,738 | INFO  | [dispatcher-event-loop-63] | Starting task 0.0 in stage 11.1 (TID 1115, dn14, executor 17, partition 77, NODE_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,757 | INFO  | [dispatcher-event-loop-53] | Added broadcast_22_piece0 in memory on dn14:22891 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,761 | INFO  | [dispatcher-event-loop-46] | Asked to send map output locations for shuffle 7 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,924 | INFO  | [task-result-getter-2] | Finished task 0.0 in stage 11.1 (TID 1115) in 186 ms on dn14 (executor 17) (1/1) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,925 | INFO  | [task-result-getter-2] | Removed TaskSet 11.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,925 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 11 (mapPartitions at GraphWriter.scala:253) finished in 0.197 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,639 | INFO  | [task-result-getter-0] | Finished task 5.0 in stage 12.2 (TID 1114) in 10964 ms on dn18 (executor 10) (8/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,639 | INFO  | [task-result-getter-0] | Removed TaskSet 12.2, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,640 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 14.227 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,640 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,642 | INFO  | [dag-scheduler-event-loop] | Reusing state from previous attempt of stage 13. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,644 | INFO  | [dag-scheduler-event-loop] | Block broadcast_23 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,649 | INFO  | [dag-scheduler-event-loop] | Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,650 | INFO  | [dispatcher-event-loop-65] | Added broadcast_23_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,651 | INFO  | [dag-scheduler-event-loop] | Created broadcast 23 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,652 | INFO  | [dag-scheduler-event-loop] | Submitting 9 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(1, 10, 11, 16, 24, 25, 33, 34, 44)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,652 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.2 with 9 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,653 | INFO  | [dispatcher-event-loop-60] | Starting task 0.0 in stage 13.2 (TID 1116, dn24, executor 9, partition 1, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,654 | INFO  | [dispatcher-event-loop-60] | Starting task 1.0 in stage 13.2 (TID 1117, dn01, executor 22, partition 10, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,654 | INFO  | [dispatcher-event-loop-60] | Starting task 2.0 in stage 13.2 (TID 1118, dn34, executor 6, partition 11, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,655 | INFO  | [dispatcher-event-loop-60] | Starting task 3.0 in stage 13.2 (TID 1119, dn28, executor 3, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,655 | INFO  | [dispatcher-event-loop-60] | Starting task 4.0 in stage 13.2 (TID 1120, dn35, executor 23, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,655 | INFO  | [dispatcher-event-loop-60] | Starting task 5.0 in stage 13.2 (TID 1121, dn19, executor 11, partition 25, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,656 | INFO  | [dispatcher-event-loop-60] | Starting task 6.0 in stage 13.2 (TID 1122, dn36, executor 20, partition 33, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,656 | INFO  | [dispatcher-event-loop-60] | Starting task 7.0 in stage 13.2 (TID 1123, dn27, executor 7, partition 34, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,657 | INFO  | [dispatcher-event-loop-60] | Starting task 8.0 in stage 13.2 (TID 1124, dn08, executor 16, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,669 | INFO  | [dispatcher-event-loop-17] | Added broadcast_23_piece0 in memory on dn24:22839 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,669 | INFO  | [dispatcher-event-loop-17] | Added broadcast_23_piece0 in memory on dn08:22604 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,670 | INFO  | [dispatcher-event-loop-7] | Added broadcast_23_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,672 | INFO  | [dispatcher-event-loop-10] | Added broadcast_23_piece0 in memory on dn19:22830 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,673 | INFO  | [dispatcher-event-loop-5] | Added broadcast_23_piece0 in memory on dn28:22784 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,673 | INFO  | [dispatcher-event-loop-5] | Added broadcast_23_piece0 in memory on dn27:22790 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,675 | INFO  | [dispatcher-event-loop-16] | Asked to send map output locations for shuffle 3 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,676 | INFO  | [dispatcher-event-loop-20] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,680 | INFO  | [dispatcher-event-loop-21] | Asked to send map output locations for shuffle 3 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,680 | INFO  | [dispatcher-event-loop-32] | Asked to send map output locations for shuffle 3 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,681 | INFO  | [dispatcher-event-loop-22] | Asked to send map output locations for shuffle 3 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,681 | INFO  | [dispatcher-event-loop-26] | Asked to send map output locations for shuffle 3 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,684 | INFO  | [dispatcher-event-loop-6] | Added broadcast_23_piece0 in memory on dn34:22620 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,685 | INFO  | [dispatcher-event-loop-57] | Asked to send map output locations for shuffle 4 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,686 | INFO  | [dispatcher-event-loop-18] | Asked to send map output locations for shuffle 4 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,690 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,693 | INFO  | [dispatcher-event-loop-23] | Asked to send map output locations for shuffle 4 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,693 | INFO  | [dispatcher-event-loop-39] | Asked to send map output locations for shuffle 4 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,694 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 4 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,707 | INFO  | [dispatcher-event-loop-28] | Added broadcast_23_piece0 in memory on dn01:22647 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,709 | INFO  | [dispatcher-event-loop-38] | Asked to send map output locations for shuffle 3 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,725 | INFO  | [dispatcher-event-loop-30] | Asked to send map output locations for shuffle 4 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,730 | INFO  | [dispatcher-event-loop-24] | Added broadcast_23_piece0 in memory on dn35:22898 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,750 | INFO  | [dispatcher-event-loop-34] | Asked to send map output locations for shuffle 3 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,752 | INFO  | [dispatcher-event-loop-27] | Asked to send map output locations for shuffle 3 to *.*.132.43:54148 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,792 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 13.2 (TID 1116) in 139 ms on dn24 (executor 9) (1/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,793 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 13.2 (TID 1118) in 139 ms on dn34 (executor 6) (2/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,852 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 13.2 (TID 1121) in 197 ms on dn19 (executor 11) (3/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,877 | INFO  | [dispatcher-event-loop-49] | Asked to send map output locations for shuffle 4 to *.*.132.43:54148 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:04,227 | INFO  | [dispatcher-event-loop-48] | Asked to send map output locations for shuffle 4 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:05,242 | INFO  | [task-result-getter-0] | Finished task 6.0 in stage 13.2 (TID 1122) in 1586 ms on dn36 (executor 20) (4/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:06,259 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 13.2 (TID 1123) in 2603 ms on dn27 (executor 7) (5/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:15,885 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 13.2 (TID 1117) in 12231 ms on dn01 (executor 22) (6/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,415 | INFO  | [dispatcher-event-loop-8] | Disabling executor 23. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,417 | INFO  | [dag-scheduler-event-loop] | Executor lost: 23 (epoch 22) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,417 | INFO  | [dispatcher-event-loop-14] | Trying to remove executor 23 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,418 | INFO  | [dispatcher-event-loop-14] | Removing block manager BlockManagerId(23, dn35, 22898, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,418 | INFO  | [dag-scheduler-event-loop] | Removed 23 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,419 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 23 (epoch 22) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,621 | INFO  | [Reporter] | Completed container container_e06_1595920838912_178438_01_000023 on host: dn35 (state: COMPLETE, exit status: 143) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,621 | WARN  | [Reporter] | Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:36:49,622 | WARN  | [dispatcher-event-loop-19] | Requesting driver to remove executor 23 for reason Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:36:49,624 | ERROR | [dispatcher-event-loop-5] | Lost executor 23 on dn35: Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:36:49,625 | WARN  | [dispatcher-event-loop-5] | Lost task 4.0 in stage 13.2 (TID 1120, dn35, executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:36:49,626 | INFO  | [dispatcher-event-loop-5] | Removal of executor 23 requested | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,626 | INFO  | [dispatcher-event-loop-20] | Trying to remove executor 23 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,626 | INFO  | [dispatcher-event-loop-5] | Asked to remove non-existent executor 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,673 | INFO  | [dispatcher-event-loop-21] | Starting task 4.1 in stage 13.2 (TID 1125, dn17, executor 18, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,714 | INFO  | [dispatcher-event-loop-26] | Added broadcast_23_piece0 in memory on dn17:22761 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,736 | INFO  | [dispatcher-event-loop-6] | Asked to send map output locations for shuffle 3 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,743 | INFO  | [dispatcher-event-loop-57] | Asked to send map output locations for shuffle 4 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,622 | INFO  | [Reporter] | Will request 1 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,623 | INFO  | [Reporter] | Submitted 1 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,828 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000025 on host dn23 for executor with ID 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,829 | INFO  | [Reporter] | Received 1 containers from YARN, launching executors on 1 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:37:00,182 | INFO  | [dispatcher-event-loop-24] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.31:36202 with ID 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:37:00,319 | INFO  | [dispatcher-event-loop-27] | Registering block manager dn23:22782 with 5.2 GB RAM, 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,390 | WARN  | [dispatcher-event-loop-48] | Removing executor 16 with no recent heartbeats: 368830 ms exceeds timeout 360000 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:40:50,393 | ERROR | [dispatcher-event-loop-48] | Lost executor 16 on dn08: Executor heartbeat timed out after 368830 ms | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:40:50,394 | WARN  | [dispatcher-event-loop-48] | Lost task 8.0 in stage 13.2 (TID 1124, dn08, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 368830 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:40:50,396 | INFO  | [dag-scheduler-event-loop] | Executor lost: 16 (epoch 23) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,396 | INFO  | [kill-executor-thread] | Requesting to kill executor(s) 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,396 | INFO  | [dispatcher-event-loop-41] | Trying to remove executor 16 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,397 | INFO  | [dispatcher-event-loop-51] | Starting task 8.1 in stage 13.2 (TID 1126, dn18, executor 10, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,397 | INFO  | [dispatcher-event-loop-41] | Removing block manager BlockManagerId(16, dn08, 22604, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,398 | INFO  | [dag-scheduler-event-loop] | Removed 16 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,398 | INFO  | [kill-executor-thread] | Actual list of executor(s) to be killed is 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,398 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 16 (epoch 23) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,399 | INFO  | [dispatcher-event-loop-43] | Driver requested to kill executor(s) 16. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,400 | INFO  | [dag-scheduler-event-loop] | Host added was in lost list earlier: dn08 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,422 | INFO  | [dispatcher-event-loop-63] | Added broadcast_23_piece0 in memory on dn18:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,430 | INFO  | [dispatcher-event-loop-70] | Asked to send map output locations for shuffle 3 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,457 | WARN  | [task-result-getter-2] | Lost task 8.1 in stage 13.2 (TID 1126, dn18, executor 10): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=44, message=																																																																		
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:40:50,458 | INFO  | [task-result-getter-2] | Task 8.1 in stage 13.2 (TID 1126) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,458 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,460 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 826.817 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,460 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,661 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,662 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,669 | INFO  | [dag-scheduler-event-loop] | Block broadcast_24 stored as values in memory (estimated size 31.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,674 | INFO  | [dag-scheduler-event-loop] | Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,675 | INFO  | [dispatcher-event-loop-46] | Added broadcast_24_piece0 in memory on dn37:22779 (size: 9.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,677 | INFO  | [dag-scheduler-event-loop] | Created broadcast 24 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,678 | INFO  | [dag-scheduler-event-loop] | Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(9, 38, 80, 81)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,678 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.3 with 4 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,680 | INFO  | [dispatcher-event-loop-33] | Starting task 0.0 in stage 12.3 (TID 1127, dn22, executor 5, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,681 | INFO  | [dispatcher-event-loop-33] | Starting task 3.0 in stage 12.3 (TID 1128, dn27, executor 7, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,681 | INFO  | [dispatcher-event-loop-33] | Starting task 1.0 in stage 12.3 (TID 1129, dn01, executor 22, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,702 | INFO  | [dispatcher-event-loop-60] | Added broadcast_24_piece0 in memory on dn22:22834 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,704 | INFO  | [dispatcher-event-loop-44] | Added broadcast_24_piece0 in memory on dn27:22790 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,723 | INFO  | [dispatcher-event-loop-56] | Added broadcast_24_piece0 in memory on dn01:22647 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,053 | INFO  | [Reporter] | Will request 1 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,054 | INFO  | [Reporter] | Submitted 1 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,264 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000026 on host dn03 for executor with ID 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,265 | INFO  | [Reporter] | Received 1 containers from YARN, launching executors on 1 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:54,673 | INFO  | [dispatcher-event-loop-45] | Starting task 2.0 in stage 12.3 (TID 1130, dn15, executor 12, partition 80, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:54,799 | INFO  | [dispatcher-event-loop-14] | Added broadcast_24_piece0 in memory on dn15:22640 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,287 | INFO  | [dispatcher-event-loop-6] | Disabling executor 16. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,287 | INFO  | [dag-scheduler-event-loop] | Executor lost: 16 (epoch 24) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,288 | INFO  | [dispatcher-event-loop-28] | Trying to remove executor 16 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,288 | INFO  | [dag-scheduler-event-loop] | Removed 16 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,288 | ERROR | [dispatcher-event-loop-6] | Lost executor 16 on dn08: Container container_e06_1595920838912_178438_01_000018 exited from explicit termination request. | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:40:55,288 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 16 (epoch 24) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:00,318 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@f5cf819) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:00,324 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6a1fb534) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:00,760 | INFO  | [dispatcher-event-loop-21] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.8:51824 with ID 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:00,894 | INFO  | [dispatcher-event-loop-40] | Registering block manager dn03:22878 with 5.2 GB RAM, 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:01,853 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 12.3 (TID 1129) in 11172 ms on dn01 (executor 22) (1/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:02,806 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 12.3 (TID 1128) in 12126 ms on dn27 (executor 7) (2/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:02,808 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 12.3 (TID 1127) in 12128 ms on dn22 (executor 5) (3/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:05,338 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@41ee52dc) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:05,342 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@14c155ac) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:06,874 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 12.3 (TID 1130) in 12202 ms on dn15 (executor 12) (4/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [task-result-getter-2] | Removed TaskSet 12.3, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 16.211 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,876 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,876 | INFO  | [dag-scheduler-event-loop] | Reusing state from previous attempt of stage 13. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,877 | INFO  | [dag-scheduler-event-loop] | Block broadcast_25 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,879 | INFO  | [dag-scheduler-event-loop] | Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,880 | INFO  | [dispatcher-event-loop-44] | Added broadcast_25_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,880 | INFO  | [dag-scheduler-event-loop] | Created broadcast 25 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,881 | INFO  | [dag-scheduler-event-loop] | Submitting 13 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(6, 16, 20, 24, 36, 44, 53, 57, 62, 64, 70, 71, 73)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,881 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.3 with 13 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 0.0 in stage 13.3 (TID 1131, dn17, executor 18, partition 6, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 1.0 in stage 13.3 (TID 1132, dn36, executor 20, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 2.0 in stage 13.3 (TID 1133, dn34, executor 6, partition 20, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 3.0 in stage 13.3 (TID 1134, dn19, executor 11, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 4.0 in stage 13.3 (TID 1135, dn20, executor 13, partition 36, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 5.0 in stage 13.3 (TID 1136, dn15, executor 12, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 6.0 in stage 13.3 (TID 1137, dn18, executor 10, partition 53, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 7.0 in stage 13.3 (TID 1138, dn01, executor 22, partition 57, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 8.0 in stage 13.3 (TID 1139, dn32, executor 21, partition 62, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 9.0 in stage 13.3 (TID 1140, dn14, executor 17, partition 64, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 10.0 in stage 13.3 (TID 1141, dn29, executor 1, partition 70, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 11.0 in stage 13.3 (TID 1142, dn27, executor 7, partition 71, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 12.0 in stage 13.3 (TID 1143, dn22, executor 5, partition 73, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,893 | INFO  | [dispatcher-event-loop-62] | Added broadcast_25_piece0 in memory on dn18:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,893 | INFO  | [dispatcher-event-loop-62] | Added broadcast_25_piece0 in memory on dn15:22640 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,896 | INFO  | [dispatcher-event-loop-5] | Added broadcast_25_piece0 in memory on dn34:22620 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,896 | INFO  | [dispatcher-event-loop-26] | Added broadcast_25_piece0 in memory on dn19:22830 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,897 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 3 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,898 | INFO  | [dispatcher-event-loop-22] | Asked to send map output locations for shuffle 3 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,899 | INFO  | [dispatcher-event-loop-18] | Added broadcast_25_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-21] | Added broadcast_25_piece0 in memory on dn20:22825 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-39] | Asked to send map output locations for shuffle 3 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 3 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-40] | Added broadcast_25_piece0 in memory on dn22:22834 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,903 | INFO  | [dispatcher-event-loop-38] | Added broadcast_25_piece0 in memory on dn27:22790 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,906 | INFO  | [dispatcher-event-loop-28] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,906 | INFO  | [dispatcher-event-loop-6] | Added broadcast_25_piece0 in memory on dn29:22705 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,906 | INFO  | [dispatcher-event-loop-6] | Added broadcast_25_piece0 in memory on dn17:22761 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,907 | INFO  | [dispatcher-event-loop-24] | Asked to send map output locations for shuffle 3 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,908 | INFO  | [dispatcher-event-loop-27] | Added broadcast_25_piece0 in memory on dn14:22891 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,908 | INFO  | [dispatcher-event-loop-11] | Asked to send map output locations for shuffle 3 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,909 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 4 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,909 | INFO  | [dispatcher-event-loop-42] | Asked to send map output locations for shuffle 4 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,910 | INFO  | [dispatcher-event-loop-4] | Asked to send map output locations for shuffle 3 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,910 | INFO  | [dispatcher-event-loop-47] | Added broadcast_25_piece0 in memory on dn01:22647 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,914 | INFO  | [dispatcher-event-loop-49] | Asked to send map output locations for shuffle 4 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,914 | INFO  | [dispatcher-event-loop-41] | Asked to send map output locations for shuffle 3 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,914 | INFO  | [dispatcher-event-loop-48] | Asked to send map output locations for shuffle 3 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,918 | INFO  | [dispatcher-event-loop-51] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,921 | INFO  | [dispatcher-event-loop-25] | Asked to send map output locations for shuffle 3 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,931 | INFO  | [dispatcher-event-loop-43] | Asked to send map output locations for shuffle 4 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,931 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 3 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,939 | INFO  | [dispatcher-event-loop-52] | Asked to send map output locations for shuffle 4 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,951 | INFO  | [dispatcher-event-loop-58] | Asked to send map output locations for shuffle 4 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,959 | INFO  | [dispatcher-event-loop-63] | Asked to send map output locations for shuffle 4 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,961 | INFO  | [dispatcher-event-loop-70] | Asked to send map output locations for shuffle 4 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,962 | INFO  | [dispatcher-event-loop-33] | Asked to send map output locations for shuffle 4 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,963 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 13.3 (TID 1142) in 80 ms on dn27 (executor 7) (1/13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,964 | INFO  | [task-result-getter-3] | Finished task 9.0 in stage 13.3 (TID 1140) in 81 ms on dn14 (executor 17) (2/13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,971 | INFO  | [dispatcher-event-loop-66] | Asked to send map output locations for shuffle 4 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,971 | INFO  | [dispatcher-event-loop-64] | Asked to send map output locations for shuffle 4 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,988 | INFO  | [dispatcher-event-loop-50] | Added broadcast_25_piece0 in memory on dn32:22662 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:07,027 | INFO  | [dispatcher-event-loop-59] | Asked to send map output locations for shuffle 3 to *.*.132.40:42962 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:10,352 | ERROR | [dispatcher-event-loop-61] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@40e29f19) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:10,358 | ERROR | [dispatcher-event-loop-3] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4dde6589) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:15,365 | ERROR | [dispatcher-event-loop-40] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@786b36ab) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:15,379 | ERROR | [dispatcher-event-loop-38] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6f5b8691) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:20,383 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2f7a45a0) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:20,392 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@179c91f8) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:25,394 | ERROR | [dispatcher-event-loop-45] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2e91b20) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:25,404 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@11fd1745) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:30,405 | ERROR | [dispatcher-event-loop-6] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7f57ba6f) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:30,415 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49776c19) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:35,416 | ERROR | [dispatcher-event-loop-69] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@51f51a63) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:35,426 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@305c2ab5) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:40,427 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6fef34f8) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:40,438 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3d178c1) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:45,440 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7c04c06b) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:45,453 | ERROR | [dispatcher-event-loop-49] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@47da37fd) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:50,454 | ERROR | [dispatcher-event-loop-67] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@58085c07) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:50,466 | ERROR | [dispatcher-event-loop-56] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5e3cb996) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:51,654 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 345 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,655 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 459 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,661 | INFO  | [dispatcher-event-loop-15] | Removed broadcast_21_piece0 on dn37:22779 in memory (size: 10.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,663 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn34:22620 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,663 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn18:22756 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,664 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn17:22761 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,664 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn27:22790 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,671 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_21_piece0 on dn19:22830 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,691 | INFO  | [dispatcher-event-loop-8] | Removed broadcast_21_piece0 on dn01:22647 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,697 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_21_piece0 on dn32:22662 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:55,465 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5d1f5a93) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:55,476 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@cbeffb5) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:55,570 | WARN  | [task-result-getter-1] | Lost task 4.1 in stage 13.2 (TID 1125, dn17, executor 18): FetchFailed(BlockManagerId(16, dn08, 22604, None), shuffleId=3, mapId=9, reduceId=24, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn08/10.27.132.13:22604																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn08/10.27.132.13:22604																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn08/10.27.132.13:22604																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:41:55,571 | INFO  | [task-result-getter-1] | Task 4.1 in stage 13.2 (TID 1125) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:55,576 | INFO  | [dag-scheduler-event-loop] | Ignoring fetch failure from ShuffleMapTask(13, 24) as it's from ShuffleMapStage 13 attempt 2 and there is a more recent attempt for that stage (attempt 3) running | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,155 | INFO  | [dispatcher-event-loop-26] | Asked to send map output locations for shuffle 4 to *.*.132.40:42962 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,192 | WARN  | [task-result-getter-2] | Lost task 8.0 in stage 13.3 (TID 1139, dn32, executor 21): FetchFailed(BlockManagerId(3, dn28, 22784, None), shuffleId=3, mapId=2, reduceId=62, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260)																																																																	
	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	... 20 more																																																																	
Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276)																																																																	
	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256)																																																																	
	... 41 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:43:07,193 | INFO  | [task-result-getter-2] | Task 8.0 in stage 13.3 (TID 1139) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,193 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,196 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 120.320 s due to org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260)																																																																	
	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	... 20 more																																																																	
Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276)																																																																	
	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256)																																																																	
	... 41 more																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,217 | INFO  | [dag-scheduler-event-loop] | Executor lost: 3 (epoch 26) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,218 | INFO  | [dispatcher-event-loop-57] | Trying to remove executor 3 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,229 | WARN  | [dispatcher-event-loop-57] | No more replicas available for broadcast_21_piece0 ! | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:43:07,229 | INFO  | [Driver] | Job 7 failed: foreachPartition at GraphWriter.scala:485, took 1990.100705 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,231 | INFO  | [dispatcher-event-loop-57] | Removing block manager BlockManagerId(3, dn28, 22784, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,232 | INFO  | [dag-scheduler-event-loop] | Removed 3 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,232 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 3 (epoch 26) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,232 | ERROR | [Driver] | Job aborted due to stage failure: ShuffleMapStage 13 (map at GraphWriter.scala:266) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53) 	at org.apache.spark.scheduler.Task.run(Task.scala:110) 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260) 	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187) 	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121) 	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.immutable.List.foreach(List.scala:381) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137) 	... 20 more Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more  | com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:491)
org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 13 (map at GraphWriter.scala:266) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53) 	at org.apache.spark.scheduler.Task.run(Task.scala:110) 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260) 	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187) 	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121) 	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.immutable.List.foreach(List.scala:381) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137) 	... 20 more Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1705)																																																																	
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1693)																																																																	
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1692)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1692)																																																																	
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1402)																																																																	
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1923)																																																																	
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1875)																																																																	
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1864)																																																																	
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)																																																																	
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:683)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2047)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2068)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2112)																																																																	
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:959)																																																																	
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:957)																																																																	
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)																																																																	
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)																																																																	
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:387)																																																																	
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:957)																																																																	
	at com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:485)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData$.main(InsertData.scala:80)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData.main(InsertData.scala)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)																																																																	
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)																																																																	
	at java.lang.reflect.Method.invoke(Method.java:498)																																																																	
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:685)																																																																	
2020-08-03 18:43:07,237 | ERROR | [Driver] | User class threw exception: com.huawei.miner.operator.spark.common.data.api.SparkException: Load relation Failed!  Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more  | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																														
com.huawei.miner.operator.spark.common.data.api.SparkException: Load relation Failed!  Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more 																																																														
	at com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:493)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData$.main(InsertData.scala:80)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData.main(InsertData.scala)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)																																																																	
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)																																																																	
	at java.lang.reflect.Method.invoke(Method.java:498)																																																																	
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:685)																																																																	
2020-08-03 18:43:07,242 | INFO  | [Driver] | Final app status: FAILED, exitCode: 15, (reason: User class threw exception: com.huawei.miner.operator.spark.common.data.api.SparkException: Load relation Failed!  Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more 																																																														
	at com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:493)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData$.main(InsertData.scala:80)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData.main(InsertData.scala)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)																																																																	
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)																																																																	
	at java.lang.reflect.Method.invoke(Method.java:498)																																																																	
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:685)																																																																	
) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:09,974 | INFO  | [main] | Closing master protocol: MasterService | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeMasterService(ConnectionManager.java:2301)																																																																		
2020-08-03 18:43:09,977 | INFO  | [main] | Closing zookeeper sessionid=0x7f043dfb32fddba6 | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeZooKeeperWatcher(ConnectionManager.java:1765)																																																																		
2020-08-03 18:43:10,000 | INFO  | [Driver-EventThread] | EventThread shut down for session: 0x7f043dfb32fddba6 | org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:614)																																																																		
2020-08-03 18:43:10,002 | INFO  | [main] | Session: 0x7f043dfb32fddba6 closed | org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:1365)																																																																		
2020-08-03 18:43:10,014 | INFO  | [main] | clear hbaseStoreManger connection | org.janusgraph.diskstorage.hbase.HBaseStoreManager.close(HBaseStoreManager.java:424)																																																																		
2020-08-03 18:43:10,017 | INFO  | [main] | standardjanusgraph[hbase:[cn01, cn03, cn02]] with id: 0a1b842d221889-dn372 closed | org.janusgraph.graphdb.database.StandardJanusGraph.closeInternal(StandardJanusGraph.java:261)																																																																		
2020-08-03 18:43:10,028 | INFO  | [shutdown-hook-0] | Invoking stop() from shutdown hook | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:10,093 | INFO  | [shutdown-hook-0] | Stopped Spark@51511ed{HTTP/1.1,[http/1.1]}{10.27.132.45:22809} | org.spark_project.jetty.server.AbstractConnector.doStop(AbstractConnector.java:318)																																																																		
2020-08-03 18:43:10,099 | INFO  | [shutdown-hook-0] | Stopped Spark web UI at http://dn37:22809 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,667 | ERROR | [Spark Context Cleaner] | Error cleaning broadcast 21 | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout																																																																		
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)																																																																	
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)																																																																	
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)																																																																	
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:160)																																																																	
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)																																																																	
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)																																																																	
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)																																																																	
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)																																																																	
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)																																																																	
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)																																																																	
	at scala.Option.foreach(Option.scala:257)																																																																	
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)																																																																	
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1366)																																																																	
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)																																																																	
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)																																																																	
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]																																																																		
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)																																																																	
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)																																																																	
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)																																																																	
	... 12 more																																																																	
2020-08-03 18:43:51,679 | WARN  | [block-manager-ask-thread-pool-245] | Failed to remove broadcast 21 with removeFromMaster = true - Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:87)																																																																		
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout																																																																		
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)																																																																	
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)																																																																	
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)																																																																	
	at scala.util.Try$.apply(Try.scala:192)																																																																	
	at scala.util.Failure.recover(Try.scala:216)																																																																	
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)																																																																	
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)																																																																	
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)																																																																	
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)																																																																	
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)																																																																	
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)																																																																	
	at scala.concurrent.Promise$class.complete(Promise.scala:55)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)																																																																	
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)																																																																	
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)																																																																	
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)																																																																	
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)																																																																	
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)																																																																	
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)																																																																	
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)																																																																	
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)																																																																	
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)																																																																	
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)																																																																	
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:206)																																																																	
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:243)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)																																																																	
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from null in 120 seconds																																																																		
	... 8 more																																																																	
2020-08-03 18:43:51,792 | INFO  | [dispatcher-event-loop-18] | Driver requested a total number of 0 executor(s). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,795 | INFO  | [shutdown-hook-0] | Shutting down all executors | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,799 | INFO  | [dispatcher-event-loop-23] | Asking each executor to shut down | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,805 | INFO  | [shutdown-hook-0] | Stopping SchedulerExtensionServices																																																																		
(serviceOption=None,																																																																		
 services=List(),																																																																		
 started=false) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,819 | INFO  | [dispatcher-event-loop-40] | MapOutputTrackerMasterEndpoint stopped! | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,898 | INFO  | [shutdown-hook-0] | MemoryStore cleared | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,898 | INFO  | [shutdown-hook-0] | BlockManager stopped | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,900 | INFO  | [shutdown-hook-0] | BlockManagerMaster stopped | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,912 | INFO  | [dispatcher-event-loop-43] | OutputCommitCoordinator stopped! | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,919 | INFO  | [shutdown-hook-0] | Successfully stopped SparkContext | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,923 | INFO  | [shutdown-hook-0] | Shutdown hook called | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,926 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data6/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d27bd7b6-d232-44c3-9e49-35bee5906d85 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,926 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data10/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-930664e2-eef5-4c7c-97a8-cd37b41bee5a | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,927 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data1/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d77ca509-2c2f-44c1-a2dd-309b3d61f0ab | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,927 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data2/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-88482a74-d6bc-4033-aa1d-e6ddad05425c | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,928 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data5/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-e2e62513-0a5a-4f78-9b6a-553501864d7f | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,928 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d3ce3bf8-b134-4389-9038-e31c62781bd7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,928 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data4/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d6f07538-2eb2-4656-bd66-63226960b611 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,929 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data8/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-c62fab4b-c96d-4b6d-9690-6f02b59c191b | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,929 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data7/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-ee1c1dd3-6818-4c13-9030-9ae9c802b2a8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,930 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data9/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-ba6f81e7-b009-4394-9b1f-c2e074f4073d | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
