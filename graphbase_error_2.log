																																																																		
2020-08-03 18:18:50,727 | INFO  | [task-result-getter-1] | Task 1.1 in stage 13.0 (TID 1085) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,730 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 473.471 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,733 | WARN  | [task-result-getter-2] | Lost task 33.1 in stage 13.0 (TID 1086, dn08, executor 16): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=33, message=																																																																		
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:18:50,733 | INFO  | [task-result-getter-2] | Task 33.1 in stage 13.0 (TID 1086) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,739 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,946 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,949 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,956 | INFO  | [dag-scheduler-event-loop] | Block broadcast_18 stored as values in memory (estimated size 31.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,965 | INFO  | [dag-scheduler-event-loop] | Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,965 | INFO  | [dispatcher-event-loop-43] | Added broadcast_18_piece0 in memory on dn37:22779 (size: 9.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,966 | INFO  | [dag-scheduler-event-loop] | Created broadcast 18 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,967 | INFO  | [dag-scheduler-event-loop] | Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(7, 34, 40, 44)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,967 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.1 with 4 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,971 | INFO  | [dispatcher-event-loop-47] | Starting task 0.0 in stage 12.1 (TID 1087, dn22, executor 5, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,971 | INFO  | [dispatcher-event-loop-47] | Starting task 3.0 in stage 12.1 (TID 1088, dn22, executor 5, partition 44, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:50,994 | INFO  | [dispatcher-event-loop-41] | Added broadcast_18_piece0 in memory on dn22:22834 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,596 | INFO  | [Reporter] | Will request 1 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,597 | INFO  | [Reporter] | Submitted 1 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,805 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000022 on host dn32 for executor with ID 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:53,806 | INFO  | [Reporter] | Received 1 containers from YARN, launching executors on 1 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,674 | INFO  | [dispatcher-event-loop-44] | Starting task 1.0 in stage 12.1 (TID 1089, dn34, executor 6, partition 34, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,675 | INFO  | [dispatcher-event-loop-44] | Starting task 2.0 in stage 12.1 (TID 1090, dn27, executor 7, partition 40, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,693 | INFO  | [dispatcher-event-loop-60] | Added broadcast_18_piece0 in memory on dn34:22620 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:54,708 | INFO  | [dispatcher-event-loop-54] | Added broadcast_18_piece0 in memory on dn27:22790 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:57,338 | INFO  | [dispatcher-event-loop-52] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.40:42962 with ID 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:18:57,485 | INFO  | [dispatcher-event-loop-36] | Registering block manager dn32:22662 with 5.2 GB RAM, 21 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:02,898 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 12.1 (TID 1087) in 11927 ms on dn22 (executor 5) (1/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:03,489 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 12.1 (TID 1088) in 12518 ms on dn22 (executor 5) (2/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,196 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 12.1 (TID 1089) in 12522 ms on dn34 (executor 6) (3/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 12.1 (TID 1090) in 12596 ms on dn27 (executor 7) (4/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [task-result-getter-2] | Removed TaskSet 12.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 16.319 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,270 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,271 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,273 | INFO  | [dag-scheduler-event-loop] | Reusing state from previous attempt of stage 13. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,274 | INFO  | [dag-scheduler-event-loop] | Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,276 | INFO  | [dag-scheduler-event-loop] | Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,277 | INFO  | [dispatcher-event-loop-13] | Added broadcast_19_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,278 | INFO  | [dag-scheduler-event-loop] | Created broadcast 19 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,278 | INFO  | [dag-scheduler-event-loop] | Submitting 5 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(1, 16, 24, 33, 44)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,278 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.1 with 5 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,280 | INFO  | [dispatcher-event-loop-29] | Starting task 0.0 in stage 13.1 (TID 1091, dn36, executor 20, partition 1, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,280 | INFO  | [dispatcher-event-loop-29] | Starting task 1.0 in stage 13.1 (TID 1092, dn22, executor 5, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,281 | INFO  | [dispatcher-event-loop-29] | Starting task 2.0 in stage 13.1 (TID 1093, dn08, executor 16, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,281 | INFO  | [dispatcher-event-loop-29] | Starting task 3.0 in stage 13.1 (TID 1094, dn28, executor 3, partition 33, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,281 | INFO  | [dispatcher-event-loop-29] | Starting task 4.0 in stage 13.1 (TID 1095, dn29, executor 1, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,295 | INFO  | [dispatcher-event-loop-49] | Added broadcast_19_piece0 in memory on dn08:22604 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,297 | INFO  | [dispatcher-event-loop-27] | Added broadcast_19_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,298 | INFO  | [dispatcher-event-loop-11] | Added broadcast_19_piece0 in memory on dn28:22784 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,300 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 3 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,302 | INFO  | [dispatcher-event-loop-43] | Added broadcast_19_piece0 in memory on dn22:22834 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,305 | INFO  | [dispatcher-event-loop-47] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,305 | INFO  | [dispatcher-event-loop-48] | Asked to send map output locations for shuffle 3 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,308 | INFO  | [dispatcher-event-loop-51] | Added broadcast_19_piece0 in memory on dn29:22705 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,310 | INFO  | [dispatcher-event-loop-41] | Asked to send map output locations for shuffle 3 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,313 | INFO  | [dispatcher-event-loop-35] | Asked to send map output locations for shuffle 4 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,318 | INFO  | [dispatcher-event-loop-33] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,320 | INFO  | [dispatcher-event-loop-52] | Asked to send map output locations for shuffle 4 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,324 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 4 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,340 | INFO  | [dispatcher-event-loop-63] | Asked to send map output locations for shuffle 3 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:19:07,349 | INFO  | [dispatcher-event-loop-70] | Asked to send map output locations for shuffle 4 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,396 | WARN  | [dispatcher-event-loop-43] | Removing executor 8 with no recent heartbeats: 372233 ms exceeds timeout 360000 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,400 | ERROR | [dispatcher-event-loop-43] | Lost executor 8 on dn37: Executor heartbeat timed out after 372233 ms | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:50,401 | WARN  | [dispatcher-event-loop-43] | Lost task 24.0 in stage 13.0 (TID 917, dn37, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 372233 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,404 | INFO  | [dag-scheduler-event-loop] | Executor lost: 8 (epoch 10) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,405 | INFO  | [dispatcher-event-loop-48] | Trying to remove executor 8 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,405 | WARN  | [dispatcher-event-loop-43] | Removing executor 19 with no recent heartbeats: 378363 ms exceeds timeout 360000 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,405 | ERROR | [dispatcher-event-loop-43] | Lost executor 19 on dn10: Executor heartbeat timed out after 378363 ms | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:50,406 | INFO  | [dispatcher-event-loop-48] | Removing block manager BlockManagerId(8, dn37, 22861, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,406 | WARN  | [dispatcher-event-loop-43] | Lost task 44.0 in stage 13.0 (TID 937, dn10, executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 378363 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:25:50,406 | INFO  | [dag-scheduler-event-loop] | Removed 8 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,406 | INFO  | [dispatcher-event-loop-43] | Removed TaskSet 13.0, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,407 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 8 (epoch 10) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,410 | INFO  | [dag-scheduler-event-loop] | Host added was in lost list earlier: dn37 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,411 | INFO  | [dag-scheduler-event-loop] | Executor lost: 19 (epoch 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,411 | INFO  | [dispatcher-event-loop-41] | Trying to remove executor 19 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,411 | INFO  | [kill-executor-thread] | Requesting to kill executor(s) 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,412 | INFO  | [dispatcher-event-loop-41] | Removing block manager BlockManagerId(19, dn10, 22719, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,412 | INFO  | [dag-scheduler-event-loop] | Removed 19 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,412 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 19 (epoch 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,413 | INFO  | [dag-scheduler-event-loop] | Host added was in lost list earlier: dn10 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,425 | INFO  | [kill-executor-thread] | Actual list of executor(s) to be killed is 8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,429 | INFO  | [dispatcher-event-loop-36] | Driver requested to kill executor(s) 8. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,431 | INFO  | [kill-executor-thread] | Requesting to kill executor(s) 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,431 | INFO  | [kill-executor-thread] | Actual list of executor(s) to be killed is 19 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:50,432 | INFO  | [dispatcher-event-loop-64] | Driver requested to kill executor(s) 19. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,289 | INFO  | [Reporter] | Will request 2 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,290 | INFO  | [Reporter] | Submitted 2 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,501 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000024 on host dn01 for executor with ID 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,501 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000023 on host dn35 for executor with ID 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:51,502 | INFO  | [Reporter] | Received 2 containers from YARN, launching executors on 2 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,991 | INFO  | [dispatcher-event-loop-17] | Disabling executor 8. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,991 | INFO  | [dag-scheduler-event-loop] | Executor lost: 8 (epoch 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,992 | INFO  | [dispatcher-event-loop-14] | Trying to remove executor 8 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,992 | INFO  | [dag-scheduler-event-loop] | Removed 8 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,993 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 8 (epoch 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:53,993 | ERROR | [dispatcher-event-loop-62] | Lost executor 8 on dn37: Container container_e06_1595920838912_178438_01_000010 exited from explicit termination request. | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:54,152 | INFO  | [dispatcher-event-loop-18] | Disabling executor 19. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,153 | INFO  | [dag-scheduler-event-loop] | Executor lost: 19 (epoch 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,154 | ERROR | [dispatcher-event-loop-13] | Lost executor 19 on dn10: Container container_e06_1595920838912_178438_01_000019 exited from explicit termination request. | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:25:54,154 | INFO  | [dispatcher-event-loop-29] | Trying to remove executor 19 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,154 | INFO  | [dag-scheduler-event-loop] | Removed 19 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:54,155 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 19 (epoch 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,032 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@650e578d) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,034 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@56ead7c1) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,035 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2f6acf53) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,035 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@406e3f19) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1413038c) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@54d842bd) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1917e31c) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,038 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3cb28504) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,159 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2f19a16c) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,162 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4e07503f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,165 | ERROR | [dispatcher-event-loop-59] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@21d45cd) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,167 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3953d0b) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,168 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2e508000) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,169 | ERROR | [dispatcher-event-loop-60] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6b70610b) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:25:59,193 | INFO  | [dispatcher-event-loop-56] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.6:40176 with ID 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,318 | INFO  | [dispatcher-event-loop-3] | Registering block manager dn01:22647 with 5.2 GB RAM, 22 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,394 | INFO  | [dispatcher-event-loop-61] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.43:54148 with ID 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:25:59,527 | INFO  | [dispatcher-event-loop-8] | Registering block manager dn35:22898 with 5.2 GB RAM, 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:04,060 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@36f576dd) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,062 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@16a210a2) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,062 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@725018f8) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,066 | ERROR | [dispatcher-event-loop-39] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@506cf608) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,067 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49fbaf21) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,079 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1e38dd8d) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,080 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@acb95e5) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,080 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1499437e) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,172 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3986e960) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,173 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@30764d00) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,177 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6bf71a14) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,179 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49c90278) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,180 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@582ca5d5) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:04,191 | ERROR | [dispatcher-event-loop-11] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@63fe8dd0) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,075 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@67576937) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,076 | ERROR | [dispatcher-event-loop-60] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@496ee4dc) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,080 | ERROR | [dispatcher-event-loop-44] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@58437a31) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,081 | ERROR | [dispatcher-event-loop-56] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@96fa71d) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,087 | ERROR | [dispatcher-event-loop-3] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@77e2ec7f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,090 | ERROR | [dispatcher-event-loop-54] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c60384b) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,093 | ERROR | [dispatcher-event-loop-0] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3b7f4a9b) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,093 | ERROR | [dispatcher-event-loop-0] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6f1be856) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,183 | ERROR | [dispatcher-event-loop-71] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3815c388) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,184 | ERROR | [dispatcher-event-loop-71] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4d92721f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,188 | ERROR | [dispatcher-event-loop-8] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4b9dd228) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,197 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3b9b6ebd) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,197 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@50bc73c3) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:09,205 | ERROR | [dispatcher-event-loop-2] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@65bb5bf3) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,088 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6d47dc69) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,089 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3a20875c) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,093 | ERROR | [dispatcher-event-loop-38] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4a9ac5e2) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,095 | ERROR | [dispatcher-event-loop-30] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@75504f31) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,100 | ERROR | [dispatcher-event-loop-25] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@52d4a895) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,103 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6b395491) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,105 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@e2f017a) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,112 | ERROR | [dispatcher-event-loop-27] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4745c0ca) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,195 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@79996e57) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,195 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@757f0697) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,201 | ERROR | [dispatcher-event-loop-37] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4bee670c) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,207 | ERROR | [dispatcher-event-loop-42] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5326769c) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,210 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@50e92d91) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:14,220 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@539c5927) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,101 | ERROR | [dispatcher-event-loop-68] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@239e1f7a) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,103 | ERROR | [dispatcher-event-loop-0] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@24733115) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,105 | ERROR | [dispatcher-event-loop-61] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@153f2df1) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,107 | ERROR | [dispatcher-event-loop-71] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@31a3af99) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,114 | ERROR | [dispatcher-event-loop-8] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49ecea25) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,116 | ERROR | [dispatcher-event-loop-45] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1e82934b) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,119 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2d9f708c) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,124 | ERROR | [dispatcher-event-loop-2] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6f885ef1) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,206 | ERROR | [dispatcher-event-loop-1] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2a54ca24) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,207 | ERROR | [dispatcher-event-loop-1] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4e419e4c) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,211 | ERROR | [dispatcher-event-loop-15] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@246b9cd) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,218 | ERROR | [dispatcher-event-loop-17] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6ee39e8) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,224 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@39b85f10) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:19,242 | ERROR | [dispatcher-event-loop-7] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7f455ee7) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,114 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1b0f358) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,117 | ERROR | [dispatcher-event-loop-27] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@451ef3d6) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,118 | ERROR | [dispatcher-event-loop-11] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@47c045da) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,119 | ERROR | [dispatcher-event-loop-4] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@d02d41f) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,126 | ERROR | [dispatcher-event-loop-37] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@790debd6) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,128 | ERROR | [dispatcher-event-loop-42] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@795932cd) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,134 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@57a63e94) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,138 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@44fb2a03) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,217 | ERROR | [dispatcher-event-loop-49] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6155769c) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,226 | ERROR | [dispatcher-event-loop-51] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@248fe95) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,229 | ERROR | [dispatcher-event-loop-43] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@530271bb) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,230 | ERROR | [dispatcher-event-loop-43] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@84bbfcf) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,235 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5d837820) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:24,257 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7ae2e4ce) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,127 | ERROR | [dispatcher-event-loop-9] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@301b048e) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,130 | ERROR | [dispatcher-event-loop-2] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@46e73de) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,131 | ERROR | [dispatcher-event-loop-67] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@45a40b65) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,132 | ERROR | [dispatcher-event-loop-1] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1c144c12) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,141 | ERROR | [dispatcher-event-loop-15] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8af1988) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,145 | ERROR | [dispatcher-event-loop-17] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@23208c6e) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,146 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@76fedb38) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,159 | ERROR | [dispatcher-event-loop-7] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@39f766c) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,233 | ERROR | [dispatcher-event-loop-10] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@35e2f618) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,240 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2243fcaa) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,241 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@567008ff) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,241 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6e644e91) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,246 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@131cd195) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:29,267 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@40f8e127) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,139 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@480fdf32) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,143 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7dad4df5) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,143 | ERROR | [dispatcher-event-loop-48] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@558c5e69) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,145 | ERROR | [dispatcher-event-loop-51] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@259b3d86) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,156 | ERROR | [dispatcher-event-loop-41] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6ae409a0) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,159 | ERROR | [dispatcher-event-loop-43] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5bf852a1) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,160 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7b12087a) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,173 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2b6f4572) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,243 | ERROR | [dispatcher-event-loop-36] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@50b238a7) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,251 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6a453450) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,252 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@16c8c169) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,252 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@219d18f1) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,258 | ERROR | [dispatcher-event-loop-70] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@69b07f99) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:34,277 | ERROR | [dispatcher-event-loop-53] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4cee61a8) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,154 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@386a4b39) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,155 | ERROR | [dispatcher-event-loop-7] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@c5f258e) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,156 | ERROR | [dispatcher-event-loop-10] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@558e0558) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,157 | ERROR | [dispatcher-event-loop-10] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7a2c95b6) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,168 | ERROR | [dispatcher-event-loop-5] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6b591d15) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,169 | ERROR | [dispatcher-event-loop-14] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5d236b0d) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,171 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@59171d98) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,183 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6ae14d21) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,253 | ERROR | [dispatcher-event-loop-20] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1fe6070b) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,262 | ERROR | [dispatcher-event-loop-12] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@201ed922) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,267 | ERROR | [dispatcher-event-loop-21] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3f4cfd98) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,269 | ERROR | [dispatcher-event-loop-22] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2d6b4c96) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,270 | ERROR | [dispatcher-event-loop-22] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c881581) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:39,285 | ERROR | [dispatcher-event-loop-26] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6fd063e6) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,166 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@63bf3f54) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,169 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c3242ca) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,170 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@37995f70) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,174 | ERROR | [dispatcher-event-loop-64] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@484e26c9) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,179 | ERROR | [dispatcher-event-loop-63] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@76f3b3b6) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,180 | ERROR | [dispatcher-event-loop-63] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@1db9bf35) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,182 | ERROR | [dispatcher-event-loop-70] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@29351abf) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,192 | ERROR | [dispatcher-event-loop-53] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2791f263) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,263 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@21154942) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,272 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@b7d1593) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,277 | ERROR | [dispatcher-event-loop-66] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@63b49459) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,284 | ERROR | [dispatcher-event-loop-55] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8c5b9e3) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,286 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7f363a77) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:44,294 | ERROR | [dispatcher-event-loop-59] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@35451f4d) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,179 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3bc550ae) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,180 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@aff1f96) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,182 | ERROR | [dispatcher-event-loop-20] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@470ca473) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,185 | ERROR | [dispatcher-event-loop-12] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@75802016) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,190 | ERROR | [dispatcher-event-loop-21] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@612c2759) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,192 | ERROR | [dispatcher-event-loop-32] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8d323f6) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,194 | ERROR | [dispatcher-event-loop-22] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@64c38080) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,199 | WARN  | [task-result-getter-0] | Lost task 0.0 in stage 13.1 (TID 1091, dn36, executor 20): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=4, reduceId=1, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:49,203 | ERROR | [dispatcher-event-loop-6] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7a9fc38d) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,204 | INFO  | [task-result-getter-0] | Task 0.0 in stage 13.1 (TID 1091) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,207 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,207 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 461.934 s due to org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,208 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,223 | WARN  | [task-result-getter-3] | Lost task 3.0 in stage 13.1 (TID 1094, dn28, executor 3): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=4, reduceId=33, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:49,225 | INFO  | [task-result-getter-3] | Task 3.0 in stage 13.1 (TID 1094) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,273 | ERROR | [dispatcher-event-loop-18] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7ff6aa06) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,283 | ERROR | [dispatcher-event-loop-13] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@8c5a519) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,289 | ERROR | [dispatcher-event-loop-23] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@445c3f69) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,301 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@784df754) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,302 | ERROR | [dispatcher-event-loop-29] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.44:60542,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@782c40ab) from 10.27.132.44:60542																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,305 | ERROR | [dispatcher-event-loop-40] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@15f09f19) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:49,408 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,410 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,418 | INFO  | [dag-scheduler-event-loop] | Block broadcast_20 stored as values in memory (estimated size 31.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,422 | INFO  | [dag-scheduler-event-loop] | Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,423 | INFO  | [dispatcher-event-loop-28] | Added broadcast_20_piece0 in memory on dn37:22779 (size: 9.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,424 | INFO  | [dag-scheduler-event-loop] | Created broadcast 20 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,425 | INFO  | [dag-scheduler-event-loop] | Submitting 8 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(4, 30, 31, 43, 54, 55, 64, 77)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,425 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.2 with 8 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,428 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 10 (MapPartitionsRDD[30] at distinct at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,428 | INFO  | [dispatcher-event-loop-38] | Starting task 7.0 in stage 12.2 (TID 1096, dn15, executor 12, partition 77, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,429 | INFO  | [dispatcher-event-loop-38] | Starting task 2.0 in stage 12.2 (TID 1097, dn22, executor 5, partition 31, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,429 | INFO  | [dispatcher-event-loop-38] | Starting task 4.0 in stage 12.2 (TID 1098, dn14, executor 17, partition 54, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,430 | INFO  | [dispatcher-event-loop-38] | Starting task 1.0 in stage 12.2 (TID 1099, dn29, executor 1, partition 30, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,430 | INFO  | [dispatcher-event-loop-38] | Starting task 3.0 in stage 12.2 (TID 1100, dn34, executor 6, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,431 | INFO  | [dispatcher-event-loop-38] | Starting task 6.0 in stage 12.2 (TID 1101, dn17, executor 18, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,431 | INFO  | [dag-scheduler-event-loop] | Block broadcast_21 stored as values in memory (estimated size 31.6 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,431 | INFO  | [dispatcher-event-loop-38] | Starting task 0.0 in stage 12.2 (TID 1102, dn24, executor 9, partition 4, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,434 | INFO  | [dag-scheduler-event-loop] | Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,435 | INFO  | [dispatcher-event-loop-30] | Added broadcast_21_piece0 in memory on dn37:22779 (size: 10.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,435 | INFO  | [dag-scheduler-event-loop] | Created broadcast 21 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,446 | INFO  | [dag-scheduler-event-loop] | Submitting 11 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[30] at distinct at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(7, 30, 31, 39, 40, 43, 44, 47, 49, 55, 64)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,446 | INFO  | [dag-scheduler-event-loop] | Adding task set 10.1 with 11 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,449 | INFO  | [dispatcher-event-loop-25] | Starting task 8.0 in stage 10.1 (TID 1103, dn35, executor 23, partition 49, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,449 | INFO  | [dispatcher-event-loop-25] | Starting task 7.0 in stage 10.1 (TID 1104, dn27, executor 7, partition 47, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,450 | INFO  | [dispatcher-event-loop-25] | Starting task 3.0 in stage 10.1 (TID 1105, dn01, executor 22, partition 39, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,450 | INFO  | [dispatcher-event-loop-25] | Starting task 5.0 in stage 10.1 (TID 1106, dn34, executor 6, partition 43, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,451 | INFO  | [dispatcher-event-loop-25] | Starting task 10.0 in stage 10.1 (TID 1107, dn17, executor 18, partition 64, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,451 | INFO  | [dispatcher-event-loop-25] | Starting task 0.0 in stage 10.1 (TID 1108, dn32, executor 21, partition 7, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,451 | INFO  | [dispatcher-event-loop-25] | Starting task 4.0 in stage 10.1 (TID 1109, dn32, executor 21, partition 40, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,454 | INFO  | [dispatcher-event-loop-35] | Added broadcast_20_piece0 in memory on dn24:22839 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,454 | INFO  | [dispatcher-event-loop-35] | Added broadcast_20_piece0 in memory on dn29:22705 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,459 | INFO  | [dispatcher-event-loop-64] | Added broadcast_20_piece0 in memory on dn17:22761 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,460 | INFO  | [dispatcher-event-loop-64] | Added broadcast_20_piece0 in memory on dn14:22891 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,460 | INFO  | [dispatcher-event-loop-64] | Added broadcast_20_piece0 in memory on dn34:22620 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,468 | INFO  | [dispatcher-event-loop-66] | Added broadcast_20_piece0 in memory on dn15:22640 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,468 | INFO  | [dispatcher-event-loop-66] | Added broadcast_21_piece0 in memory on dn34:22620 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,469 | INFO  | [dispatcher-event-loop-66] | Added broadcast_21_piece0 in memory on dn17:22761 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,495 | INFO  | [dispatcher-event-loop-65] | Added broadcast_21_piece0 in memory on dn27:22790 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,546 | INFO  | [dispatcher-event-loop-54] | Added broadcast_20_piece0 in memory on dn22:22834 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,729 | INFO  | [dispatcher-event-loop-8] | Added broadcast_21_piece0 in memory on dn01:22647 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,786 | INFO  | [dispatcher-event-loop-45] | Added broadcast_21_piece0 in memory on dn35:22898 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:49,794 | INFO  | [dispatcher-event-loop-9] | Added broadcast_21_piece0 in memory on dn32:22662 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:50,124 | INFO  | [dispatcher-event-loop-1] | Added broadcast_3_piece0 in memory on dn01:22647 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:50,181 | INFO  | [dispatcher-event-loop-17] | Added broadcast_3_piece0 in memory on dn35:22898 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:50,195 | INFO  | [dispatcher-event-loop-31] | Added broadcast_3_piece0 in memory on dn32:22662 (size: 58.5 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,673 | INFO  | [dispatcher-event-loop-23] | Starting task 1.0 in stage 10.1 (TID 1110, dn01, executor 22, partition 30, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,674 | INFO  | [dispatcher-event-loop-23] | Starting task 2.0 in stage 10.1 (TID 1111, dn18, executor 10, partition 31, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,674 | INFO  | [dispatcher-event-loop-23] | Starting task 6.0 in stage 10.1 (TID 1112, dn19, executor 11, partition 44, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,674 | INFO  | [dispatcher-event-loop-23] | Starting task 9.0 in stage 10.1 (TID 1113, dn28, executor 3, partition 55, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,675 | INFO  | [dispatcher-event-loop-23] | Starting task 5.0 in stage 12.2 (TID 1114, dn18, executor 10, partition 55, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,693 | INFO  | [dispatcher-event-loop-27] | Added broadcast_21_piece0 in memory on dn28:22784 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,701 | INFO  | [dispatcher-event-loop-11] | Added broadcast_21_piece0 in memory on dn19:22830 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,771 | INFO  | [dispatcher-event-loop-37] | Added broadcast_21_piece0 in memory on dn18:22756 (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:52,784 | INFO  | [dispatcher-event-loop-47] | Added broadcast_20_piece0 in memory on dn18:22756 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,195 | ERROR | [dispatcher-event-loop-36] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@61d8632e) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,205 | ERROR | [dispatcher-event-loop-35] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@503743fa) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,208 | ERROR | [dispatcher-event-loop-52] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3c36ea73) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,211 | ERROR | [dispatcher-event-loop-58] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4e9fe16e) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,215 | ERROR | [dispatcher-event-loop-63] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2203ea9f) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,218 | ERROR | [dispatcher-event-loop-70] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(8),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3620df54) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,277 | WARN  | [task-result-getter-1] | Lost task 2.0 in stage 13.1 (TID 1093, dn08, executor 16): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=55, reduceId=24, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:54,278 | INFO  | [task-result-getter-1] | Task 2.0 in stage 13.1 (TID 1093) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,278 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,294 | ERROR | [dispatcher-event-loop-53] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.30:59294,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@42351890) from 10.27.132.30:59294																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,297 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.37:52522,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7616a5c8) from 10.27.132.37:52522																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,301 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5dcbedf) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,308 | WARN  | [task-result-getter-2] | Lost task 4.0 in stage 13.1 (TID 1095, dn29, executor 1): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=4, reduceId=44, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:54,309 | INFO  | [task-result-getter-2] | Task 4.0 in stage 13.1 (TID 1095) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,315 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.36:38392,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3e1fb1d2) from 10.27.132.36:38392																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,317 | ERROR | [dispatcher-event-loop-50] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.13:58454,IsExecutorAlive(19),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@73c171ec) from 10.27.132.13:58454																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:26:54,378 | WARN  | [task-result-getter-0] | Lost task 1.0 in stage 13.1 (TID 1092, dn22, executor 5): FetchFailed(BlockManagerId(8, dn37, 22861, None), shuffleId=3, mapId=55, reduceId=16, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn37/10.27.132.45:22861																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn37/10.27.132.45:22861																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:26:54,378 | INFO  | [task-result-getter-0] | Task 1.0 in stage 13.1 (TID 1092) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,378 | INFO  | [task-result-getter-0] | Removed TaskSet 13.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:54,480 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:59,341 | INFO  | [task-result-getter-3] | Finished task 10.0 in stage 10.1 (TID 1107) in 9890 ms on dn17 (executor 18) (1/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:59,401 | INFO  | [task-result-getter-1] | Finished task 7.0 in stage 10.1 (TID 1104) in 9952 ms on dn27 (executor 7) (2/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:26:59,558 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 10.1 (TID 1106) in 10108 ms on dn34 (executor 6) (3/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:00,477 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 12.2 (TID 1102) in 11046 ms on dn24 (executor 9) (1/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:00,832 | INFO  | [task-result-getter-3] | Finished task 1.0 in stage 12.2 (TID 1099) in 11402 ms on dn29 (executor 1) (2/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,272 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 10.1 (TID 1111) in 8599 ms on dn18 (executor 10) (4/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,334 | INFO  | [task-result-getter-2] | Finished task 3.0 in stage 10.1 (TID 1105) in 11884 ms on dn01 (executor 22) (5/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,358 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 10.1 (TID 1110) in 8685 ms on dn01 (executor 22) (6/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,360 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 12.2 (TID 1096) in 11933 ms on dn15 (executor 12) (3/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,493 | INFO  | [task-result-getter-1] | Finished task 8.0 in stage 10.1 (TID 1103) in 12045 ms on dn35 (executor 23) (7/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,563 | INFO  | [task-result-getter-2] | Finished task 6.0 in stage 12.2 (TID 1101) in 12132 ms on dn17 (executor 18) (4/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,574 | INFO  | [task-result-getter-0] | Finished task 0.0 in stage 10.1 (TID 1108) in 12123 ms on dn32 (executor 21) (8/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,636 | INFO  | [task-result-getter-3] | Finished task 4.0 in stage 12.2 (TID 1098) in 12207 ms on dn14 (executor 17) (5/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,696 | INFO  | [task-result-getter-1] | Finished task 3.0 in stage 12.2 (TID 1100) in 12266 ms on dn34 (executor 6) (6/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,842 | INFO  | [task-result-getter-2] | Finished task 4.0 in stage 10.1 (TID 1109) in 12391 ms on dn32 (executor 21) (9/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:01,870 | INFO  | [task-result-getter-0] | Finished task 2.0 in stage 12.2 (TID 1097) in 12441 ms on dn22 (executor 5) (7/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,568 | INFO  | [task-result-getter-3] | Finished task 9.0 in stage 10.1 (TID 1113) in 9893 ms on dn28 (executor 3) (10/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,723 | INFO  | [task-result-getter-1] | Finished task 6.0 in stage 10.1 (TID 1112) in 10049 ms on dn19 (executor 11) (11/11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,724 | INFO  | [task-result-getter-1] | Removed TaskSet 10.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,724 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 10 (distinct at GraphWriter.scala:253) finished in 13.295 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13, ShuffleMapStage 11) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,725 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,726 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 11 (MapPartitionsRDD[33] at mapPartitions at GraphWriter.scala:253), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,729 | INFO  | [dag-scheduler-event-loop] | Block broadcast_22 stored as values in memory (estimated size 7.5 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,735 | INFO  | [dag-scheduler-event-loop] | Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,735 | INFO  | [dispatcher-event-loop-58] | Added broadcast_22_piece0 in memory on dn37:22779 (size: 4.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,736 | INFO  | [dag-scheduler-event-loop] | Created broadcast 22 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,737 | INFO  | [dag-scheduler-event-loop] | Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[33] at mapPartitions at GraphWriter.scala:253) (first 15 tasks are for partitions Vector(77)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,737 | INFO  | [dag-scheduler-event-loop] | Adding task set 11.1 with 1 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,738 | INFO  | [dispatcher-event-loop-63] | Starting task 0.0 in stage 11.1 (TID 1115, dn14, executor 17, partition 77, NODE_LOCAL, 7629 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,757 | INFO  | [dispatcher-event-loop-53] | Added broadcast_22_piece0 in memory on dn14:22891 (size: 4.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,761 | INFO  | [dispatcher-event-loop-46] | Asked to send map output locations for shuffle 7 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,924 | INFO  | [task-result-getter-2] | Finished task 0.0 in stage 11.1 (TID 1115) in 186 ms on dn14 (executor 17) (1/1) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,925 | INFO  | [task-result-getter-2] | Removed TaskSet 11.1, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,925 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 11 (mapPartitions at GraphWriter.scala:253) finished in 0.197 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | running: Set(ShuffleMapStage 12) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:02,926 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,639 | INFO  | [task-result-getter-0] | Finished task 5.0 in stage 12.2 (TID 1114) in 10964 ms on dn18 (executor 10) (8/8) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,639 | INFO  | [task-result-getter-0] | Removed TaskSet 12.2, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,640 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 14.227 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,640 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,641 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,642 | INFO  | [dag-scheduler-event-loop] | Reusing state from previous attempt of stage 13. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,644 | INFO  | [dag-scheduler-event-loop] | Block broadcast_23 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,649 | INFO  | [dag-scheduler-event-loop] | Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,650 | INFO  | [dispatcher-event-loop-65] | Added broadcast_23_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,651 | INFO  | [dag-scheduler-event-loop] | Created broadcast 23 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,652 | INFO  | [dag-scheduler-event-loop] | Submitting 9 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(1, 10, 11, 16, 24, 25, 33, 34, 44)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,652 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.2 with 9 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,653 | INFO  | [dispatcher-event-loop-60] | Starting task 0.0 in stage 13.2 (TID 1116, dn24, executor 9, partition 1, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,654 | INFO  | [dispatcher-event-loop-60] | Starting task 1.0 in stage 13.2 (TID 1117, dn01, executor 22, partition 10, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,654 | INFO  | [dispatcher-event-loop-60] | Starting task 2.0 in stage 13.2 (TID 1118, dn34, executor 6, partition 11, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,655 | INFO  | [dispatcher-event-loop-60] | Starting task 3.0 in stage 13.2 (TID 1119, dn28, executor 3, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,655 | INFO  | [dispatcher-event-loop-60] | Starting task 4.0 in stage 13.2 (TID 1120, dn35, executor 23, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,655 | INFO  | [dispatcher-event-loop-60] | Starting task 5.0 in stage 13.2 (TID 1121, dn19, executor 11, partition 25, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,656 | INFO  | [dispatcher-event-loop-60] | Starting task 6.0 in stage 13.2 (TID 1122, dn36, executor 20, partition 33, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,656 | INFO  | [dispatcher-event-loop-60] | Starting task 7.0 in stage 13.2 (TID 1123, dn27, executor 7, partition 34, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,657 | INFO  | [dispatcher-event-loop-60] | Starting task 8.0 in stage 13.2 (TID 1124, dn08, executor 16, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,669 | INFO  | [dispatcher-event-loop-17] | Added broadcast_23_piece0 in memory on dn24:22839 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,669 | INFO  | [dispatcher-event-loop-17] | Added broadcast_23_piece0 in memory on dn08:22604 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,670 | INFO  | [dispatcher-event-loop-7] | Added broadcast_23_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,672 | INFO  | [dispatcher-event-loop-10] | Added broadcast_23_piece0 in memory on dn19:22830 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,673 | INFO  | [dispatcher-event-loop-5] | Added broadcast_23_piece0 in memory on dn28:22784 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,673 | INFO  | [dispatcher-event-loop-5] | Added broadcast_23_piece0 in memory on dn27:22790 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,675 | INFO  | [dispatcher-event-loop-16] | Asked to send map output locations for shuffle 3 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,676 | INFO  | [dispatcher-event-loop-20] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,680 | INFO  | [dispatcher-event-loop-21] | Asked to send map output locations for shuffle 3 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,680 | INFO  | [dispatcher-event-loop-32] | Asked to send map output locations for shuffle 3 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,681 | INFO  | [dispatcher-event-loop-22] | Asked to send map output locations for shuffle 3 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,681 | INFO  | [dispatcher-event-loop-26] | Asked to send map output locations for shuffle 3 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,684 | INFO  | [dispatcher-event-loop-6] | Added broadcast_23_piece0 in memory on dn34:22620 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,685 | INFO  | [dispatcher-event-loop-57] | Asked to send map output locations for shuffle 4 to *.*.132.13:58454 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,686 | INFO  | [dispatcher-event-loop-18] | Asked to send map output locations for shuffle 4 to *.*.132.32:57566 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,690 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,693 | INFO  | [dispatcher-event-loop-23] | Asked to send map output locations for shuffle 4 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,693 | INFO  | [dispatcher-event-loop-39] | Asked to send map output locations for shuffle 4 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,694 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 4 to *.*.132.36:38392 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,707 | INFO  | [dispatcher-event-loop-28] | Added broadcast_23_piece0 in memory on dn01:22647 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,709 | INFO  | [dispatcher-event-loop-38] | Asked to send map output locations for shuffle 3 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,725 | INFO  | [dispatcher-event-loop-30] | Asked to send map output locations for shuffle 4 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,730 | INFO  | [dispatcher-event-loop-24] | Added broadcast_23_piece0 in memory on dn35:22898 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,750 | INFO  | [dispatcher-event-loop-34] | Asked to send map output locations for shuffle 3 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,752 | INFO  | [dispatcher-event-loop-27] | Asked to send map output locations for shuffle 3 to *.*.132.43:54148 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,792 | INFO  | [task-result-getter-3] | Finished task 0.0 in stage 13.2 (TID 1116) in 139 ms on dn24 (executor 9) (1/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,793 | INFO  | [task-result-getter-1] | Finished task 2.0 in stage 13.2 (TID 1118) in 139 ms on dn34 (executor 6) (2/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,852 | INFO  | [task-result-getter-2] | Finished task 5.0 in stage 13.2 (TID 1121) in 197 ms on dn19 (executor 11) (3/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:03,877 | INFO  | [dispatcher-event-loop-49] | Asked to send map output locations for shuffle 4 to *.*.132.43:54148 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:04,227 | INFO  | [dispatcher-event-loop-48] | Asked to send map output locations for shuffle 4 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:05,242 | INFO  | [task-result-getter-0] | Finished task 6.0 in stage 13.2 (TID 1122) in 1586 ms on dn36 (executor 20) (4/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:06,259 | INFO  | [task-result-getter-3] | Finished task 7.0 in stage 13.2 (TID 1123) in 2603 ms on dn27 (executor 7) (5/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:27:15,885 | INFO  | [task-result-getter-1] | Finished task 1.0 in stage 13.2 (TID 1117) in 12231 ms on dn01 (executor 22) (6/9) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,415 | INFO  | [dispatcher-event-loop-8] | Disabling executor 23. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,417 | INFO  | [dag-scheduler-event-loop] | Executor lost: 23 (epoch 22) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,417 | INFO  | [dispatcher-event-loop-14] | Trying to remove executor 23 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,418 | INFO  | [dispatcher-event-loop-14] | Removing block manager BlockManagerId(23, dn35, 22898, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,418 | INFO  | [dag-scheduler-event-loop] | Removed 23 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,419 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 23 (epoch 22) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,621 | INFO  | [Reporter] | Completed container container_e06_1595920838912_178438_01_000023 on host: dn35 (state: COMPLETE, exit status: 143) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,621 | WARN  | [Reporter] | Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:36:49,622 | WARN  | [dispatcher-event-loop-19] | Requesting driver to remove executor 23 for reason Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:36:49,624 | ERROR | [dispatcher-event-loop-5] | Lost executor 23 on dn35: Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:36:49,625 | WARN  | [dispatcher-event-loop-5] | Lost task 4.0 in stage 13.2 (TID 1120, dn35, executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Container marked as failed: container_e06_1595920838912_178438_01_000023 on host: dn35. Exit status: 143. Diagnostics: [2020-08-03 18:36:49.421]Container killed on request. Exit code is 143																																																																		
[2020-08-03 18:36:49.422]Container exited with a non-zero exit code 143. 																																																																		
[2020-08-03 18:36:49.448]Killed by external signal																																																																		
 | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:36:49,626 | INFO  | [dispatcher-event-loop-5] | Removal of executor 23 requested | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,626 | INFO  | [dispatcher-event-loop-20] | Trying to remove executor 23 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,626 | INFO  | [dispatcher-event-loop-5] | Asked to remove non-existent executor 23 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,673 | INFO  | [dispatcher-event-loop-21] | Starting task 4.1 in stage 13.2 (TID 1125, dn17, executor 18, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,714 | INFO  | [dispatcher-event-loop-26] | Added broadcast_23_piece0 in memory on dn17:22761 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,736 | INFO  | [dispatcher-event-loop-6] | Asked to send map output locations for shuffle 3 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:49,743 | INFO  | [dispatcher-event-loop-57] | Asked to send map output locations for shuffle 4 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,622 | INFO  | [Reporter] | Will request 1 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,623 | INFO  | [Reporter] | Submitted 1 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,828 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000025 on host dn23 for executor with ID 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:36:52,829 | INFO  | [Reporter] | Received 1 containers from YARN, launching executors on 1 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:37:00,182 | INFO  | [dispatcher-event-loop-24] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.31:36202 with ID 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:37:00,319 | INFO  | [dispatcher-event-loop-27] | Registering block manager dn23:22782 with 5.2 GB RAM, 24 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,390 | WARN  | [dispatcher-event-loop-48] | Removing executor 16 with no recent heartbeats: 368830 ms exceeds timeout 360000 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:40:50,393 | ERROR | [dispatcher-event-loop-48] | Lost executor 16 on dn08: Executor heartbeat timed out after 368830 ms | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:40:50,394 | WARN  | [dispatcher-event-loop-48] | Lost task 8.0 in stage 13.2 (TID 1124, dn08, executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 368830 ms | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:40:50,396 | INFO  | [dag-scheduler-event-loop] | Executor lost: 16 (epoch 23) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,396 | INFO  | [kill-executor-thread] | Requesting to kill executor(s) 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,396 | INFO  | [dispatcher-event-loop-41] | Trying to remove executor 16 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,397 | INFO  | [dispatcher-event-loop-51] | Starting task 8.1 in stage 13.2 (TID 1126, dn18, executor 10, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,397 | INFO  | [dispatcher-event-loop-41] | Removing block manager BlockManagerId(16, dn08, 22604, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,398 | INFO  | [dag-scheduler-event-loop] | Removed 16 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,398 | INFO  | [kill-executor-thread] | Actual list of executor(s) to be killed is 16 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,398 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 16 (epoch 23) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,399 | INFO  | [dispatcher-event-loop-43] | Driver requested to kill executor(s) 16. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,400 | INFO  | [dag-scheduler-event-loop] | Host added was in lost list earlier: dn08 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,422 | INFO  | [dispatcher-event-loop-63] | Added broadcast_23_piece0 in memory on dn18:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,430 | INFO  | [dispatcher-event-loop-70] | Asked to send map output locations for shuffle 3 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,457 | WARN  | [task-result-getter-2] | Lost task 8.1 in stage 13.2 (TID 1126, dn18, executor 10): FetchFailed(null, shuffleId=3, mapId=-1, reduceId=44, message=																																																																		
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:40:50,458 | INFO  | [task-result-getter-2] | Task 8.1 in stage 13.2 (TID 1126) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,458 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,460 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 826.817 s due to org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 3																																																																		
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1086)																																																																	
	at org.apache.spark.MapOutputTracker$$anonfun$convertMapStatuses$2.apply(MapOutputTracker.scala:1082)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)																																																																	
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1082)																																																																	
	at org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:835)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:55)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,460 | INFO  | [dag-scheduler-event-loop] | Resubmitting ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) and ShuffleMapStage 13 (map at GraphWriter.scala:266) due to fetch failure | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,661 | INFO  | [dag-scheduler-event-loop] | Resubmitting failed stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,662 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,669 | INFO  | [dag-scheduler-event-loop] | Block broadcast_24 stored as values in memory (estimated size 31.0 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,674 | INFO  | [dag-scheduler-event-loop] | Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,675 | INFO  | [dispatcher-event-loop-46] | Added broadcast_24_piece0 in memory on dn37:22779 (size: 9.9 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,677 | INFO  | [dag-scheduler-event-loop] | Created broadcast 24 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,678 | INFO  | [dag-scheduler-event-loop] | Submitting 4 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at keyBy at GraphWriter.scala:258) (first 15 tasks are for partitions Vector(9, 38, 80, 81)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,678 | INFO  | [dag-scheduler-event-loop] | Adding task set 12.3 with 4 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,680 | INFO  | [dispatcher-event-loop-33] | Starting task 0.0 in stage 12.3 (TID 1127, dn22, executor 5, partition 9, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,681 | INFO  | [dispatcher-event-loop-33] | Starting task 3.0 in stage 12.3 (TID 1128, dn27, executor 7, partition 81, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,681 | INFO  | [dispatcher-event-loop-33] | Starting task 1.0 in stage 12.3 (TID 1129, dn01, executor 22, partition 38, NODE_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,702 | INFO  | [dispatcher-event-loop-60] | Added broadcast_24_piece0 in memory on dn22:22834 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,704 | INFO  | [dispatcher-event-loop-44] | Added broadcast_24_piece0 in memory on dn27:22790 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:50,723 | INFO  | [dispatcher-event-loop-56] | Added broadcast_24_piece0 in memory on dn01:22647 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,053 | INFO  | [Reporter] | Will request 1 executor container(s), each with 2 core(s) and 14336 MB memory (including 4096 MB of overhead) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,054 | INFO  | [Reporter] | Submitted 1 unlocalized container requests. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,264 | INFO  | [Reporter] | Launching container container_e06_1595920838912_178438_01_000026 on host dn03 for executor with ID 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:53,265 | INFO  | [Reporter] | Received 1 containers from YARN, launching executors on 1 of them. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:54,673 | INFO  | [dispatcher-event-loop-45] | Starting task 2.0 in stage 12.3 (TID 1130, dn15, executor 12, partition 80, RACK_LOCAL, 7954 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:54,799 | INFO  | [dispatcher-event-loop-14] | Added broadcast_24_piece0 in memory on dn15:22640 (size: 9.9 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,287 | INFO  | [dispatcher-event-loop-6] | Disabling executor 16. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,287 | INFO  | [dag-scheduler-event-loop] | Executor lost: 16 (epoch 24) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,288 | INFO  | [dispatcher-event-loop-28] | Trying to remove executor 16 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,288 | INFO  | [dag-scheduler-event-loop] | Removed 16 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:40:55,288 | ERROR | [dispatcher-event-loop-6] | Lost executor 16 on dn08: Container container_e06_1595920838912_178438_01_000018 exited from explicit termination request. | org.apache.spark.internal.Logging$class.logError(Logging.scala:70)																																																																		
2020-08-03 18:40:55,288 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 16 (epoch 24) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:00,318 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@f5cf819) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:00,324 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6a1fb534) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:00,760 | INFO  | [dispatcher-event-loop-21] | Registered executor NettyRpcEndpointRef(spark-client://Executor) (*.*.132.8:51824 with ID 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:00,894 | INFO  | [dispatcher-event-loop-40] | Registering block manager dn03:22878 with 5.2 GB RAM, 25 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:01,853 | INFO  | [task-result-getter-0] | Finished task 1.0 in stage 12.3 (TID 1129) in 11172 ms on dn01 (executor 22) (1/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:02,806 | INFO  | [task-result-getter-3] | Finished task 3.0 in stage 12.3 (TID 1128) in 12126 ms on dn27 (executor 7) (2/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:02,808 | INFO  | [task-result-getter-1] | Finished task 0.0 in stage 12.3 (TID 1127) in 12128 ms on dn22 (executor 5) (3/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:05,338 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@41ee52dc) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:05,342 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@14c155ac) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:06,874 | INFO  | [task-result-getter-2] | Finished task 2.0 in stage 12.3 (TID 1130) in 12202 ms on dn15 (executor 12) (4/4) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [task-result-getter-2] | Removed TaskSet 12.3, whose tasks have all completed, from pool  | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) finished in 16.211 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | looking for newly runnable stages | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | running: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | waiting: Set(ResultStage 16, ShuffleMapStage 13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,875 | INFO  | [dag-scheduler-event-loop] | failed: Set() | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,876 | INFO  | [dag-scheduler-event-loop] | Submitting ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266), which has no missing parents | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,876 | INFO  | [dag-scheduler-event-loop] | Reusing state from previous attempt of stage 13. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,877 | INFO  | [dag-scheduler-event-loop] | Block broadcast_25 stored as values in memory (estimated size 3.8 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,879 | INFO  | [dag-scheduler-event-loop] | Block broadcast_25_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,880 | INFO  | [dispatcher-event-loop-44] | Added broadcast_25_piece0 in memory on dn37:22779 (size: 2.3 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,880 | INFO  | [dag-scheduler-event-loop] | Created broadcast 25 from broadcast at DAGScheduler.scala:1083 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,881 | INFO  | [dag-scheduler-event-loop] | Submitting 13 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[38] at map at GraphWriter.scala:266) (first 15 tasks are for partitions Vector(6, 16, 20, 24, 36, 44, 53, 57, 62, 64, 70, 71, 73)) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,881 | INFO  | [dag-scheduler-event-loop] | Adding task set 13.3 with 13 tasks | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 0.0 in stage 13.3 (TID 1131, dn17, executor 18, partition 6, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 1.0 in stage 13.3 (TID 1132, dn36, executor 20, partition 16, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 2.0 in stage 13.3 (TID 1133, dn34, executor 6, partition 20, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 3.0 in stage 13.3 (TID 1134, dn19, executor 11, partition 24, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,882 | INFO  | [dispatcher-event-loop-68] | Starting task 4.0 in stage 13.3 (TID 1135, dn20, executor 13, partition 36, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 5.0 in stage 13.3 (TID 1136, dn15, executor 12, partition 44, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 6.0 in stage 13.3 (TID 1137, dn18, executor 10, partition 53, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 7.0 in stage 13.3 (TID 1138, dn01, executor 22, partition 57, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 8.0 in stage 13.3 (TID 1139, dn32, executor 21, partition 62, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 9.0 in stage 13.3 (TID 1140, dn14, executor 17, partition 64, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 10.0 in stage 13.3 (TID 1141, dn29, executor 1, partition 70, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 11.0 in stage 13.3 (TID 1142, dn27, executor 7, partition 71, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,883 | INFO  | [dispatcher-event-loop-68] | Starting task 12.0 in stage 13.3 (TID 1143, dn22, executor 5, partition 73, PROCESS_LOCAL, 7719 bytes) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,893 | INFO  | [dispatcher-event-loop-62] | Added broadcast_25_piece0 in memory on dn18:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,893 | INFO  | [dispatcher-event-loop-62] | Added broadcast_25_piece0 in memory on dn15:22640 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,896 | INFO  | [dispatcher-event-loop-5] | Added broadcast_25_piece0 in memory on dn34:22620 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,896 | INFO  | [dispatcher-event-loop-26] | Added broadcast_25_piece0 in memory on dn19:22830 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,897 | INFO  | [dispatcher-event-loop-13] | Asked to send map output locations for shuffle 3 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,898 | INFO  | [dispatcher-event-loop-22] | Asked to send map output locations for shuffle 3 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,899 | INFO  | [dispatcher-event-loop-18] | Added broadcast_25_piece0 in memory on dn36:22756 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-21] | Added broadcast_25_piece0 in memory on dn20:22825 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-39] | Asked to send map output locations for shuffle 3 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-29] | Asked to send map output locations for shuffle 3 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,901 | INFO  | [dispatcher-event-loop-40] | Added broadcast_25_piece0 in memory on dn22:22834 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,903 | INFO  | [dispatcher-event-loop-38] | Added broadcast_25_piece0 in memory on dn27:22790 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,906 | INFO  | [dispatcher-event-loop-28] | Asked to send map output locations for shuffle 3 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,906 | INFO  | [dispatcher-event-loop-6] | Added broadcast_25_piece0 in memory on dn29:22705 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,906 | INFO  | [dispatcher-event-loop-6] | Added broadcast_25_piece0 in memory on dn17:22761 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,907 | INFO  | [dispatcher-event-loop-24] | Asked to send map output locations for shuffle 3 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,908 | INFO  | [dispatcher-event-loop-27] | Added broadcast_25_piece0 in memory on dn14:22891 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,908 | INFO  | [dispatcher-event-loop-11] | Asked to send map output locations for shuffle 3 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,909 | INFO  | [dispatcher-event-loop-37] | Asked to send map output locations for shuffle 4 to *.*.132.26:51202 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,909 | INFO  | [dispatcher-event-loop-42] | Asked to send map output locations for shuffle 4 to *.*.132.20:51756 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,910 | INFO  | [dispatcher-event-loop-4] | Asked to send map output locations for shuffle 3 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,910 | INFO  | [dispatcher-event-loop-47] | Added broadcast_25_piece0 in memory on dn01:22647 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,914 | INFO  | [dispatcher-event-loop-49] | Asked to send map output locations for shuffle 4 to *.*.132.27:46054 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,914 | INFO  | [dispatcher-event-loop-41] | Asked to send map output locations for shuffle 3 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,914 | INFO  | [dispatcher-event-loop-48] | Asked to send map output locations for shuffle 3 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,918 | INFO  | [dispatcher-event-loop-51] | Asked to send map output locations for shuffle 4 to *.*.132.44:60542 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,921 | INFO  | [dispatcher-event-loop-25] | Asked to send map output locations for shuffle 3 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,931 | INFO  | [dispatcher-event-loop-43] | Asked to send map output locations for shuffle 4 to *.*.132.35:40302 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,931 | INFO  | [dispatcher-event-loop-36] | Asked to send map output locations for shuffle 3 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,939 | INFO  | [dispatcher-event-loop-52] | Asked to send map output locations for shuffle 4 to *.*.132.19:48900 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,951 | INFO  | [dispatcher-event-loop-58] | Asked to send map output locations for shuffle 4 to *.*.132.42:36736 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,959 | INFO  | [dispatcher-event-loop-63] | Asked to send map output locations for shuffle 4 to *.*.132.28:55400 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,961 | INFO  | [dispatcher-event-loop-70] | Asked to send map output locations for shuffle 4 to *.*.132.30:59294 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,962 | INFO  | [dispatcher-event-loop-33] | Asked to send map output locations for shuffle 4 to *.*.132.6:40176 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,963 | INFO  | [task-result-getter-0] | Finished task 11.0 in stage 13.3 (TID 1142) in 80 ms on dn27 (executor 7) (1/13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,964 | INFO  | [task-result-getter-3] | Finished task 9.0 in stage 13.3 (TID 1140) in 81 ms on dn14 (executor 17) (2/13) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,971 | INFO  | [dispatcher-event-loop-66] | Asked to send map output locations for shuffle 4 to *.*.132.37:52522 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,971 | INFO  | [dispatcher-event-loop-64] | Asked to send map output locations for shuffle 4 to *.*.132.22:42584 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:06,988 | INFO  | [dispatcher-event-loop-50] | Added broadcast_25_piece0 in memory on dn32:22662 (size: 2.3 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:07,027 | INFO  | [dispatcher-event-loop-59] | Asked to send map output locations for shuffle 3 to *.*.132.40:42962 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:10,352 | ERROR | [dispatcher-event-loop-61] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@40e29f19) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:10,358 | ERROR | [dispatcher-event-loop-3] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@4dde6589) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:15,365 | ERROR | [dispatcher-event-loop-40] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@786b36ab) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:15,379 | ERROR | [dispatcher-event-loop-38] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6f5b8691) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:20,383 | ERROR | [dispatcher-event-loop-33] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2f7a45a0) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:20,392 | ERROR | [dispatcher-event-loop-46] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@179c91f8) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:25,394 | ERROR | [dispatcher-event-loop-45] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@2e91b20) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:25,404 | ERROR | [dispatcher-event-loop-31] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@11fd1745) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:30,405 | ERROR | [dispatcher-event-loop-6] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7f57ba6f) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:30,415 | ERROR | [dispatcher-event-loop-24] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@49776c19) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:35,416 | ERROR | [dispatcher-event-loop-69] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@51f51a63) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:35,426 | ERROR | [dispatcher-event-loop-65] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@305c2ab5) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:40,427 | ERROR | [dispatcher-event-loop-16] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@6fef34f8) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:40,438 | ERROR | [dispatcher-event-loop-19] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@3d178c1) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:45,440 | ERROR | [dispatcher-event-loop-47] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@7c04c06b) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:45,453 | ERROR | [dispatcher-event-loop-49] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@47da37fd) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:50,454 | ERROR | [dispatcher-event-loop-67] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@58085c07) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:50,466 | ERROR | [dispatcher-event-loop-56] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5e3cb996) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:51,654 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 345 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,655 | INFO  | [Spark Context Cleaner] | Cleaned accumulator 459 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,661 | INFO  | [dispatcher-event-loop-15] | Removed broadcast_21_piece0 on dn37:22779 in memory (size: 10.2 KB, free: 2.5 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,663 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn34:22620 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,663 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn18:22756 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,664 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn17:22761 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,664 | INFO  | [dispatcher-event-loop-1] | Removed broadcast_21_piece0 on dn27:22790 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,671 | INFO  | [dispatcher-event-loop-45] | Removed broadcast_21_piece0 on dn19:22830 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,691 | INFO  | [dispatcher-event-loop-8] | Removed broadcast_21_piece0 on dn01:22647 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:51,697 | INFO  | [dispatcher-event-loop-62] | Removed broadcast_21_piece0 on dn32:22662 in memory (size: 10.2 KB, free: 5.2 GB) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:55,465 | ERROR | [dispatcher-event-loop-28] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@5d1f5a93) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:55,476 | ERROR | [dispatcher-event-loop-34] | Ignoring error | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.SparkException: Unsupported message RpcMessage(10.27.132.22:42584,IsExecutorAlive(16),org.apache.spark.rpc.netty.RemoteNettyRpcCallContext@cbeffb5) from 10.27.132.22:42584																																																																		
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:106)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1$$anonfun$apply$mcV$sp$1.apply(Inbox.scala:105)																																																																	
	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:76)																																																																	
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)																																																																	
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)																																																																	
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)																																																																	
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
2020-08-03 18:41:55,570 | WARN  | [task-result-getter-1] | Lost task 4.1 in stage 13.2 (TID 1125, dn17, executor 18): FetchFailed(BlockManagerId(16, dn08, 22604, None), shuffleId=3, mapId=9, reduceId=24, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: Failed to connect to dn08/10.27.132.13:22604																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.io.IOException: Failed to connect to dn08/10.27.132.13:22604																																																																		
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.lambda$initiateRetry$0(RetryingBlockFetcher.java:169)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)																																																																	
	... 1 more																																																																	
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: dn08/10.27.132.13:22604																																																																		
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)																																																																	
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)																																																																	
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:323)																																																																	
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:633)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)																																																																	
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)																																																																	
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)																																																																	
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)																																																																	
	... 2 more																																																																	
Caused by: java.net.ConnectException: Connection refused																																																																		
	... 11 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:41:55,571 | INFO  | [task-result-getter-1] | Task 4.1 in stage 13.2 (TID 1125) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:41:55,576 | INFO  | [dag-scheduler-event-loop] | Ignoring fetch failure from ShuffleMapTask(13, 24) as it's from ShuffleMapStage 13 attempt 2 and there is a more recent attempt for that stage (attempt 3) running | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,155 | INFO  | [dispatcher-event-loop-26] | Asked to send map output locations for shuffle 4 to *.*.132.40:42962 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,192 | WARN  | [task-result-getter-2] | Lost task 8.0 in stage 13.3 (TID 1139, dn32, executor 21): FetchFailed(BlockManagerId(3, dn28, 22784, None), shuffleId=3, mapId=2, reduceId=62, message=																																																																		
org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260)																																																																	
	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	... 20 more																																																																	
Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276)																																																																	
	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256)																																																																	
	... 41 more																																																																	
																																																																		
) | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:43:07,193 | INFO  | [task-result-getter-2] | Task 8.0 in stage 13.3 (TID 1139) failed, but the task will not be re-executed (either because the task failed with a shuffle data fetch failure, so the previous stage needs to be re-run, or because a different copy of the task has already succeeded). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,193 | INFO  | [dag-scheduler-event-loop] | Marking ShuffleMapStage 13 (map at GraphWriter.scala:266) as failed due to a fetch failure from ShuffleMapStage 12 (keyBy at GraphWriter.scala:258) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,196 | INFO  | [dag-scheduler-event-loop] | ShuffleMapStage 13 (map at GraphWriter.scala:266) failed in 120.320 s due to org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62)																																																																	
	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)																																																																	
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)																																																																	
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)																																																																	
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)																																																																	
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)																																																																	
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49)																																																																	
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348)																																																																	
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)																																																																	
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)																																																																	
	at org.apache.spark.scheduler.Task.run(Task.scala:110)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345)																																																																	
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424)																																																																	
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260)																																																																	
	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115)																																																																	
	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257)																																																																	
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141)																																																																	
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121)																																																																	
	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367)																																																																	
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163)																																																																	
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137)																																																																	
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)																																																																	
	at scala.collection.immutable.List.foreach(List.scala:381)																																																																	
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)																																																																	
	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137)																																																																	
	... 20 more																																																																	
Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task.																																																																		
	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276)																																																																	
	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96)																																																																	
	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256)																																																																	
	... 41 more																																																																	
 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,217 | INFO  | [dag-scheduler-event-loop] | Executor lost: 3 (epoch 26) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,218 | INFO  | [dispatcher-event-loop-57] | Trying to remove executor 3 from BlockManagerMaster. | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,229 | WARN  | [dispatcher-event-loop-57] | No more replicas available for broadcast_21_piece0 ! | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66)																																																																		
2020-08-03 18:43:07,229 | INFO  | [Driver] | Job 7 failed: foreachPartition at GraphWriter.scala:485, took 1990.100705 s | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,231 | INFO  | [dispatcher-event-loop-57] | Removing block manager BlockManagerId(3, dn28, 22784, None) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,232 | INFO  | [dag-scheduler-event-loop] | Removed 3 successfully in removeExecutor | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,232 | INFO  | [dag-scheduler-event-loop] | Shuffle files lost for executor: 3 (epoch 26) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:07,232 | ERROR | [Driver] | Job aborted due to stage failure: ShuffleMapStage 13 (map at GraphWriter.scala:266) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53) 	at org.apache.spark.scheduler.Task.run(Task.scala:110) 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260) 	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187) 	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121) 	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.immutable.List.foreach(List.scala:381) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137) 	... 20 more Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more  | com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:491)
org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 13 (map at GraphWriter.scala:266) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.FetchFailedException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:545) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:468) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:62) 	at org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29) 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434) 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31) 	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37) 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408) 	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:153) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:154) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:153) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:153) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:49) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:348) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:312) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96) 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53) 	at org.apache.spark.scheduler.Task.run(Task.scala:110) 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$4.apply(Executor.scala:345) 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1424) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:351) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: java.lang.RuntimeException: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.base.Throwables.propagate(Throwables.java:160) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:260) 	at org.apache.spark.network.sasl.SaslClientBootstrap.doBootstrap(SaslClientBootstrap.java:70) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doSaslAuth(AuthClientBootstrap.java:115) 	at org.apache.spark.network.crypto.AuthClientBootstrap.doBootstrap(AuthClientBootstrap.java:74) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:257) 	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187) 	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:124) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:141) 	at org.apache.spark.network.shuffle.RetryingBlockFetcher.start(RetryingBlockFetcher.java:121) 	at org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:145) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:267) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.org$apache$spark$storage$ShuffleBlockFetcherIterator$$send$1(ShuffleBlockFetcherIterator.scala:522) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:517) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:367) 	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:163) 	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:63) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:148) 	at org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$2.apply(CoGroupedRDD.scala:137) 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733) 	at scala.collection.immutable.List.foreach(List.scala:381) 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732) 	at org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:137) 	... 20 more Caused by: java.util.concurrent.TimeoutException: Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1705)																																																																	
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1693)																																																																	
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1692)																																																																	
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)																																																																	
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)																																																																	
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1692)																																																																	
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1402)																																																																	
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1923)																																																																	
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1875)																																																																	
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1864)																																																																	
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)																																																																	
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:683)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2047)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2068)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)																																																																	
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2112)																																																																	
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:959)																																																																	
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:957)																																																																	
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)																																																																	
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)																																																																	
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:387)																																																																	
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:957)																																																																	
	at com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:485)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData$.main(InsertData.scala:80)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData.main(InsertData.scala)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)																																																																	
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)																																																																	
	at java.lang.reflect.Method.invoke(Method.java:498)																																																																	
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:685)																																																																	
2020-08-03 18:43:07,237 | ERROR | [Driver] | User class threw exception: com.huawei.miner.operator.spark.common.data.api.SparkException: Load relation Failed!  Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more  | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																														
com.huawei.miner.operator.spark.common.data.api.SparkException: Load relation Failed!  Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more 																																																														
	at com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:493)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData$.main(InsertData.scala:80)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData.main(InsertData.scala)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)																																																																	
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)																																																																	
	at java.lang.reflect.Method.invoke(Method.java:498)																																																																	
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:685)																																																																	
2020-08-03 18:43:07,242 | INFO  | [Driver] | Final app status: FAILED, exitCode: 15, (reason: User class threw exception: com.huawei.miner.operator.spark.common.data.api.SparkException: Load relation Failed!  Timeout waiting for task. 	at org.spark_project.guava.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:276) 	at org.spark_project.guava.util.concurrent.AbstractFuture.get(AbstractFuture.java:96) 	at org.apache.spark.network.client.TransportClient.sendRpcSync(TransportClient.java:256) 	... 41 more 																																																														
	at com.huawei.relation.miner.core.transformer.GraphWriter.terminate(GraphWriter.scala:493)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData$.main(InsertData.scala:80)																																																																	
	at com.huawei.relation.miner.core.transformer.InsertData.main(InsertData.scala)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)																																																																	
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)																																																																	
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)																																																																	
	at java.lang.reflect.Method.invoke(Method.java:498)																																																																	
	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:685)																																																																	
) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:09,974 | INFO  | [main] | Closing master protocol: MasterService | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeMasterService(ConnectionManager.java:2301)																																																																		
2020-08-03 18:43:09,977 | INFO  | [main] | Closing zookeeper sessionid=0x7f043dfb32fddba6 | org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.closeZooKeeperWatcher(ConnectionManager.java:1765)																																																																		
2020-08-03 18:43:10,000 | INFO  | [Driver-EventThread] | EventThread shut down for session: 0x7f043dfb32fddba6 | org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:614)																																																																		
2020-08-03 18:43:10,002 | INFO  | [main] | Session: 0x7f043dfb32fddba6 closed | org.apache.zookeeper.ZooKeeper.close(ZooKeeper.java:1365)																																																																		
2020-08-03 18:43:10,014 | INFO  | [main] | clear hbaseStoreManger connection | org.janusgraph.diskstorage.hbase.HBaseStoreManager.close(HBaseStoreManager.java:424)																																																																		
2020-08-03 18:43:10,017 | INFO  | [main] | standardjanusgraph[hbase:[cn01, cn03, cn02]] with id: 0a1b842d221889-dn372 closed | org.janusgraph.graphdb.database.StandardJanusGraph.closeInternal(StandardJanusGraph.java:261)																																																																		
2020-08-03 18:43:10,028 | INFO  | [shutdown-hook-0] | Invoking stop() from shutdown hook | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:10,093 | INFO  | [shutdown-hook-0] | Stopped Spark@51511ed{HTTP/1.1,[http/1.1]}{10.27.132.45:22809} | org.spark_project.jetty.server.AbstractConnector.doStop(AbstractConnector.java:318)																																																																		
2020-08-03 18:43:10,099 | INFO  | [shutdown-hook-0] | Stopped Spark web UI at http://dn37:22809 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,667 | ERROR | [Spark Context Cleaner] | Error cleaning broadcast 21 | org.apache.spark.internal.Logging$class.logError(Logging.scala:91)																																																																		
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [120 seconds]. This timeout is controlled by spark.rpc.askTimeout																																																																		
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)																																																																	
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)																																																																	
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)																																																																	
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:160)																																																																	
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)																																																																	
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)																																																																	
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)																																																																	
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)																																																																	
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)																																																																	
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)																																																																	
	at scala.Option.foreach(Option.scala:257)																																																																	
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)																																																																	
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1366)																																																																	
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)																																																																	
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)																																																																	
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [120 seconds]																																																																		
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)																																																																	
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)																																																																	
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)																																																																	
	... 12 more																																																																	
2020-08-03 18:43:51,679 | WARN  | [block-manager-ask-thread-pool-245] | Failed to remove broadcast 21 with removeFromMaster = true - Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout | org.apache.spark.internal.Logging$class.logWarning(Logging.scala:87)																																																																		
org.apache.spark.rpc.RpcTimeoutException: Cannot receive any reply from null in 120 seconds. This timeout is controlled by spark.rpc.askTimeout																																																																		
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)																																																																	
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)																																																																	
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)																																																																	
	at scala.util.Failure$$anonfun$recover$1.apply(Try.scala:216)																																																																	
	at scala.util.Try$.apply(Try.scala:192)																																																																	
	at scala.util.Failure.recover(Try.scala:216)																																																																	
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)																																																																	
	at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326)																																																																	
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)																																																																	
	at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)																																																																	
	at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136)																																																																	
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)																																																																	
	at scala.concurrent.Promise$class.complete(Promise.scala:55)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153)																																																																	
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)																																																																	
	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237)																																																																	
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:63)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:78)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)																																																																	
	at scala.concurrent.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:55)																																																																	
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)																																																																	
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:54)																																																																	
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:601)																																																																	
	at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:106)																																																																	
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:599)																																																																	
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)																																																																	
	at scala.concurrent.Promise$class.tryFailure(Promise.scala:112)																																																																	
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:153)																																																																	
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:206)																																																																	
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1.run(NettyRpcEnv.scala:243)																																																																	
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)																																																																	
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)																																																																	
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)																																																																	
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)																																																																	
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)																																																																	
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)																																																																	
	at java.lang.Thread.run(Thread.java:748)																																																																	
Caused by: java.util.concurrent.TimeoutException: Cannot receive any reply from null in 120 seconds																																																																		
	... 8 more																																																																	
2020-08-03 18:43:51,792 | INFO  | [dispatcher-event-loop-18] | Driver requested a total number of 0 executor(s). | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,795 | INFO  | [shutdown-hook-0] | Shutting down all executors | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,799 | INFO  | [dispatcher-event-loop-23] | Asking each executor to shut down | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,805 | INFO  | [shutdown-hook-0] | Stopping SchedulerExtensionServices																																																																		
(serviceOption=None,																																																																		
 services=List(),																																																																		
 started=false) | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,819 | INFO  | [dispatcher-event-loop-40] | MapOutputTrackerMasterEndpoint stopped! | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,898 | INFO  | [shutdown-hook-0] | MemoryStore cleared | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,898 | INFO  | [shutdown-hook-0] | BlockManager stopped | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,900 | INFO  | [shutdown-hook-0] | BlockManagerMaster stopped | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,912 | INFO  | [dispatcher-event-loop-43] | OutputCommitCoordinator stopped! | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,919 | INFO  | [shutdown-hook-0] | Successfully stopped SparkContext | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,923 | INFO  | [shutdown-hook-0] | Shutdown hook called | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,926 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data6/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d27bd7b6-d232-44c3-9e49-35bee5906d85 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,926 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data10/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-930664e2-eef5-4c7c-97a8-cd37b41bee5a | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,927 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data1/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d77ca509-2c2f-44c1-a2dd-309b3d61f0ab | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,927 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data2/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-88482a74-d6bc-4033-aa1d-e6ddad05425c | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,928 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data5/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-e2e62513-0a5a-4f78-9b6a-553501864d7f | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,928 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data3/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d3ce3bf8-b134-4389-9038-e31c62781bd7 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,928 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data4/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-d6f07538-2eb2-4656-bd66-63226960b611 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,929 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data8/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-c62fab4b-c96d-4b6d-9690-6f02b59c191b | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,929 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data7/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-ee1c1dd3-6818-4c13-9030-9ae9c802b2a8 | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
2020-08-03 18:43:51,930 | INFO  | [shutdown-hook-0] | Deleting directory /srv/BigData/hadoop/data9/nm/localdir/usercache/su_graph_pro/appcache/application_1595920838912_178438/spark-ba6f81e7-b009-4394-9b1f-c2e074f4073d | org.apache.spark.internal.Logging$class.logInfo(Logging.scala:54)																																																																		
